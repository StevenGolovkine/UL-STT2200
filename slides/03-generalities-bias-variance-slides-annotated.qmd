--- 
title: "Généralités"
subtitle: "Biais et Variance"
author: "Steven Golovkine"
lang: fr
date: "19 sept. 2024"
date-format: "DD MMM YYYY"
slide-number: c/t
title-logo: ../include/logo-ul.png
format:
  revealjs:
    theme: [default, ../include/ulaval-slide.scss]
    chalkboard:
      src: annotation/03-generalities-bias-variance-slides-annotation.json
    width: 1280
    height: 720
    template-partials:
      - title-slide.html
--- 


## Objectif de modélisation

<br>

Modéliser la relation entre :

- Variable réponse $Y$ (quantitative, qualitative, etc.).

- Variables explicatives $X = (X_1, \ldots, X_p)$.


## Modèle général

<br>

$$Y = f(X) + \varepsilon$$

- $f$ : fonction déterministe (information systématique).

- $\varepsilon$ : terme d'erreur aléatoire.


## Hypothèses du modèle

<br>

Sur le terme d'erreur $\varepsilon$ :

- Indépendant des variables explicatives $X$.

- $\mathbb{E}[\varepsilon] = 0$ (espérance nulle).

- $\mathrm{Var}(\varepsilon) = \sigma^2$ (variance constante).

. . .

→ Cadre général pour toutes les méthodes du cours.


## Plan

<br>

1. Mesures de qualité - MSE et taux d'erreur

2. Compromis biais/variance - Décomposition fondamentale

3. Flexibilité des modèles - Rigidité vs adaptabilité

4. Optimisation pratique - Trouver l'équilibre

## Comment mesurer la qualité ?

<br>

Une fois $\hat{f}$ estimé, comment évaluer $\hat{Y} = \hat{f}(X)$ ?

. . .

<br>

Idée : Mesurer à quel point $\hat{Y}$ est proche de la vraie valeur $Y$.


## Variables quantitatives : EQM (MSE)

::: {.callout-warning icon=false}
## Erreur Quadratique Moyenne (MSE)

$$\text{MSE}(Y, \hat{Y}) = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{f}(x_i))^2$$

:::

. . .

Interprétation → Distance moyenne entre valeurs observées et prédites.

. . .

MSE faible → Prédictions proches des observations.


## Variables qualitatives : Taux d'erreur (ER)

::: {.callout-warning icon=false}
## Taux d'erreur (ER)

$$\text{ER}(Y, \hat{Y}) = \frac{1}{n} \sum_{i=1}^{n} \mathbb{1}(y_i \neq \hat{f}(x_i))$$
:::

. . .

Interprétation → Proportion de mauvaises prédictions.

. . .

ER faible → Prédictions proches des observations.


## Exactitude vs Interprétabilité

<br>

Modèles simples (ex: régression linéaire) :

- Faciles à interpréter

- Relations complexes mal captées


Modèles flexibles (ex: forêt aléatoire) :

- Meilleures prédictions

- Difficiles à interpréter

. . .

Le choix dépend de l'objectif : compréhension ou performance ?


## "No Free Lunch in Statistics"

<br>

::: {.callout-tip icon=false}
## Il n'existe pas de méthode universellement optimale !

Une méthode performante dans un contexte peut échouer ailleurs.

→ Toujours adapter l'approche au problème.
:::

## Erreur de prédiction

<br>

Notre vrai objectif : Minimiser l'erreur sur de **nouvelles données**

$$\mathbb{E}[(Y - \hat{Y})^2] = \mathbb{E}[(Y - \hat{f}(X))^2]$$

. . .

<br>

Cette erreur se décompose en 3 parties...


## Décomposition biais/variance

::: {.callout-important icon=false}
## Décomposition biais/variance

$$\mathbb{E}[(Y - \hat{f}(X))^2] = \text{Biais}(\hat{f}(X))^2 + \text{Var}(\hat{f}(X)) + \sigma^2$$
:::

Trois composantes :

::: {.incremental}
1. Biais$^2$ → Erreur systématique d'approximation.

2. Variance → Sensibilité aux fluctuations d'échantillon.

3. $\sigma^2$ → Erreur irréductible (bruit intrinsèque).
:::


## Décomposition biais/variance

<br>

Modèle peu flexible (ex: régression linéaire)

- ✅ Variance faible

- ❌ Biais élevé

Modèle très flexible (ex: régression avec beaucoup de polynômes)

- ❌ Variance élevée 

- ✅ Biais faible

. . .

→ Besoin d'un équilibre optimal !


## Décomposition biais/variance

<center>
<img src="./img/Bias_and_variance_contributing_to_total_error.svg" alt="Décomposition biais/variance" width="1080" height="540">

Par <a href="//commons.wikimedia.org/wiki/User:Bigbossfarin" title="User:Bigbossfarin">Bigbossfarin</a> - <span class="int-own-work" lang="en">Own work</span>, <a href="http://creativecommons.org/publicdomain/zero/1.0/deed.en" title="Creative Commons Zero, Public Domain Dedication">CC0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=105307219">Link</a>.
</center>


## Stratégies d'optimisation

<br>

Comment trouver l'équilibre ?

::: {.incremental}
1. Validation croisée → Estimation de l'erreur de prédiction.

2. Sélection de modèle → Comparer différentes des modèles avec différentes flexibilités.

3. Méthodes d'ensembles → Combiner plusieurs modèles.

4. Régularisation → Contrôler la complexité du modèle.
:::

## Implications pour la pratique

<br>

Questions à se poser :

::: {.incremental}
- Ai-je assez de données pour un modèle flexible ?

- Mon objectif est-il la prédiction ou la compréhension ?

- Quelle est la complexité réelle du phénomène étudié ?

- Comment évaluer la performance sur nouvelles données ?
:::

## Conclusion

::: {.incremental}
1. Erreur totale = Biais$^2$ + Variance + Bruit irréductible.

2. Compromis entre biais et variance.

3. Modèles rigides → Fort biais, faible variance.

4. Modèles flexibles → Faible biais, forte variance.  

5. Optimum → Équilibre minimisant l'erreur totale.

6. Pas de solution universelle → Il faut s'adapter au contexte.
:::

. . .

Prochaine étape → Validation et sélection de modèles.
