--- 
title: "Supervisée"
subtitle: "Analyse discriminante"
author: "Steven Golovkine"
lang: fr
date: "07 nov. 2025"
date-format: "DD MMM YYYY"
slide-number: c/t
title-logo: ../include/logo-ul.png
format:
  revealjs:
    theme: [default, ../include/ulaval-slide.scss]
    chalkboard: true
    width: 1280
    height: 720
    template-partials:
      - title-slide.html
--- 


## Plan

<br>

1. La théorie de l'analyse discriminante

2. L'analyse discriminante en pratique

3. Exemple


## Notation


Données:

- $X = (X_{ij}) \in \mathbb{R}^{n \times p}$ : matrice de données.

- $n$ : nombre d'individus / d'observations.

- $p$ : nombre de variables.

. . .

Groupes:

- $K$ groupes dans la population.

- $I_k$ : ensemble des individus du groupe $k$.

- $n_k$ : nombre d'observations dans $I_k$ et $\sum_{k=1}^{K} n_k = n$.


## Objectif principal

::: {.fragment}
Principe: 

- Partitionner $\mathbb{R}^p$ en $K$ sous-ensembles.

- Passer de $\mathbb{R}^p$ à $\mathbb{R}$ via un score.
:::

. . .

Score de Fisher

$$f(X_1, \ldots, X_p) = a^{\top} X + b = a_1 X_1 + \cdots + a_p X_p + b$$

. . .

Utiliser ce score pour déterminer le groupe d'appartenance.


## Simplification

<br>

En centrant les variables: $-b = a^{\top} \overline{X}$.

<br>

Il reste à déterminer le vecteur $a = (a_1, \ldots, a_p)$.


## Intuition

<br>

On voudrait choisir le vecteur $a$ de sorte que les scores soient 

- très différents entre les groupes

- très similaire à l'intérieur des groupes

. . .

On s'intéresse donc à la variabilité des scores à l'intérieur des groupes et entre les groupes.

. . .

Optimiser le rapport entre la variabilité **inter-groupes** (maximiser) et
la variabilité **intra-groupe** (minimiser).


## Matrices de variance-covariance

<br>

- $S$ : matrice de variance totale

- $W$ : matrice de variance intra-groupe  

- $B$ : matrice de variance inter-groupe

. . .

Relation fondamentale:

$$S = W + B$$


## Matrices de variance-covariance

<br>

Matrice totale: $S = \sum_{i=1}^{n} (X_i - \overline{X})(X_i - \overline{X})^{\top}$

. . .

<br>

Matrice intra-groupe: $W = \sum_{k=1}^{K} \sum_{i \in I_k} (X_i - \overline{X}_k)(X_i - \overline{X}_k)^{\top}$

. . .

<br>

Matrice inter-groupe: $B = \sum_{k=1}^{K} n_k (\overline{X}_k - \overline{X})(\overline{X}_k - \overline{X})^{\top}$

## Variabilité des scores

<br>

Étant donné que $a \in \mathbb{R}^p$, on a:
$$\mathrm{Var}(f(X_{1}, \dots, X_p)) = \mathrm{Var}(a^{\top} X) = a^{\top} \mathrm{Var}(X) a.$$

Comme $S$ est un estimateur de la variance totale de $X$,

$$\widehat{\mathrm{Var}}(f(X_{1}, \dots, X_p)) = \frac{1}{n} a^{\top} S a = \frac{1}{n} \left( a^{\top} W a + a^{\top} B a \right).$$



## Critère d'optimisation

<br>

$$J(a) = \frac{a^{\top} B a}{a^{\top} W a} = \frac{a^{\top} B a}{a^{\top} S a}$$

. . .

Formulations équivalentes

1. Maximiser $J(a)$ sous contrainte $a^{\top} a = 1$

2. Maximiser $a^{\top} B a$ sous contrainte $a^{\top} S a = 1$

3. Maximiser $c^{\top} S^{-1/2} B S^{-1/2} c$ sous contrainte $c^{\top} c = 1$ où $c = S^{1/2} a$.


## Solution optimale

<br>

En réécrivant la troisième formulation 

$$c^{\top} \left( S^{-1/2} B S^{-1/2} \right) c \quad\text{s.c.}\quad c^{\top} c = 1,$$

. . .

On peut prendre $a = S^{-1/2} c$, où $c$ est un vecteur propre normé associé à $\lambda_{1}$, la première valeur propre de $S^{-1/2} B S^{-1/2}$. 



## Fonction discriminante

<br>

$$f(x) = a^{\top} (x - \overline{X})$$

. . .

Scores des observations
$$U_i = a^{\top} (X_i - \overline{X})$$
Ces scores maximisent le rapport variance inter-groupe / variance intra-groupe


## Pouvoir discriminant

<br>

Interprétation de $\lambda_1$ → pouvoir discriminant de $f$
$$\lambda_1 = \frac{a^{\top} B a}{a^{\top} S a} \quad \text{avec } 0 \leq \lambda_1 \leq 1$$

. . .

$\lambda_1 = 1$ : Cas idéal

. . .

$\lambda_1 = 0$ : Analyse inutile



## Règle de classification

<br>

Score moyen par groupe
$$m_k = a^{\top} (\overline{X}_{k1}, \ldots, \overline{X}_{kp})^{\top}$$

. . .

Classification d'une nouvelle observation $X_0$

1. Calculer le score: $f(X_0) = a^{\top} X_0$

2. Assigner au groupe $k^*$ tel que:

$$k^* = \arg\min_{k} |a^{\top} X_0 - m_k|$$


## Cas binaire ($K = 2$)

<br>

Solution explicite
$$C = \sqrt{\frac{n_1 n_2}{n}} (\overline{X}_1 - \overline{X}_2)$$
$$B = CC^{\top}, \quad a = S^{-1}C$$

## Cas binaire ($K = 2$)

<br>

Règle de classification

Si $m_{1} = a^{\top} \overline{X}_1 > a^{\top} \overline{X}_2 = m_{2}$, classer $X_0$ dans le groupe 1 si:
$$a^{\top} X_0 > \frac{m_1 + m_2}{2}$$


## Évaluation de la performance

<br>

Matrice de confusion

- Appliquer la règle de classification à l'échantillon d'apprentissage

- Comparer les classifications prédites aux vraies classes

- Estimer les risques de mauvaise classification



## Conclusion

<br>

L'analyse discrimante est un algorithme de classification supervisée qui :

- est simple et interprétable.

- a une solution analytique explicite.

- permet une réduction de dimension naturelle ($\mathbb{R}^p \to \mathbb{R}$).

. . .

Prochaine étape → Des arbres !