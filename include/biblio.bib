@book{deisenrothMathematicsMachineLearning2020,
  title = {Mathematics for {{Machine Learning}}},
  author = {Deisenroth, Marc Peter and Faisal, A. Aldo and Ong, Cheng Soon},
  year = {2020},
  month = feb,
  edition = {1},
  publisher = {Cambridge University Press},
  doi = {10.1017/9781108679930},
  urldate = {2025-05-28},
  copyright = {https://www.cambridge.org/core/terms},
  isbn = {978-1-108-67993-0 978-1-108-47004-9 978-1-108-45514-5},
  file = {/Users/steven/Library/Mobile Documents/com~apple~CloudDocs/Zotero/bibliography/Deisenroth et al. - 2020 - Mathematics for Machine Learning.pdf}
}

@book{delmasIntroductionAuCalcul2013,
  title = {{Introduction au calcul des probabilit{\'e}s et {\`a} la statistique : exercices, probl{\`e}mes et corrections (2e {\'e}dition)}},
  shorttitle = {{Introduction au calcul des probabilit{\'e}s et {\`a} la statistique}},
  author = {Delmas, Jean-Fran{\c c}ois},
  year = {2013},
  pages = {416},
  publisher = {Les Presses de l'ENSTA},
  urldate = {2025-05-30},
  abstract = {Cet ouvrage illustre les grands concepts des probabilit{\'e}s et de la statistique math{\'e}matique pr{\'e}sent{\'e}s dans l'Introduction au calcul des probabilit{\'e}s et {\`a} la statistique, avec des exercices de mod{\'e}lisation et de manipulation : variables al{\'e}atoires, th{\'e}or{\`e}mes asymptotiques, mod{\`e}les gaussiens, r{\'e}gions de confiance, etc.},
  langid = {french},
  file = {/Users/steven/Library/Mobile Documents/com~apple~CloudDocs/Zotero/bibliography/Delmas - 2013 - Introduction au calcul des probabilités et à la statistique  exercices, problèmes et corrections (2.pdf;/Users/steven/Zotero/storage/86CBWM2J/hal-00964983.html}
}

@book{grifoneAlgebreLineaire2024,
  title = {{Alg{\`e}bre Lin{\'e}aire}},
  author = {Grifone, Joseph},
  year = {2024},
  edition = {7e edition},
  publisher = {CEPADUES},
  address = {Toulouse},
  abstract = {Cet ouvrage de r{\'e}f{\'e}rence pr{\'e}sente un cours complet d'alg{\`e}bre lin{\'e}aire recouvrant les programmes du premier cycle des Universit{\'e}s et des Classes Pr{\'e}paratoires. L'alg{\`e}bre lin{\'e}aire a sans doute une place sp{\'e}ciale parmi les disciplines enseign{\'e}es en premier cycle. - D'une part parce qu'elle est utilis{\'e}e pratiquement dans toutes les branches scientifiques : la physique, l'{\'e}conomie, la chimie, l'informatique... Sa connaissance fait partie du bagage indispensable au futur chercheur, ing{\'e}nieur ou agr{\'e}gatif. - D'autre part en vertu de son caract{\`e}re p{\'e}dagogique, car l'alg{\`e}bre et la g{\'e}om{\'e}trie se m{\^e}lent constamment et l'imagination est sans cesse sollicit{\'e}e. L'auteur s'est efforc{\'e} de r{\'e}diger un ouvrage qui, sans sacrifier {\`a} la rigueur, pr{\'e}sente les diff{\'e}rents sujets avec clart{\'e} et simplicit{\'e}.},
  isbn = {978-2-38395-134-6},
  langid = {french},
  keywords = {/unread},
  file = {/Users/steven/Library/Mobile Documents/com~apple~CloudDocs/Zotero/bibliography/Grifone - 2024 - Algèbre Linéaire.pdf}
}

@book{hastieElementsStatisticalLearning2009,
  title = {The {{Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2009},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-0-387-84858-7},
  urldate = {2023-07-07},
  isbn = {978-0-387-84857-0 978-0-387-84858-7},
  keywords = {statistics},
  file = {/Users/steven/Library/Mobile Documents/com~apple~CloudDocs/Zotero/bibliography/Springer/2009/Hastie et al_2009_The Elements of Statistical Learning.pdf;/Users/steven/Library/Mobile Documents/com~apple~CloudDocs/Zotero/bibliography/Springer/2009/Hastie et al_2009_The Elements of Statistical Learning2.pdf}
}

@article{hotellingAnalysisComplexStatistical1933,
  title = {Analysis of a Complex of Statistical Variables into Principal Components},
  author = {Hotelling, H.},
  year = {1933},
  journal = {Journal of Educational Psychology},
  volume = {24},
  number = {6},
  pages = {417--441},
  publisher = {Warwick \& York},
  address = {US},
  issn = {1939-2176},
  doi = {10.1037/h0071325},
  abstract = {The problem is stated in detail, a method of analysis is derived and its geometrical meaning shown, methods of solution are illustrated and certain derivative problems are discussed. (To be concluded in October issue.) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {/unread,Statistical Analysis,Statistical Variables},
  file = {/Users/steven/Library/Mobile Documents/com~apple~CloudDocs/Zotero/bibliography/Hotelling - 1933 - Analysis of a complex of statistical variables into principal components 1.pdf;/Users/steven/Library/Mobile Documents/com~apple~CloudDocs/Zotero/bibliography/Hotelling - 1933 - Analysis of a complex of statistical variables into principal components.pdf;/Users/steven/Zotero/storage/Z5KSI3CE/1934-00645-001.html}
}

@book{jamesIntroductionStatisticalLearning2021,
  title = {An {{Introduction}} to {{Statistical Learning}}: With {{Applications}} in {{R}}},
  shorttitle = {An {{Introduction}} to {{Statistical Learning}}},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  year = {2021},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {Springer US},
  address = {New York, NY},
  doi = {10.1007/978-1-0716-1418-1},
  urldate = {2024-06-13},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-1-0716-1417-4 978-1-0716-1418-1},
  langid = {english},
  keywords = {r-software,statistics},
  file = {/Users/steven/Library/Mobile Documents/com~apple~CloudDocs/Zotero/bibliography/Springer US/2021/James et al_2021_An Introduction to Statistical Learning2.pdf}
}

@inproceedings{leclercqTASTEApproachGeneral1993,
  title = {The {{TASTE Approach}}: {{General Implicit Solutions}} in {{Multiple Choice Questions}} ({{MCQs}}), {{Open Books Exams}} and {{Interactive Testing}}},
  shorttitle = {The {{TASTE Approach}}},
  booktitle = {Item {{Banking}}: {{Interactive Testing}} and {{Self-Assessment}}},
  author = {Leclercq, D. and Boxus, E. and {de Brogniez}, P. and Wuidar, H. and Lambert, F.},
  editor = {Leclercq, Dieudonn{\`e} A. and Bruno, James E.},
  year = {1993},
  pages = {210--232},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-58033-8_17},
  abstract = {The efficiency of school to efficiently train in higher order cognitive skills is sometimes questioned. Principles and techniques (such as open books exams, implicit questioning, self assessment) have been developed to enhance cognitive vigilance, data processing skills and metacognition. The details of those techniques are provided as well as some results about question characteristics and Student opinions. Further developments are considered and perspectivized with ambitious training and assessment goals.},
  isbn = {978-3-642-58033-8},
  langid = {english},
  file = {/Users/steven/Library/Mobile Documents/com~apple~CloudDocs/Zotero/bibliography/Leclercq et al. - 1993 - The TASTE Approach General Implicit Solutions in Multiple Choice Questions (MCQs), Open Books Exams.pdf}
}

@book{mcelreathStatisticalRethinkingBayesian2020,
  title = {Statistical {{Rethinking}}: {{A Bayesian Course}} with {{Examples}} in {{R}} and {{STAN}}},
  shorttitle = {Statistical {{Rethinking}}},
  author = {McElreath, Richard},
  year = {2020},
  month = mar,
  edition = {2},
  publisher = {{Chapman and Hall/CRC}},
  address = {New York},
  doi = {10.1201/9780429029608},
  abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds your knowledge of and confidence in making inferences from data. Reflecting the need for scripting in today's model-based statistics, the book pushes you to perform step-by-step calculations that are usually automated. This unique computational approach ensures that you understand enough of the details to make reasonable choices and interpretations in your own modeling work. The text presents causal inference and generalized linear multilevel models from a simple Bayesian perspective that builds on information theory and maximum entropy. The core material ranges from the basics of regression to advanced multilevel models. It also presents measurement error, missing data, and Gaussian process models for spatial and phylogenetic confounding. The second edition emphasizes the directed acyclic graph (DAG) approach to causal inference, integrating DAGs into many examples. The new edition also contains new material on the design of prior distributions, splines, ordered categorical predictors, social relations models, cross-validation, importance sampling, instrumental variables, and Hamiltonian Monte Carlo. It ends with an entirely new chapter that goes beyond generalized linear modeling, showing how domain-specific scientific models can be built into statistical analyses. Features Integrates working code into the main text Illustrates concepts through worked data analysis examples Emphasizes understanding assumptions and how assumptions are reflected in code Offers more detailed explanations of the mathematics in optional sections Presents examples of using the dagitty R package to analyze causal graphs Provides the rethinking R package on the author's website and on GitHub},
  isbn = {978-0-429-02960-8},
  keywords = {bayesian-analysis},
  file = {/Users/steven/Library/Mobile Documents/com~apple~CloudDocs/Zotero/bibliography/Chapman and Hall/CRC/2020/McElreath_2020_Statistical Rethinking.pdf}
}

@book{pyleDataPreparationData1999,
  title = {Data {{Preparation}} for {{Data Mining}}},
  author = {Pyle, Dorian},
  year = {1999},
  month = mar,
  publisher = {Morgan Kaufmann},
  abstract = {Data Preparation for Data Mining addresses an issue unfortunately ignored by most authorities on data mining: data preparation. Thanks largely to its perceived difficulty, data preparation has traditionally taken a backseat to the more alluring question of how best to extract meaningful knowledge. But without adequate preparation of your data, the return on the resources invested in mining is certain to be disappointing.Dorian Pyle corrects this imbalance. A twenty-five-year veteran of what has become the data mining industry, Pyle shares his own successful data preparation methodology, offering both a conceptual overview for managers and complete technical details for IT professionals. Apply his techniques and watch your mining efforts pay off-in the form of improved performance, reduced distortion, and more valuable results.On the enclosed CD-ROM, you'll find a suite of programs as C source code and compiled into a command-line-driven toolkit. This code illustrates how the author's techniques can be applied to arrive at an automated preparation solution that works for you. Also included are demonstration versions of three commercial products that help with data preparation, along with sample data with which you can practice and experiment. * Offers in-depth coverage of an essential but largely ignored subject.* Goes far beyond theory, leading you-step by step-through the author's own data preparation techniques.* Provides practical illustrations of the author's methodology using realistic sample data sets.* Includes algorithms you can apply directly to your own project, along with instructions for understanding when automation is possible and when greater intervention is required.* Explains how to identify and correct data problems that may be present in your application.* Prepares miners, helping them head into preparation with a better understanding of data sets and their limitations.},
  isbn = {978-1-55860-529-9},
  langid = {english},
  keywords = {Computers / Artificial Intelligence / General,Computers / Data Science / Data Analytics,Computers / Database Administration & Management},
  file = {/Users/steven/Library/Mobile Documents/com~apple~CloudDocs/Zotero/bibliography/Pyle - 1999 - Data Preparation for Data Mining.pdf}
}

@book{wassermanAllStatisticsConcise2010,
  title = {All of {{Statistics}}: {{A Concise Course}} in {{Statistical Inference}}},
  shorttitle = {All of {{Statistics}}},
  author = {Wasserman, Larry},
  year = {2010},
  month = nov,
  publisher = {Springer Publishing Company, Incorporated},
  abstract = {WINNER OF THE 2005 DEGROOT PRIZE! This book is for people who want to learn probability and statistics quickly. It brings together many of the main ideas in modern statistics in one place. The book is suitable for students and researchers in statistics, computer science, data mining and machine learning. This book covers a much wider range of topics than a typical introductory text on mathematical statistics. It includes modern topics like nonparametric curve estimation, bootstrapping and classification, topics that are usually relegated to follow-up courses. The reader is assumed to know calculus and a little linear algebra. No previous knowledge of probability and statistics is required. The text can be used at the advanced undergraduate and graduate level.},
  isbn = {978-1-4419-2322-6},
  file = {/Users/steven/Library/Mobile Documents/com~apple~CloudDocs/Zotero/bibliography/Wasserman - 2010 - All of Statistics A Concise Course in Statistical Inference.pdf}
}

@article{wickhamTidyData2014,
  title = {Tidy {{Data}}},
  author = {Wickham, Hadley},
  year = {2014},
  month = sep,
  journal = {Journal of Statistical Software},
  volume = {59},
  pages = {1--23},
  issn = {1548-7660},
  doi = {10.18637/jss.v059.i10},
  urldate = {2023-10-25},
  abstract = {A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.},
  copyright = {Copyright (c) 2013 Hadley  Wickham},
  langid = {english},
  keywords = {data-cleaning,r-software},
  file = {/Users/steven/Library/Mobile Documents/com~apple~CloudDocs/Zotero/bibliography/Journal of Statistical Software/2014/Wickham_2014_Tidy Data.pdf}
}
