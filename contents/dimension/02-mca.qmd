--- 
title: "Analyse des correspondances multiples"
format: 
  html: default
  pdf:
    number-sections: true
    header-includes:
      - \usepackage{mathtools} 
---

## Que faire avec des données catégorielles ? 

L'analyse en composantes principales (ACP) est bien adaptée pour des données **continues**. Mais que faire lorsque les variables sont catégorielles ? C'est la cas dans de nombreux contextes : enquêtes avec des questions à choix multiples, tableaux croisant des variables comme la profession, la région d'origine, la couleur des yeux, etc. 

Dans ces situations, on peut recourir à une méthode analogue à l'ACP, spécifiquement conçue pour les variables qualitatives : l'analyse des correspondances (AC). Cette méthode permet une représentation géométrique des relations entre les modalités de variables qualitatives. On distingue plusieurs variantes : 

* l'analyse factorielle des correspondances (AFC) qui est utilisée pour étudier la relation entre deux variables qualitatives (souvent sous forme d'un tableau de contingence).

* l'analyse des correspondances multiples (ACM) qui est une généralisation de l'AFC à plus de deux variables qualitatives, notamment dans le cas de questionnaires avec plusieurs questions à réponses catégorielles.


::: {.callout-note icon=false}
## Exemples

* La boussole électorale de Radio-Canada : visualisation des profiles politiques à partir de réponses à un questionnaire.

* Étude de segmentation de clientèle pour un opérateur télécom, à partir des caractéristiques déclarées par les clients.

* Association entre couleur des yeux et couleur des cheveux dans une enquête démographique.
  
:::

## Notation 

On considère un tableau de contingence $K = (k_{ij})$, où $k_{ij}$ est le nombre d'individus appartenant à la classe $i \in \{ 1, \dots, n \}$ et à la catégorie $j \in \{ 1, \dots, p \}$.
On travaille ensuite avec le tableau des fréquences relatives en normalisant ce tableau. Comme les fréquences sont proportionnelles à la taille d'échantillon $n$, le tableau des fréquences relatives contient plus d'information. Notons $F = (f_{ij})$, dans lequel
$$f_{ij} = \frac{k_{ij}}{k_{\bullet\bullet}} = \frac{k_{ij}}{\sum_{l = 1}^{n} \sum_{m = 1}^{p} k_{lm}}.$$

Les marges lignes (resp. colonnes) du tableau correspondent à la somme des colonnes pour chaque ligne (resp. à la somme des lignes pour chaque colonne):
\begin{align}
f_{i \bullet} &= \sum_{j = 1}^{p} f_{ij} = \frac{k_{i \bullet}}{k_{\bullet\bullet}}, \quad 1 \leq i \leq n; \\
f_{\bullet j} &= \sum_{i = 1}^{n} f_{ij} = \frac{k_{\bullet j}}{k_{\bullet\bullet}}, \quad 1 \leq j \leq p.
\end{align}

### Indépendance statistique 

Le tableau des fréquences relatives $F = (f_{ij})$ peut être interprété comme une estimation des probabilités conjointes des modalités des deux variables qualitatives. Si les deux variables sont statistiquement indépendantes, on s'attend à ce que la probabilité conjointe s'approche du produit des probabilités marginales :
$$f_{ij} \approx f_{i \bullet} f_{\bullet j}, \quad i \in \{ 1, \dots, n \},~ j \in \{ 1, \dots, p \}.$$

Pour tester si les écarts observés entre $f_{ij}$ et $f_{i \bullet} f_{\bullet j}$ sont significatifs, on utilise le test du $\chi^2$ d'indépendance :
$$T = \sum_{i = 1}^{n} \sum_{j = 1}^{p} \frac{\left( k_{ij} - \mathbb{E}(k_{ij}) \right)^2}{\mathbb{E}(k_{ij})} = \sum_{i = 1}^{n} \sum_{j = 1}^{p} \frac{\left( k_{ij} - \frac{k_{i \bullet}k_{\bullet j}}{k_{\bullet\bullet}} \right)^2}{\left( \frac{k_{i \bullet} k_{\bullet j}}{k_{\bullet\bullet}} \right)}.$$
Sous l'hypothèse d'indépendance, cette statistique suit approximativement une loi du $\chi^2$. Si les variables sont indépendantes, la statistique $T$ doit être proche de $0$.


### Profils-lignes et profils-colonnes

Pour analyser les structures dans le tableau de contingence, on introduit la notion de profil. Chaque ligne du tableau peut être vue comme un profil-ligne
$$L_i = \left( \frac{k_{i 1}}{k_{i \bullet}}, \dots, \frac{k_{i p}}{k_{i \bullet}} \right) = \left( \frac{f_{i 1}}{f_{i \bullet}}, \dots, \frac{f_{i p}}{f_{i \bullet}} \right).$$
Le profil-ligne représente la répartition des modalités $i$ de la première variable parmi les modalités de la seconde.

De même, chaque colonne du tableau peut être vue comme un profil-colonne
$$C_j = \left( \frac{k_{1 j}}{k_{\bullet j}}, \dots, \frac{k_{n j}}{k_{\bullet j}} \right) = \left( \frac{f_{1 j}}{f_{\bullet j}}, \dots, \frac{f_{n j}}{f_{\bullet j}} \right)
.$$
Le profil-colonne représente la répartition des modalités $j$ de la deuxième variable parmi les modalités de la première.

On peut ensuite s'intéresser au profil-ligne moyen (resp. profil-colonne moyen) obtenus comme la moyenne pondérée des profils-lignes (resp. profils-colonnes). Autrement dit, ils correspond aux fréquences marginales colonnes (resp. fréquences marginales lignes). Le profil-ligne moyen est donné par 
$$\left( \sum_{i = 1}^{n} f_{i \bullet} \frac{f_{i 1}}{f_{i \bullet}}, \dots, \sum_{i = 1}^{n} f_{i \bullet} \frac{f_{i p}}{f_{i \bullet}} \right) = \left( f_{\bullet 1}, \dots, f_{\bullet p} \right),$$
et le profil-colonne moyen est donné par 
$$\left( \sum_{j = 1}^{p} f_{{\bullet j}} \frac{f_{1 j}}{f_{\bullet j}}, \dots, \sum_{j = 1}^{p} f_{\bullet j} \frac{f_{n j}}{f_{\bullet j}} \right) = \left( f_{{1 \bullet}}, \dots, f_{n \bullet} \right).$$

Si les variables sont indépendantes, tous les profiles sont égaux à leur profils moyens respectifs. Autrement dit, pour tout $i \in \{ 1, \dots, n \}$ et $j \in \{ 1, \dots, p \}$, 
$$\left( \frac{f_{i 1}}{f_{i \bullet}}, \dots, \frac{f_{i p}}{f_{i \bullet}} \right) = \left( f_{\bullet 1}, \dots, f_{\bullet p} \right) \quad\text{et}\quad
\left( \frac{f_{1 j}}{f_{\bullet j}}, \dots, \frac{f_{n j}}{f_{\bullet j}} \right) = \left( f_{{1 \bullet}}, \dots, f_{n \bullet} \right).$$
Ainsi, plus les profils s'éloignent de leurs moyennes, plus les variables montrent une dépendance.

Pour mesurer la différence entre deux profils-lignes, on utilise la distance du $\chi^2$ pondérée par les fréquences marginales :
$$d^2(L_i, L_{i^\prime}) = \sum_{j = 1}^{p} \frac{1}{f_{\bullet j}} \left( \frac{f_{ij}}{f_{i \bullet}} - \frac{f_{i^\prime j}}{f_{i^\prime \bullet}} \right)^2.$$
On peut faire de même pour la différence entre deux profils-colonnes :
$$d^2(C_j, C_{j^\prime}) = \sum_{i = 1}^{n} \frac{1}{f_{i \bullet}} \left( \frac{f_{ij}}{f_{\bullet j}} - \frac{f_{i j^\prime}}{f_{\bullet j^\prime}} \right)^2.$$


On peut écrire cela sous forme matricielle. Notons $D_n = \text{diag}(f_{i \bullet})$ la matrice diagonale des poids des lignes et $D_p = \text{diag}(f_{\bullet j})$ la matrice diagonale des poids des colonnes. La matrice $D_n^{-1}F$ a pour lignes les profils-lignes et la matrice $D_p^{-1}F^{\top}$ a pour lignes les profils-colonnes. la distance du $\chi^2$ entre deux profils-lignes $L_i$ et $L_{i^\prime}$ s'écrit alors 
$$d^2(L_i, L_{i^\prime}) = (L_i - L_{i^\prime})^\top D_p^{-1} (L_i - L_{i^\prime}),$$
et de manière analogue pour deux profils-colonnes $C_j$ et $C_{j^\prime}$
$$d^2(C_j, C_{j^\prime}) = (C_j - C_{j^\prime})^\top D_n^{-1} (C_j - C_{j^\prime}).$$

Ces distances sont à la base de la représentation géométrique dans l'analyse des correspondances, où l'on cherche une projection des profils dans un espace de faible dimension qui conserve au mieux ces distances.

## Analyse factorielle des correspondances

L'analyse factorielle des correspondances (AFC) est une méthode d'analyse exploratoire qui vise à représenter graphiquement les relations entre les modalités de deux variables qualitatives. Elle permet de représenter simultanément les profils-lignes (dans $\mathbb{R}^p$) et les profils-colonnes (dans $\mathbb{R}^n$) d'un tableau de contingences, dans un espace de faible dimension, tout en préservant au mieux la distance du $\psi^2$. L'objectif de l'AFC est de trouver une représentation bidimensionnelle (voir tridimensionnelle) dans laquelle les proximités géométriques entre points reflètent au mieux les similarités entre les modalités.

::: {.callout-tip icon=false}
## Remarque

L'AFC peut être vue comme une double ACP : une ACP pondérée appliquée aux profils-lignes et aux profils-colonnes, dans leur espaces respectifs avec une métrique adaptée.

:::

L'analyse des profils-lignes s'appelle l'analyse directe. On considère les profils-lignes contenus dans la matrice $D_n^{-1}F \in \mathbb{R}^{n \times p}$. On projette les profils-lignes dans un espace muni de la métrique du $\chi^2$ sur les colonnes, définie par 
$$\left\langle x, y \right\rangle = x^{\top} D_p^{-1} y.$$

L'analyse des profils-colonnes s'appelle l'analyse duale. On considère les profils-colonnes contenus dans la matrice $D_p^{-1} F^{\top} \in \mathbb{R}^{p \times n}$. On projette les profils-colonnes dans un espace muni de la métrique du $\chi^2$ sur les lignes, définie par 
$$\left\langle x, y \right\rangle = x^{\top} D_n^{-1} y.$$

Pour l'analyse directe, on cherche le premier axe factoriel, i.e. la direction $u \in R^p$ qui maximise la variance projetée des profils-lignes, sous contrainte que $u$ soit normé. On cherche donc
$$\max_{u} = u^{\top} D_p^{-1} F^{\top} D_n^{-1} F D_p^{-1} u, \quad\text{s.c.}\quad u^{\top} D_p^{-1} u = 1.$$
Ce problème d'optimisation revient à chercher le premier vecteur propre de la matrice
$$S = F^{\top} D_n^{-1} F D_p^{-1}.$$
La matrice $S$ joue un rôle analogue à la matrice de covariance dans l'ACP. L'analyse duale se fait de façon similaire. On cherche le premier vecteur propre de la matrice 
$$T = F D_p^{-1} F^{\top} D_n^{-1}.$$
Les vecteurs propres de la matrice $T$ donnent les axes factoriels dans l'espace des lignes.

::: {.callout-tip icon=false}
## Remarques

1. Les matrices $S$ et $T$ sont les mêmes $r = \min(n - 1, p - 1)$ premières valeurs propres positives. Cela garantit une représentation cohérente des lignes et des colonnes dans le mêmes espace réduit.

2. En centrant les profils, on peut projeter les profils-lignes et les profils-colonnes dans un même repère, facilitant ainsi l'interprétation géométrique conjointe.

3. Les coordonnées factorielles des modalités sont obtenues à partir des vecteurs propres et des valeurs propres, mais leurs formules sont souvent complexes. Ce sont surtout les distances et les angles dans le plan factoriel qui importent pour l'analyse.

:::


## Centre de gravité et inertie 

Dans les sorties des logiciels de statistique, le nuage des points issus d'une AFC est généralement centré en $(0, 0)$. Cette convention reflète une analysis relative aux centres de gravité des profils-lignes et des profils-colonnes. Ce centrage est à la fois pratique et interprétable. En effet, il fait apparaître les distances entre les modalités par rapport à leur moyenne poindérée, i.e. par rapport au comportement moyen dans la population. 

Chaque modalité (ligne ou colonne) est associée à un poids, correspondant à sa fréquence marginale : le poids de la $i$e ligne est $f_{i \bullet}$ et le poids de la $j$e colonne est $f_{\bullet j}$. Le centre de gravité des lignes est la moyenne pondérée des profils-lignes : 

$$G_L = \left( g_{1}, \dots, g_{p} \right)^{top}, \quad \text{où}\quad g_j = \sum_{i = 1}^{n} f_{i \bullet} \frac{f_{i j}}{f_{i \bullet}} = \sum_{i = 1}^{n} f_{i j} = f_{\bullet j}, j \in \{ 1, \dots, p \}.$$ 

De même, le centre de gravité des colonnes est 
$$G_C = \left( f_{1 \bullet}, \dots, f_{n \bullet} \right)^{top}.$$

Pour recentrer les profils autour du centre de gravité, on soustrait leur valeur moyenne :
$$\frac{f_{i j}}{f_{i \bullet}} - g_{j} = \frac{f_{i j}}{f_{i \bullet}} - f_{\bullet j} = \frac{f_{i j} - f_{i \bullet} f_{\bullet j}}{f_{i \bullet}}.$$
Ce centrage garantit que chaque profil-ligne $i \in \{ 1, \dots, n \}$ est moyenné à zéro :
$$\sum_{j = 1}^{p} \frac{f_{i j} - f_{i \bullet}f_{\bullet j}}{f_{i \bullet}} = 0.$$

L'AFC ne se fait donc plus sur $S$ mais plutôt sur une matrice centrée $S^\star = (s_{j j^\prime}^\star),$ où 
$$s_{j j^\prime}^\star = \sum_{i = 1}^{n} \frac{\left( f_{i j} - f_{i \bullet} f_{\bullet j} \right) \left( f_{i j^\prime} - f_{i \bullet} f_{\bullet j^\prime} \right)}{f_{i \bullet} f_{\bullet j^\prime}}.$$

Par définition, 
$$\text{tr}(S^\star) = \sum_{j = 1}^{p} \sum_{i = 1}^{n} \frac{\left( f_{i j} - f_{i \bullet}f_{\bullet j} \right)^2}{f_{i \bullet} f_{\bullet j}}.$$

On retrouve l'expression de la statistique du $\chi^2$ servant à tester l'indépendance entre deux variables.


On peut prouver que $s_{j j^\prime}^\star = s_{j j^\prime} - f_{\bullet j},$ où 
$$s_{j j^\prime} = \sum_{i = 1}^{n} \frac{f_{i j}f_{i j^\prime}}{f_{i \bullet} f_{\bullet j^\prime}}.$$
Ceci entraîne que ces deux matrices ont les mêmes $p$ premiers vecteurs propres normalisés.


Coordonnées des points-lignes. La projection du $i$e point-ligne sur l'axe $j$ est donnée par 
$$\left( D_n^{-1} F \phi_j \right)_i = \frac{1}{f_{i \bullet}} \sum_{j^\prime = 1}^{p} f_{i j^\prime} \phi_{j j^\prime} = \sqrt{\lambda_j} \Psi_{j i} \equiv \widehat{\Psi}_{j i}.$$
De plus,
$$\sum_{i = 1}^{n} f_{i \bullet} \widehat{\Psi}^2_{j i} = \sum_{i = 1}^{n} f_{i \bullet} \left( \sqrt{\lambda_j} \Psi_{j i} \right)^2 = \lambda_j.$$


Coordonnées des point-colonne. La projection du $k$e point-ligne sur l'axe $j$ est donnée par 
$$\left( D_p^{-1} F^{\top} \psi_j \right)_k = \frac{1}{f_{\bullet k}} \sum_{i = 1}^{n} f_{i k} \psi_{j i} = \sqrt{\lambda_j} \Phi_{j k} \equiv \widehat{\Phi}_{j k}.$$
De plus,
$$\sum_{k = 1}^{p} f_{\bullet k} \widehat{\Phi}^2_{j k} = \sum_{k = 1}^{p} f_{\bullet k} \left( \sqrt{\lambda_j} \Phi_{j k} \right)^2 = \lambda_j.$$


L'inertie absolue du $i$e point-ligne sur l'axe $j$ est $f_{i \bullet}\widehat{\Psi}_{j i}^2$. L'inertie relative du $i$e point-ligne sur l'axe $j$ est 
$$\frac{f_{i \bullet} \widehat{\Psi}_{j i}^2}{\lambda_j}.$$


L'inertie absolue du $k$e point-colonne sur l'axe $j$ est $f_{\bullet k}\widehat{\Phi}_{j k}^2$. L'inertie relative du $k$e point-colonne sur l'axe $j$ est 
$$\frac{f_{\bullet k} \widehat{\Phi}_{j k}^2}{\lambda_j}.$$

L'inertie totale est $I = T / k_{\bullet\bullet}$.

la qualité de la représentation du $k$e point-colonne dans l'axe $j$ est donnée par
$$\frac{d_j^2(k, G_C)}{d^2(k, G_c)} = \cos^2(\theta_{k j}),$$
où $\theta_{k j}$ est l'angle entre le point $k$ et sa projection sur l'axe $j$.

Interprétation: 

1. Plus les $\cos^2(\theta_{k j})$ sont élevés, mieux les points sont représentés sur l'axe $j$.

2. Ceci ne signifie pas pour autant que les points sont près du centre du graphique.

3. Les points éloignés du centre de gravité se distinguent du centre de gravité.

4. Une interprétation semblable existe pour les points-lignes.



## Analyse des correspondances multiples

L'analyse des correspondances multiples est une généralisation de l'analyse des correspondances binaires.
Elle permet la representation graphique de tableaux de fréquences contnant plus de deux variables.
Un exemple classique d'un tableau de fréquences avec plus de deux variables est le tableau présentant les réponses d'individus à un questionnaire contenant $Q$ questions à choix multiples.

Très utile pour visualiser les résultats d'une étude par questionnaire.

L'ACM peut aussi être vue comme une version de l'ACP quand les variables sont catégorielles:

  * l'analyse duale permet de voir les individus ayant des profils de réponses similaires

  * on peut obtenir des scores continus pour les individus qui capturent une grande partie de l'information

  * donc aussi utile pour scorer les résultats d'une étude par questionnaire dans un but éventuel de partitionnement, par exemple


En général, pour un questionnaire contenant $Q$ questions, on a un tableau de la forme suivante:
$$Z = \left[ Z_1 \mid \cdots \mid Z_{Q} \right].$$

Notation: 

* $Q$: nombre de questions
* $n$: nombre d'individus répondant au questionnaire
* $p_q$: nombre de modalités (choix de réponses) de la question $q$.
* $p = p_{1} + p_{Q}$

Potentiel problème: plus le nombre de questions est grand, plus il y aura de cellules vides. C'est aussi le cas si le nombre de réponses aux questions est important.
La proportion de cellules non vides est 
$$\frac{nQ}{np} = \frac{Q}{p}.$$.

Si toutes les questions ont le même nombre de choix de réponses, alors $p_{1} = \dots = p_{Q} = \frac{p}{Q}$, de sorte que
$$\frac{Q}{p} = \frac{1}{p_{1}} \longrightarrow 0, \quad\text{quand}~ p_{1} \rightarrow \infty.$$

Le tableau résumé est un tableau de taille $n \times Q$. Il contient le numéro de la modalité associée à la réponse de chaque individu pour chacune des questions.

La tableau de Burt est une autre fa\c{c}on de présenter un tableau de fréquences contenant plus de deux variables. Étant donné un tableau logique $Z = \left[ Z_{1} \mid \cdots \mid Z_{Q} \right]$, le tableau de Burt associé est la matrice carrée $p \times p$ définie comme étant 
$$ B = \begin{pmatrix}
  Z_1^\top Z_1 & \cdots & Z_1^\top Z_Q \\
  \vdots & \ddots & \vdots \\
  Z_Q^\top Z_1 & \cdots & Z_Q^\top Z_Q
\end{pmatrix}.$$

::: {.callout-important icon=false}
## Propriétés de $Z_q^\top Z_q$

1. $Z_{q}^\top Z_q$ est une matrice diagonale $p_q \times p_q$ présentant les réponses à la $q$e question.

2. L'élément $(j, j)$ de la matrice $Z_q^\top Z_q$ est égal au nombre d'individus $d_{jj}$ qui appartiennent à la $j$e catégorie de la $q$e question.

3. $Z_{q}^\top Z_{r}$ est le tableau de fréquences présentant les répones au x $q$e et $r$e questions.

4. L'élément $(j, k)$ de la matrice $Z_q^\top Z_r$ est égal au nombre d'individus $d_{jk}$ qui appartiennent à la $j$e catégorie de la $q$e question et à la $k$e catégorie de la $r$e question.

:::

D'un point de vue mathématique, l'ACM est une AFC effectuée sur la matrice logique $Z$ ou sur le tableau de Burt $B$. On peut démontrer que l'on obtient les mêmes facteurs, et ce, peu importe la matrice utilisé pour l'analyse.

::: {.callout-note icon=false}
## Note

On peut créé un graphique comme l'AFC. Cependant, en ACM, la distance entre les points de même couleur et la géométrie globale du graphique ne peuvent pas s'interpréter comme en AFC. En fait, on s'intéresse aux points qui sont dans une même direction par rapport à l'origine.
:::

