--- 
title: "Probabilités et Statistiques"
format: 
  html: default
  pdf:
    header-includes:
      - \usepackage{mathtools} 
---

Dans cette partie, on présente quelques résultats en probabilités et statistiques dans le cadre de ce cours. Pour plus d'information, vous pouvez vous référer au cours STT-1000, à @wassermanAllStatisticsConcise2010 (en anglais) et à @delmasIntroductionAuCalcul2013 (en français).

## Modéliser le hasard 

Beaucoup de phénomènes réels ne sont pas prévisibles et généralement, leurs résultats contiennent une certaine variabilité. Cette variabilité est prise en compte grâce à une mesure de l'incertitude que l'on appelle **mesure de probabilités**. 

::: {.callout-warning icon=false}
## Définition

L'**espace d'évènements** $S$ est l'ensemble de tous les résultats possibles d'un phénomène. Un **évènement** est un sous-ensemble de l'espace d'évènements $S$.

:::

::: {.callout-note icon=false}
## Exemples

1. Si l'expérience consiste à lancer un pièce, $S = \{0, 1\}$. Le résultat de cette expérience ne peut pas être connu à l'avance. Par exemple, $E = \{1\}$ est un évènement de $S$. 

2. Si on s'intéresse à la durée de vie d'un téléphone, $S = \mathbb{R}_{+}$. On peut aussi choisir $S = [0, M]$, car cette durée de vie n'est probablement pas infini ! L'évènement $E = [10, \infty)$ représente l'évènement "une durée de vie de plus de 10 unités de temps".

3. Pour le nombre de jours sans neige à Québec dans l'année, on peut choisir $S = \mathbb{N}$. L'évènement $E = (0, 5]$ représente l'évènement "moins de 5 jours sans neige à Québec dans l'année". 

:::

::: {.callout-warning icon=false}
## Définition

Une **mesure de probabilités** $\mathbb{P}$ sur $S$ est une application (fonction) définie sur l'espace d'évènements et satisfaisant les propriétés suivantes :

1. Pour chaque évènement $E$, $\mathbb{P}(E) \in [0, 1]$. 

2. $\mathbb{P}(S) = 1$.

3. Soient $E_{1}, E_{2}, \dots$, une séquence d'évènements (finie ou infinie) mutuellement exclusive, i.e. $\forall i \neq j, E_{i} \cap E_{j} = \varnothing$. On a 
$$\mathbb{P}(\bigcup_{n = 1}^{\infty} E_n) = \sum_{n = 1}^{\infty} \mathbb{P}(E_n).$$

On appelle $\mathbb{P}(E)$, la probabilité de l'évènement $E$.

:::

La définition de mesures de probabilités peut être subjective et lié à l'expérience du statisticien. En reprenant l'exemple 3 sur le nombre de jours sans neige à Québec dans l'année. Une personne venant d'arriver au Canada peut vouloir donner la même probabilité à chacun des jours, alors qu'un Québécois aura plus d'information et pourras faire varier les probabilités en fonction de cette connaissance.

::: {.callout-warning icon=false}
## Définition

Deux évènements $E$ et $F$ sont dits **indépendants** si $\mathbb{P}(E \cap F) = \mathbb{P}(E) \times \mathbb{P}(F)$.

:::

::: {.callout-warning icon=false}
## Définition

Soient $E$ et $F$, deux évènements, la **probabilité conditionelle** que $E$ se réalise sachant que $F$ s'est réalisé est définie par :
$$\mathbb{P}(E \mid F) = \frac{\mathbb{P}(E \cap F)}{\mathbb{P}(F)}.$$

:::

De façon intuitive, deux évènements sont indépendants si la connaissance de l'un ne donne aucune information sur la réalisation de l'autre. On a aussi $\mathbb{P}(E \mid F) = \mathbb{P}(E)$.

## Variables aléatoires

En probabilité, la convention est d'exprimer le résultat d'expériences comme la valeur d'une fonction appelé **variable aléatoire**. Cette caractérisation est toujours possible.

::: {.callout-warning icon=false}
## Définition

Soit une variable aléatoire $X$. La **distribution** de cette variable aléatoire est définie par l'application $A \mapsto \mathbb{P(X \in A)}$.

:::

::: {.callout-warning icon=false}
## Définition

Soit une variable aléatoire $X$. Cette variable aléatoire est **discrète** si elle prend, au plus, un nombre dénombrable de valeurs. Dans ce cas, la distribution de $X$ est donnée par les probabilités $\mathbb{P}(X = x)$ pour tout résultat $x$.

:::


::: {.callout-warning icon=false}
## Définition

Soit une variable aléatoire $X$. Cette variable aléatoire est **continue** si les probabilités $\mathbb{P}(X \in A)$ sont données par des intégrales de la forme $\int_{A} f(x) dx$ où $f: \mathbb{R}^d \to \mathbb{R}_+$ est une fonction intégrable tel que $\int_{\mathbb{R}^d} f(x) dx = 1$. Notons que, pour un résultat $x$ fixé, $\mathbb{P}(X = x) = 0$.

:::


::: {.callout-warning icon=false}
## Définition

Soit une variable aléatoire $X$. L'**espérance mathématique** $\mathbb{E}(X)$ de $X$ est la valeur moyenne du résultat de $X$ par rapport à sa distribution de probabilité. L'espérance est généralement noté $\mu$.

:::


Soit $F$ un ensemble dénombrable. Une variable aléatoire discrète $X$ a pour espérance $\mathbb{E}(X) = \sum_{x \in F} x \mathbb{P}(X = x)$. Soit une variable aléatoire continue $X$ ayant pour densité $f$, son espérance est donnée par $\mathbb{E}(X) = \int_{\mathbb{R}^d} x f(x) dx$. 

::: {.callout-caution icon=false}
## Théorème de transfert 

Soit une variable aléatoire $X$. Soit $g: \mathbb{R}^d \mapsto \mathbb{R}$ une fonction telle que $\mathbb{E}\left[ g(X) \right]$ existe. On a :

1. Si $X$ est une variable aléatoire discrète, $\mathbb{E}\left[ g(X) \right] = \sum_{x \in F} g(x) \mathbb{P}(X = x)$;

2. Si $X$ est une variable aléatoire continue de densité $f$, $\mathbb{E}\left[ g(X) \right] = \int_{\mathbb{R}^d} g(x)f(x) dx$.

:::

::: {.callout-important icon=false}
## Propriétés: Linéarité de l'espérance

Soient $X$ et $Y$, deux variables aléatoires, dont les espérances sont définies et soit $\lambda \in R$. On a :

1. $\mathbb{E}(X + Y) = \mathbb{E}(X) + \mathbb{E}(Y)$;

2. $\mathbb{E}(\lambda X) = \lambda \mathbb{E}(X)$.

:::

::: {.callout-note icon=false collapse=true}
## Preuve

La preuve se déduit du théorème de transfert et de la linéarité de l'addition et de l'intégration.
:::


::: {.callout-warning icon=false}
## Définition

Soit $X$ une variable aléatoire telle que l'espérance de son carré existe. La **variance** de $X$ est définie par 
$$\mathrm{Var}(X) = \mathbb{E}\left[ \left( X - \mathbb{E}(X) \right)^2 \right] = \mathbb{E}\left[ X^2 \right] - \mathbb{E}\left[ X \right]^2.$$

:::

La variance mesure la dispersion d'une variable aléatoire autour de sa moyenne. On peut aussi s'intéresser à l'**écart-type**, défini comme la racine carrée de la variance : $\sigma(X) = \sqrt{\mathrm{Var}(X)}$.

::: {.callout-warning icon=false}
## Définition

Soient $X$ et $Y$, deux variables aléatoires et $A$ et $B$, deux évenements. Si les évenements $\left{ X \in A \right}$ et $\left{ Y \in B \right}$ sont indépendants, alors on dit que les variables aléatoires $X$ et $Y$ sont indépendantes.

:::
Matrice de corrélation: 
$$\mathrm{Cor}(X) = \begin{pmatrix}
  1 & \cdots & \mathrm{Corr}(X_{1}, X_{p})  \\
  \vdots & \ddots & \vdots \\
  \mathrm{Corr}(X_{1}, X_{p}) & \cdots & 1
  \end{pmatrix} \coloneqq \begin{pmatrix}
  1 & \cdots & \rho_{1, p} \\
  \vdots & \ddots & \vdots \\
  \rho_{1, p} & \cdots & 1
\end{pmatrix} \coloneqq R.$$

Propriété des moments:

::: {.callout-important icon=false}
## Properties

Soit $X$ un vecteur aléatoire de moyenne $\mathbb{E}(X) = \mu$ et de variance $\mathrm{Var}(X) = \Sigma$, et soit $M$ une matrice de constantes et $v$ un vecteur de constantes.

1. $\Sigma$ est définie non-négative et symétrique.

2. $\Sigma = \mathbb{E}\left[ (X - \mu)(X - \mu)^\top \right] = \mathbb{E}(X X^\top) - \mu \mu^\top$.

3. $\mathbb{E}(MX + v) = \mathbb{E}(X) + v$.

4. $\mathrm{Var}(MX + v) = \mathrm{Var}(MX) = M \Sigma M^\top$.

5. $\Sigma = \Delta R \Delta \iff R = \Delta^{-1} \Sigma \Delta^{-1}$.

:::

Ajouter qqc sur l'indépendance de variables aléatoires!


Loi normale multivariée: 
On dit qu'un vecteur aléatoire $X$ de dimension $p$ suit une loi normale multidimensionnelle de moyenne $\mu$ et de variance $\Sigma \sim \mathcal{N}_{p}(\mu, \sigma^2)$, si sa densité est données par 
$$f_X(x) = \frac{1}{(2 \pi)^{p /2}} \cdot \frac{1}{(\text{det} \Sigma)^{1/2}} \cdot \exp\left\{ -\frac{1}{2}\left( x - \mu \right)^\top \Sigma^{-1} \left( x - \mu \right) \right\}, \quad x \in \mathbb{R}^p.$$

Estimation avec un échantillon: 
En practique, nous ne connaissons pas les valeurs de $\mu$ et de $\Sigma$ et nous voulons les estimer à partir d'un échantillon. Soit $X_{1}, \dots, X_{n}$, $n$ réalisations indépendantes d'un vecteur aléatoire $X$ de moyenne $\mu$ et de variance $\Sigma$. On estime $\mu$ et $\Sigma$ par : 


$$\widehat{\mu} = \overline{X} \coloneqq \frac{1}{n} \sum_{i = 1}^{n} X_i$$

$$\widehat{\Sigma} = S^2 \coloneqq \frac{1}{n - 1}\sum_{i = 1}^{n} (X_i - \overline{X})(X_i - \overline{X})^\top.$$

Notons $D = \{\text{diag}(S^2)\}^{1/2}$, la matrice des écarts-types calculés sur l'échantillon. On peut calculer la matrice des corrélations sur l'échantillon par : 
$$\widehat{R} = D^{-1} S^2 D^{-1} \iff S^2 = D \widehat{R} D.$$
