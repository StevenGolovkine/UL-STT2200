[
  {
    "objectID": "td/03-generalities-td.html#exercice-2-classifieur-de-bayes",
    "href": "td/03-generalities-td.html#exercice-2-classifieur-de-bayes",
    "title": "TD: Généralités",
    "section": "Exercice 2 : Classifieur de Bayes",
    "text": "Exercice 2 : Classifieur de Bayes"
  },
  {
    "objectID": "contents/06-nonsupervisee.html",
    "href": "contents/06-nonsupervisee.html",
    "title": "Non-supervisée",
    "section": "",
    "text": "On veut partitionner \\(n\\) observations en \\(K\\) groupes avec comme objectifs:\n\nque les observations dans une même classe soient le plus similaire possible;\nque les observations dans des classes différentes soient les moins similaires possibles.\n\nOn veut donc définir une fonction, que l’on appelle classifieur, qui prend un numéro d’observation \\(i\\) en entrée et qui donne son numéro de groupe en sortie qui va remplir ces deux objectifs.\n\\[\\begin{align}\nC: \\{ 1, \\dots, n \\} &\\rightarrow \\{ 1, \\dots, K\\} \\\\\ni &\\mapsto C(i)\n\\end{align}\\]\nLa fonction objectif est \\[W(C) = \\sum_{k = 1}^{K} \\sum_{i: C(i) = k} \\sum_{j: C(j) = k} d(x_i, x_j),\\]\nou \\(d(x_i, x_j)\\)\nProblème de grande taille!\nComme on ne peut pas explorer l’espace de toutes les possibilités, nous utiliserons des algorithmes gloutons (greedy algorithm), c’est-à-dire qu’ils vont nous donner une règle \\(C\\) qui minimise \\(W(C)\\) sur un espace restreint et qui ne garantissent pas nous ayons trouvé un minimum global.\nDans notre contexte:\n\n\\(p\\) variables sont numériques/ordinales (et habituellement standardisées).\nLa valeur de \\(K\\) est fixé.",
    "crumbs": [
      "Modules",
      "06 - Non-supervisée"
    ]
  },
  {
    "objectID": "contents/03-generalities.html",
    "href": "contents/03-generalities.html",
    "title": "Généralités",
    "section": "",
    "text": "Slides: link\nTD: link\nTP: link",
    "crumbs": [
      "Modules",
      "03 - Généralités"
    ]
  },
  {
    "objectID": "contents/03-generalities.html#sommaire",
    "href": "contents/03-generalities.html#sommaire",
    "title": "Généralités",
    "section": "Sommaire",
    "text": "Sommaire\n\nProjet d’analyse de données\nEspaces\nDistances\nBiais / Variance\nÉvaluation de modèles\n\n\n\n\nCorrelation (xkcd:552).",
    "crumbs": [
      "Modules",
      "03 - Généralités"
    ]
  },
  {
    "objectID": "contents/unsupervised/02-hierarchy.html",
    "href": "contents/unsupervised/02-hierarchy.html",
    "title": "Hierarchique",
    "section": "",
    "text": "Certains problèmes de l’algorithme \\(k\\)-means peuvent être résolu avec des algorithmes de classification hiérarchique. Par exemple, lorque l’on a à dispostion qu’une matrice de similiarité/distance entre les observations.\nLa classification hiérarchique permet d’obtenir des partitions toutes imbriquées les unes dans les autres. Il existe deux types d’algortihmes pour effectuer de la classification hiérarchique:\nDans les deux cas, on obtient \\(n\\) partitions hiérarchiques constituées de \\(1\\) à \\(n\\) groupes.",
    "crumbs": [
      "Modules",
      "06 - Non-supervisée",
      "Hierarchique"
    ]
  },
  {
    "objectID": "contents/unsupervised/02-hierarchy.html#algorithme-descendant",
    "href": "contents/unsupervised/02-hierarchy.html#algorithme-descendant",
    "title": "Hierarchique",
    "section": "Algorithme descendant",
    "text": "Algorithme descendant\nUn algorithme descendant fonctionne ainsi:\n\nAu départ, toutes les observations sont dans un seul et même groupe de \\(n\\) observations;\nÀ chaque étape, on divise le groupe le moins homogéne en deux groupes.\nÀ la fin, après \\(n\\) étapes, chaque observation à son propre groupe, c’est-à-dire qu’on obtient \\(n\\) groupes contenant une seule observation.\n\nL’exécution de cet algorithme ne donne pas une seule parition, mais \\(n\\) partitions, que l’on peut résumer à l’aide d’un graphique en forme d’arbre appelé dendogramme. Certains critères peuvent aider à choisir l’une parmi les \\(n\\) partitions proposées par l’algorithme. Ils demandent beaucoup de temps de calcul.",
    "crumbs": [
      "Modules",
      "06 - Non-supervisée",
      "Hierarchique"
    ]
  },
  {
    "objectID": "contents/unsupervised/02-hierarchy.html#algorithme-ascendant",
    "href": "contents/unsupervised/02-hierarchy.html#algorithme-ascendant",
    "title": "Hierarchique",
    "section": "Algorithme ascendant",
    "text": "Algorithme ascendant\nUn algorithme ascendant fonctionne ainsi:\n\nAu départ, chaque observation est son propre groupe, c’est-à-dire uq’on démarre avec \\(n\\) groupes content chacun une seule observation.\nÀ chaque étape, on fusionne les deux groupes les plus similaires.\nÀ la fin, après \\(n\\) étapes, on obtient un seul groupe contenant toutes les \\(n\\) observations.\n\nDifférences entre les algorithmes:\n\ncaractère ascendant ou descendant;\nleur faon de mesurer les distances / similiarité entre deux observations;\nleur faon de mesurer les distances / similiarité entre deux groupes.",
    "crumbs": [
      "Modules",
      "06 - Non-supervisée",
      "Hierarchique"
    ]
  },
  {
    "objectID": "contents/unsupervised/02-hierarchy.html#distance-entre-groupes",
    "href": "contents/unsupervised/02-hierarchy.html#distance-entre-groupes",
    "title": "Hierarchique",
    "section": "Distance entre groupes",
    "text": "Distance entre groupes\nPour mettre en oeuvre les algorithmes précédent, on doit définir la distance entre deux groupes d’observations \\(A\\) et \\(B\\), \\(d(A, B)\\).\nExample: On sait comment mesurer la distance entre les trois paires possibles de \\(\\{ 1 \\}\\), \\(\\{  2 \\}\\) et \\(\\{ 3 \\}\\), mais comment mesurer la distance entre \\(\\{ 1, 2 \\}\\) et \\(\\{ 3 \\}\\) ?\nIl existe plusieurs faons de calculer une telle distance entre deux groupes.\n\nMéthode du plus proche voisin (single linkage)\n\n\\[d(A, B) = \\min \\{ d_{i j}: i \\in A, j \\in B \\}.\\]\n\\[s(A, B) = \\max \\{ s_{i j}: i \\in A, j \\in B \\}.\\]\nLa distance/similiarité entre deux groupes d’observations est tout simplement la distance/similiarité entre les points de chaque groupe qui sont les plus rapprochés/similaires\nAvantages: * Donne de bons résultats lorsque les variables sont de types différents * Possède d’excellentes propriétés théoriques * Permet de créer des groupes dont la forme est très irrégulière * Est robuste aux données aberrantes\nDésavantages: * Tend à former un grand groupe avec plusieurs petits groupes satellites * Perd de l’efficacité si les vrais groupes sont de forme réegulière * Possède des propriétés théoriques ne semblant pas se réaliser en pratique dans certaines études\n\nMéthode du voisin le plus distant (complete linkage)\n\n\\[d(A, B) = \\max \\{ d_{i j}: i \\in A, j \\in B \\}.\\]\n\\[s(A, B) = \\min \\{ s_{i j}: i \\in A, j \\in B \\}.\\]\nLa distance/similiarité entre deux groupes d’observations est tout simplement la distance/similiarité entre les points de chaque groupe qui sont les plus éloignés/dissimilaires.\nAvantages: * Donne de bons résultats lorsque les variables sont de types différents * Tend à former des groupes de taille égale\nDésavantages: * Est extrêmement sensible aux données aberrantes * Tend à former des groupes de taille égale * Est très peu utilisée en pratique\n\nMéthode de la moyenne (average linkage)\n\n\\[d(A, B) = \\frac{1}{n_{A}n_{B}} \\sum_{i \\in A} \\sum_{j \\in B} d(x_{i}, x_{j}).\\] où \\(n_{A}\\) est le nombre d’observations dans le groupe \\(A\\) et \\(n_{B}\\) est le nonmbre d’observations dans le group \\(B\\).\nOn doit calculer les \\(n_{A} \\times n_{B}\\) distances/similiarités possibles entre les points des deux groupes, ensuite on prend la moyenne de ces distances/similiarités comme étant celle qui sépare les groupes.\nAvantages: * Tend à former des groupes de faible variance\nDésavantages: * Tend à former des groupes de même variance\n\nMéthode du centroïde (centroid method)\n\n\\[d(A, B) = d(\\overline{x}_{A}, \\overline{x}_{B}).\\] où \\[\\overline{x}_{A} = \\frac{1}{n_{A}} \\sum_{i \\in A} x_i, \\quad\\text{et}\\quad \\overline{x}_B = \\frac{1}{n_{B}} \\sum_{j \\in B} x_j\\]\nLa moyenne \\(\\overline{x}_{AB}\\) du nouveau groupe résultant de la fusion des groupes \\(A\\) et \\(B\\) se calcule comme suit: \\[\\overline{x}_{AB} = \\frac{n_{A} \\overline{x}_{A} + n_{B} \\overline{x}_{B}}{n_{A} + n_{B}}.\\]\nAvantages: * Est très robuste aux données aberrantes\nDésavantages: * Est peu efficace en l’absence de données aberrantes\n\nMéthode de la médiane (median method)\n\nÀ une étape donnée, nous avons toujours à notre disposition la distance entre les groupes déjà formés. On fusionne les deux groupes les moins distants/les plus similaires, disons \\(A\\) et \\(B\\) pour obtenir un groupe \\(AB\\). On met à jour la matrice des distances: la distance entre le nouveau groupe \\(AB\\) et tout autre groupe \\(C\\) est donnée par \\[d(AB, C) = \\frac{d(A, C) + d(B, C)}{2} - \\frac{d(A, B)}{4}.\\]\nAvantages: * Est encore plus robuste en présence de données aberrantes\nDésavantages: * Est très peu efficace en l’absence de données aberrante\n\nMéthode de Ward (Ward’s method)\n\nVariante de la méthode du centroïde pour tenir compte de la taille des groupes. Elle a été conue pour être optimale si les \\(n\\) vecteurs \\(x_{1}, \\dots, x_{n}\\) suivent des lois normales multivariées de \\(K\\) moyennes différentes mais toutes de même matrice de variance-covariance.\nBasée sur les sommes des carrées \\[SC_A = \\sum_{i \\in A} (x_i - \\overline{x}_A)^\\top (x_i - \\overline{x}_A).\\]\n\\[SC_B = \\sum_{j \\in B} (x_j - \\overline{x}_B)^\\top (x_j - \\overline{x}_B).\\]\n\\[SC_AB = \\sum_{k \\in A \\cup B} (x_k - \\overline{x}_{AB})^\\top (x_k - \\overline{x}_{AB}).\\]\noù \\(\\overline{x}_A\\), \\(\\overline{x}_B\\) et \\(\\overline{x}_{AB}\\) sont calculées comme dans la méthode du centroïde. On regroupe les classes \\(A\\) et \\(B\\) pour lesquelles \\[I_{AB} = SC_{AB} - SC_A - SC_B = \\frac{d^2(\\overline{x}_A, \\overline{x}_B)}{\\frac{1}{n_{A} + \\frac{1}{n_{B}}}}\\] est minimale.\nAvantages: * Est optimale si les observations sont approximativement distribuées selon une loi normale multidimensionnelle de même matrice de variances-covariances\nDésavantages: * Est sensible aux données aberrantes * Tend à former des groupes de petite taille * Tend à former des groupes de même taille\n\nMéthode flexible\n\nLes auteurs de cette méthode ont remarqué que pour plusieurs méthodes connues, on a les relations suivantes: \\[d(C, AB) = \\alpha_A d(C, A) + \\beta d(C, B) + \\beta d(A, B) + \\gamma \\left| d(C, A) - d(C, B) \\right|.\\]\n\n\n\n\n\n\n\n\n\n\nMéthode\n\\(\\alpha_A\\)\n\\(\\alpha_B\\)\n\\(\\beta\\)\n\\(\\gamma\\)\n\n\n\n\nPlus proche\n\\(1/2\\)\n\\(1/2\\)\n\\(0\\)\n\\(-1/2\\)\n\n\nPlus distant\n\\(1/2\\)\n\\(1/2\\)\n\\(0\\)\n\\(1/2\\)\n\n\nMédiane\n\\(1/2\\)\n\\(1/2\\)\n\\(-1/4\\)\n\\(0\\)\n\n\nMoyenne\n\\(\\frac{n_A}{n_A+n_B}\\)\n\\(\\frac{n_B}{n_A+n_B}\\)\n\\(0\\)\n\\(0\\)\n\n\nCentroïde\n\\(\\frac{n_A}{n_A+n_B}\\)\n\\(\\frac{n_B}{n_A+n_B}\\)\n\\(-\\frac{n_An_B}{n_A + n_B}\\)\n\\(0\\)\n\n\nWard\n\\(\\frac{n_A+n_C}{n_A+n_B+n_C}\\)\n\\(\\frac{n_B+n_C}{n_A+n_B+n_C}\\)\n\\(-\\frac{n_C}{n_A+n_B+n_C}\\)\n\\(0\\)\n\n\n\nAvec la méthode flexible, on impose arbitrairement les contraintes suivantes: \\[\\alpha_A + \\alpha_B + \\beta = 1, \\quad \\alpha_A = \\alpha_B, \\quad \\gamma = 0.\\]\nAinsi, \\[\\alpha_A = \\alpha_B = \\frac{1 - \\beta}{2}.\\] Et il ne reste qu’à choisir \\(\\beta\\). Les autheurs suggèrent de poser \\(\\beta = -0.25\\) sauf quand on souponne la présence de données aberrantes où l’on suggère \\(\\beta = -0.5\\).",
    "crumbs": [
      "Modules",
      "06 - Non-supervisée",
      "Hierarchique"
    ]
  },
  {
    "objectID": "contents/unsupervised/02-hierarchy.html#pratique",
    "href": "contents/unsupervised/02-hierarchy.html#pratique",
    "title": "Hierarchique",
    "section": "Pratique",
    "text": "Pratique\nL’exécution d’un algorithme nous donne une séquence de \\(n\\) partitions ayant de \\(n\\) à \\(1\\) groupes.\nQuelle partition de cette séquence devrions-nous choisir?\nL’une des \\(n\\) partitions est-elle particulièrement interprétable? L’une des \\(n\\) partitions a-t-elle a un sens pratique? Visions-nous séparer la population en un nombre \\(K\\) de groupes?\nS’il n’y a pas de réponse claire à ces questions, des critères peuvent nous guider …\nIl y a plusieurs indications pour nous aider dans le choix du nombre de classe (surtout si les variables sont continues). La librairie NbClust en contient une trentaine: https://www.rdocumentation.org/packages/NbClust/versions/3.0.1/topics/NbClust\n\nLes indicateurs basées sur l’inertie\n\n\\[I_{tot} = I_{intra-groupe}+ I_{inter-groupe}\\] Ces indicateurs sont plus pertinents avec des variables continues. Prendre garde au poids des variables et à la standardisation.\n\nPseudo- \\(R^2\\)\n\n\\[Pseudo-R^2 =\\frac{I_{inter-groupe}}{I_{tot}}\\]\n\nStatistique de Caliliski-Harabasz (CH):\n\n\\[CH = \\frac{I_{inter-groupe}/(k-1)}{I_{intra-groupe}/(n-k)}\\]\n\nIndice de Dunn: On maxime l’indice suivant:\n\n\\[D= \\frac{\\text{Distance minimale entre 2 groupes}}{\\text{Distance maximale dans un groupe}}\\]\nL’indice de Dunn cherche donc à créer des groupes denses et bien séparés.\n\nIndice de silhouette\n\nLa silhouette de l’observation \\(i\\) mesure la confiance dans le choix du groupe pour l’observation \\(i\\): \\[S(i) = \\frac{b_i-a_i}{max(b_i,a_i)}\\] où \\(a_i\\) est la distance moyenne entre l’observation \\(i\\) et les autres observations de son groupe et \\(b_i\\) est la distance moyenne entre l’observation \\(i\\) et les observations du groupe le plus proche de \\(i\\). On souhaite maximiser la silhouette moyenne des observations.\n\nCritère de classification cubique (CCC)\n\nOn fait un graphique avec le CCC en ordonnée et le nombre de groupes en abscisse. Pour le nombre de groupes, on ne considère que les partitions de \\(K=1\\) à \\(K=n/10\\). Si \\(CCC&gt;2\\), on est en présence d’une classification de bonne qualité. Si \\(0&lt;CCC&lt;2\\), on est en présence d’une classification de qualité moyenne. Si \\(CCC&lt;0\\), on est en présence d’une classification de mauvaise qualité. Pour choisir le nombre de classes à retenir, on peut considérer les nombres de classes associés aux fortes hausses du critère CCC entre deux nombres de classes subséquents. On considère les pics, atteignant des valeurs du critère supérieures à 2 ou à 3 comme étant de fortes hausses de ce critère.\nIl ne faut pas utiliser le critère CCC avec la méthode du plus proche voisin, ou lorsque l’on suspecte que les groupes sont de forme très allongée ou irrégulière. Le critères ne fonctionne pas bien quand le nombre d’observations dans certains groupes est inférieur à 10.\n\nStatistique pseudo-\\(F\\)\n\nStatistique presque distribuée selon une loi \\(F\\) lorsque la loi des données pas trop loin de la normale multivariée avec variances égales dans toutes les classes. Même si on est loin de la normalité, en pratique cette statistique peut quand-même être informative. On cherche des nombres de classes pour lesquels la statistique du pseudo-\\(F\\) se démarque par une grande valeur. Sur un graphique de la statistique du pseudo-\\(F\\) en fonction du nombre de classes, ceci se traduit par la recherche de pics. Il ne faut pas utiliser la statistique du pseudo-\\(F\\) avec la méthode du plus proche voisin.\n\nStatistique du pseudo-\\(t^2\\)\n\nStatistique presque distribuée selon une loi \\(t\\) lorsque loi des données pas trop loin de la normale multivariée avec des variances égales dans toutes les classes. En pratique, on regarde le graphique de la statistique du pseudo-\\(t^2\\) en fonction du nombre de classes de droite à gauche, on essaie de trouver des valeurs de la statistique qui sont beaucoup plus élevées que la valeur précédente. Supposons que la forte hausse se produit entre \\(k\\) et \\(k-1\\) classes. On choisit \\(k\\) classes dans le partitionnement de nos observations. Il ne faut pas utiliser la statistique du pseudo-\\(t^2\\) avec la méthode du plus proche voisin.",
    "crumbs": [
      "Modules",
      "06 - Non-supervisée",
      "Hierarchique"
    ]
  },
  {
    "objectID": "contents/misc/good-practices-R.html",
    "href": "contents/misc/good-practices-R.html",
    "title": "Bonnes pratiques en R",
    "section": "",
    "text": "Cette page est basée sur un document qu’Aurélien Nicosia (ULaval) a créé en 2023 appelé “Bonnes pratiques de programmation en R”. Celui-ci a été mis à jour.\nR étant “juste” un langage de programmation, il est techniquement possible d’utiliser un simple éditeur de texte pour écrire du R et un terminal pour lancer le code. Il est cependant bien plus commode—en particulier, pour les débutants—d’utiliser un éditeur de code comme RStudio pour lancer son code. En effet, celui-ci permet de lancer son code de façon intéractive, de pouvoir voir son environnement de travail, de tester son code, …\nDe plus, il vaut mieux s’assurer de travailler avec la dernière version de R et des packages dont nous avons besoin. Ainsi, nous risquons moins de rencontrer des bogues et nous pouvons profiter des dernières fonctionnalités. Un point d’attention, cependant, je vous déconseillerais de changer la version de R ou des packages une fois que vous avez commencé à travailler sur quelquechose. En effet, ce changement pourrais introduire des bogues au milieu de l’analyse (il faut donc toujours reporter les versions des packages utilisés pour la reproducibilité). Il est possible d’avoir un résumé de l’environnement de travail avec les fonctions systemInfo() et packageVersion(pkg).\nConcernant la documentation, le package roxygen permet de convertir les commentaires de vos fonctions et packages en une documentation propre.\nUne syntaxe uniforme rend un code beaucoup plus facile à lire et à comprendre. Un guide de style énonce des normes pour avoir une syntaxe uniforme. Le guide de style du tidyverse est recommandé en R. Avant de présenter quelques conventions de style, notons qu’il est possible de modifier rapidement la mise en forme d’un bout de code R dans RStudio dans le menu “Code -&gt; Reformat Selection”.\nRetour à la ligne et indentation\nUne façon simple de rendre som code plus lisible est d’y insérer des retours à la ligne et des indentations appropriés. Par exemple, supposons que nous avons la chaîne de caractère suivante :\n\ntext &lt;- \"Ceci est un example\"\n\nNous souhaitons corriger deux fautes dans cette phrase : le mot “example” écrit en anglais plutôt qu’en français et le point manquant à la fin de la phrase. Ceci peut se faire avec l’instruction :\n\npaste0(gsub(pattern = \"example\", replacement = \"exemple\", x = text), \".\")\n\nCette instruction comporte un appel de fonction imbriqué dans un autre. Elle est bien plus facile à lire comme suit :\n\npaste0(\n  gsub(\n    pattern = \"example\",\n    replacement = \"exemple\",\n    x = text),\n  \".\"\n)\n\nOpérateur d’assignation\nEn R, on utilise &lt;- pour assigner une valeur à une variable et on utilise = pour passer des valeurs à des arguments dans un appel de fonctions.\nConventions de noms\nLe guide de style du tydiverse préconise l’utilisation de lettres minuscules, de nombres et de l’underscore _ pour nommer variables et fonctions. Les underscores sont utilisés pour séparer les mots dans un nom. Bien que l’on puisse trouver d’autres conventions, celles-ci sont à éviter. Dans tous les cas, il est important de choisir une convention et de la respecter. De plus, il est préférable d’éviter les accents dans les noms de variables.\nOrganisation du code\nLorsque le code commence à devenir long, il devient avantageux de le séparer en plusieurs fichiers. Par exemple, on peut avoir un fichier par partie de l’analyse (un pour le nettoyage des données, un pour l’analyse, un pour la visualisation, …). De plus, une analyse de données n’est généralement pas constitué uniquement de code R, e.g. fichiers de code C++, fichiers de données, fichiers du configuration, etc. Il est donc recommandé des créer des sous-dosssiers regroupant les fichiers du même type. Les projets RStudio sont parfaits pour rassembler au même endroit tous les fichiers relatifs au projet. De plus, ils permettent de faciliter le travail sur plusieurs projets simultanément en gérant le passage d’un répertoire de travail à un autre.\nQuelques trucs à faire\n\nRédiger son code dans un script et l’enregistrer fréquemment. Cela permet d’éviter de perdre la trace de certaines instructions importantes parce qu’elles ont été écrites directement dans la console.\nIl est préférable de débuter toute session de travail en R avec un environnement de travail vide. Pour ce faire, il faut désactiver la restauration automatique d’une image de session dans les paramètres. Cela permet d’être conscient de la présence des différents objets dans l’environnement de travail.\nNe pas utiliser la fonction load lorsque l’environnement de travail n’est pas vide. Cela permet de ne pas modifier un objet de l’environnement de travail en l’écrasant.\nNe pas utiliser la fonction attach. Cela permet de ne pas modifier le chemin de recherche des fichiers.\nSauvegarder les options et paramètres graphiques avant de les modifier.\nNe pas utiliser T et F à la place de TRUE et FALSE."
  },
  {
    "objectID": "contents/misc/good-practices-python.html",
    "href": "contents/misc/good-practices-python.html",
    "title": "Bonnes pratiques en Python",
    "section": "",
    "text": "Cette page est inspirée sur ce document.\nDe même que R, Python est “juste” un langage de programmation, il est donc possible d’écrire du code Python dans un éditeur de texte et de lancer ce code via un terminal. Bien que ce soit faisable, il est plus simple d’utilser un éditeur de code. Bien qu’il soit techniquement possible d’utiliser RStudio comme éditeur pour Python, je vous recommanderais dans utiliser spécialiser comme PyCharm. Le format notebook est aussi très populaire en Python. Dans ce cas, je vous conseillerais la librarie marimo qui permet de transformer ses fichiers .py en notebook.\nDe plus, il vaut mieux s’assurer de travailler avec la dernière version stable de Python comptatible avec les packages les utilisés (e.g. numpy, matplotlib, sklearn). En effet, très souvent, il y a un délai pour que les dernières versions des packages soient comptatibles avec la dernière version de Python. Il est donc important de partager la version des packages utilisés avec l’analyse.\nConcernant la documentation, le standard en Python est de suivre les recommendations du PEP 257. La libraries Sphinx permet de générer une documentation à partir des docstring.\nUne syntaxe uniforme rend un code beaucoup plus facile à lire et à comprendre. Un guide de style énonce des normes pour avoir une syntaxe uniforme. Le guide de style PEP 8 est recommandé en Python.\nRetour à la ligne et indentation\nL’indentation fait partie de Python, i.e. les blocks if...else et for sont définis grâce aux indentations. Il est possible d’utiliser un tab ou des espaces. Le choix vous appartient mais il est important d’être consistant dans votre code.\nConvention de noms\nL’utilisation des noms de variables avec un seul caractère est à éviter. Sinon, les variables, fonctions, méthodes, packages et modules sont nommés avec des lettres minuscules, des nombres et l’underscore _. Les classes et exceptions doivent être nommés avec des majuscules pour séparer les mots (UneClasse). Les constants sont en majuscules.\nOrganisation du code\nDe même que pour R, lorsque le code commence à devenir long, il devient avantageux de le séparer en plusieurs fichiers. Par exemple, on peut avoir un fichier par partie de l’analyse (un pour le nettoyage des données, un pour l’analyse, un pour la visualisation, …). On peut aussi créer plusieurs sous-dosssiers.\nQuelques trucs à faire\n\nNe pas faire de comparaison à True, False or None.\n\n\nif attr:\n    print(\"True!\")\n\nif not attr:\n    print(\"False!\")\n\nif attr is None:\n    print(\"None!\")\n\n\nUtiliser la compréhension de liste lorsque cela est possible.\n\n\na = [3, 4, 5]\nb = [i for i in a if i &gt; 4]\n\n\nCharger un fichier avec with. Cela permet d’être sur que la connexion avec le fichier est fermé une fois qu’il a été lu.\n\n\nwith open(\"file.txt\") as f:\n    read(f)\n\n\nUtiliser un maximum de 80 caractères par ligne.\nUtiliser des parenthèses pour aller à la ligne dans les longues chaînes de caractères."
  },
  {
    "objectID": "contents/supervised/02-discriminant.html",
    "href": "contents/supervised/02-discriminant.html",
    "title": "Discriminant",
    "section": "",
    "text": "La méthode a été introduite en 1936 par R. A. Fisher. Il s’intéressait à la taxonimie végétale, c’est-à-dire déterminer l’espèce de fleurs à partir de diverses mesures.\nNotation:\nSoit \\(X = (X_{i j})\\), qui est une matrice de dimension \\(n \\times p\\), où \\(n\\) est le nombre d’individus dans l’échantillon, \\(p\\) est le nombre de variables et \\(X_{i j}\\) est la valeur de la \\(j\\)e variable pour le \\(i\\)e individus.\nIdentification des groupes:\nScore de l’analyse discriminante: on a des observations dans \\(R^p\\). Pour faire de la classification à partir de \\(X_{1}, \\dots, X_p\\), on doit partionner \\(R^p\\) en \\(q\\) sous-ensembles de sorte que chacun des \\(q\\) sous-ensembles est associé à un des \\(q\\) groupes.\nOn va chercher à passer de la dimension \\(p\\) à la dimension \\(1\\) en calculant un score \\(f(x_{1}, \\dots, x_p) \\in \\mathbb{R}\\) pour chaque observation et ensuite utiliser ce score pour déterminer le groupe d’appartenance (et donc partionner \\(R\\)). Le score proposé par Fisher est une combinaison linéaire des variables, c’est-à-dire \\[f(X_{1}, \\dots, X_p) = a^{\\top} X + b = a_{1} X_{1} + \\cdots + a_p X_p + b.\\]\nOn en déduira \\(q\\) intervalles de décision \\(S_{1}, \\dots, S_q\\) associés aux groupes.\nOn voudrait choisir le vecteur \\(a\\) de sorte que les scores soient, à la fois, très différents entre les groupes et très similaires à l’intérieur d’un groupe. On s’intéresse donc à la variabilité des scores à l’intérieur des groupes et entre les groupes.\nÉtant donné \\(a \\in R^p\\), on a: \\[\\mathrm{Var}(f(X_{1}, \\dots, X_p)) = \\mathrm{Var}(a^{\\top} X) = a^{\\top} \\mathrm{Var}(X) a,\\] que nous estimons à partir des \\(n\\) observations par \\[\\widehat{\\mathrm{Var}}(f(X_{1}, \\dots, X_p)) = \\frac{1}{n} a^{\\top} S a.\\]\nLa base de l’analyse discriminante repose sur le fait que \\[S = W + B,\\] où \\(W\\) est la matrice de variance intragroupe et \\(B\\) est la matrice de variance intergroupe.\nOn peut prouver ce résultat en considérant la définition des matrices \\(S, W\\) et \\(B\\). La moyenne de la variable \\(j\\) pour tous les individus de l’échantillon est \\[\\overline{X}_j = \\frac{1}{n}\\sum_{i = 1}^{n} X_{i j}.\\]\nLa moyenne de la variable \\(j\\) pour les individus du groupe \\(k\\) est \\[\\overline{X}_{k j} = \\frac{1}{n_{k}} \\sum_{i \\in I_k} X_{i j}.\\]\nLa somme des carrés totale est \\[s_{j j^\\prime} \\sum_{i = 1}^{n} (X_{i j} - \\overline{X}_j)(X_{i j^\\prime} - \\overline{X}_{j^\\prime}).\\]\nOn tirerait de la matrice \\(S\\) une estimation de \\(\\mathrm{Cov}(X_j, X_{j^\\prime})\\) si toutes les observations provenaient d’un même groupe. On définit \\(s_{j j^\\prime}\\) comme étant \\[s_{j j^\\prime} = w_{j j^\\prime} + b_{j j^\\prime},\\] où \\[w_{j j^\\prime} = \\sum_{k = 1}^{q} \\sum_{i \\in I_k} (X_{i j} - \\overline{X}_{k j})(X_{i j^\\prime} - \\overline{X}_{k j^\\prime}),\\]\n\\[b_{j j^\\prime} = \\sum_{k = 1}^{q} n_k (\\overline{X}_{k j} - \\overline{X}_j)(\\overline{X}_{k j^\\prime} - \\overline{X}_{j^\\prime}).\\]\nPreuve:\nOn obtient \\[\\widehat{\\mathrm{Var}}(a^{\\top} X) = \\frac{1}{n} a^{\\top} S a = \\frac{1}{n} \\left( a^{\\top} W a + a^{\\top} B a \\right).\\]\nOn se rappelle que l’on veut choisir le vecteur \\(a\\) pour que les scores puissent facilement séparer les groupes. En d’autres mots, on veut des scores les plus similaires possible à l’intérieur d’un groupe et des scores les plus différents possible entre les groupes.\nOn propose de choisir le vecteur \\(a in \\mathbb{R}^p\\) pour maximiser \\[\\frac{a^{\\top} B a}{a^{\\top} W a} \\quad\\text{où}\\quad \\frac{a^{\\top} B a}{a^{\\top} S a}.\\] ce vecteur est unique à une constante près.\nCe problème peut être reformuler des faons suivantes:\nEn écrivant la troisième formulation \\[c^{\\top} \\left( S^{-1/2} B S^{-1/2} \\right) c \\quad\\text{s.c.} c^{\\top} c = 1,\\] on peut prendre \\(a = S^{-1/2} c\\), où \\(c\\) est un vecteur propre normé associé à \\(\\lambda_{1}\\) la première valeur propre de \\(S^{-1/2} B S^{-1/2}\\). De faon équivalente, de la deuxième formulation, on peut prendre \\(a\\), un vecteur propre normé associé à \\(\\lambda_{1}\\) la première valeur propre de \\(S^{-1} B\\). Notons que comme \\[S^{-1/2} B S^{-1/2} c = \\lambda c \\quad\\text{et}\\quad a = S^{-1/2} c,\\] alors \\[S^{-1/2} B a = \\lambda S^{1/2} a \\Rightarrow S^{-1} B a = \\lambda a.\\] Les valeurs propres de \\(S^{-1} B\\) et de \\(S^{-1/2} B S^{-1/2}\\) sont donc les mêmes.\nLa fonction discriminante de Fisher est donc \\[f(x) = a^{\\top} (x - \\overline{X}),\\] où \\(a\\) est le vecteur propre normé associé à la plus grande valeur propre de \\(S^{-1} B\\). Les scores \\(U_i = a^{\\top} (X_{i} - \\overline{X})\\) sont les scores linéaires en \\(X_i\\) qui ont le rapport (variance inter) / (variance intra) le plus élevé. On peut aussi prendre \\(U_i = a^{\\top} X_i\\), car ajouter la même constante à toutes les observations \\(i = 1, \\dots, n\\) ne change rien.\nPuisque la matrice \\(S^{-1/2} B S^{-1/2}\\) est symétrique et définie positive, ses valeurs propres sont toutes réelles et positives. De plus, on a que \\(S^{-1} B a - \\lambda_{1} a\\). Ainsi, \\[B a = \\lambda_{1} S a \\Rightarrow a^{\\top} B a = \\lambda_{1} a^{\\top} S a \\Rightarrow \\lambda_{1} = \\frac{a^{\\top} B a}{a^{\\top} S a}.\\]\nOn a donc \\(0 \\leq \\lambda_{1} \\leq 1\\). La valeur propre \\(\\lambda_{1}\\) peut donc être vue comme le pouvoir discriminant de \\(f\\):",
    "crumbs": [
      "Modules",
      "05 - Supervisée",
      "Discriminant"
    ]
  },
  {
    "objectID": "contents/supervised/02-discriminant.html#example",
    "href": "contents/supervised/02-discriminant.html#example",
    "title": "Discriminant",
    "section": "Example",
    "text": "Example",
    "crumbs": [
      "Modules",
      "05 - Supervisée",
      "Discriminant"
    ]
  },
  {
    "objectID": "contents/supervised/03-tree.html",
    "href": "contents/supervised/03-tree.html",
    "title": "Arbres",
    "section": "",
    "text": "Les arbres de régression et de classification (Classification And Regression Trres, CART) font partie des méthodes d’apprentissage supervisée. On dispose d’observations qui appartiennent à \\(\\mathbb{R}^p\\), soit \\(X_{1}, \\dots, X_p\\). Un arbre de classification cherche à assigner une observation à l’un des \\(K\\) groupes sur la base de \\(X_{1}, \\dots, X_p\\). Un arbre de régression cherche à prédire la valeur d’une valeur numérique continue \\(Y\\) à partir de \\(X_{1}, \\dots, X_p\\).\nLa construction d’arbres, on partitionne l’ensemble \\(R^p\\) en hyper-rectangles en effectuant des divisions binaires successives en fonction de la valeur d’une des \\(p\\) variables (algorithme de dédoublements binaires successifs).\n\nOn effectue des divisions binaires successives de l’ensemble \\(R^p\\) en fonction de la valeur d’une variable. Le choix de la variable et le choix de la limite pour la division binaire sont déterminés par un certain critère.\nOn cesse d’effectuer des divisions lorsqu’un critère d’arrêt est rencontré (nombre minimal d’observations par feuille atteint, nombre de feuilles désirées atteint, etc.)\nChaque sous-division finale de l’ensemble \\(\\mathbb{R}^p\\)est appelée “feuille” ou “noeud terminal”. On prédit une catégorie à chaque observation selon la feuille à laquelle elle appartient.\n\nToutes les observations dans une même “feuille” reoivent la même prédiction, soit la classe la plus fréquente parmi les données du jeu d’entrainement qui aboutissent dans cette feuille.\n\n\n\n\n\n\nRemarque\n\n\n\nL’algorithme de partitions binaires successives est un algortihme glouton qui ne nous garantit pas l’arbre optimal…\nSupposons que nous désirions partionner \\(\\mathbb{R}^p\\) en J hyper-rectangles (donc un arbre à \\(J\\) feuilles) et soit \\(c_j\\) un critère de “coût” pour les observations qui sont mal classées dans la région \\(j\\). On aimerait pouvoir trouver les hyper-rectangles \\(R_1, \\dots, R_J\\) tels que \\(\\sum_{j = 1}^{J} c_j\\) soit minimal, mais il n’est pas computationnellement possible de le faire !\n\n\n\nAlgortihme\nPour chaque noeud de l’arbre, on doit décider si on le découpe en deux et si oui, en utilisant quelle valeur de quelle variable :\n\nPour chacune des \\(p\\) variables et pour chaque point de coupure possible pour cette variable, calculer l’amélioration du critère de qualité et choisir la variable et le point de coupure résultant en la meilleur amélioration du critère.\nCréer une division binaire de l’arbre à l’aide de la variable et du point de coupure choisis en 1.\nRépéter 1 et 2 jusqu’à ce que l’arbre ait le nombre de feuilles désiré ou que le nombre minimal d’observations soit atteint dans chaque feuille.\n\n\n\nCritères\nSoit \\(\\widehat{p}_{jk}\\), la proporiton d’observations de la \\(j\\)e région de l’ensemble \\(\\mathbb{R}^p\\) qui appartiennent à la \\(k\\)e classe.\nTrois critères sont habituellement utilisés pour déterminer les divisions optimales à chaque étape de la construction de l’arbre:\n\nTaux d’erreurs de classification \\[E_j = 1 - \\max_k \\widehat{p}_{jk}.\\] Pas assez sensible pour construire l’arbre.\nIndice de Gini \\[G_j = \\sum_{k = 1}^{K} \\widehat{p}_{jk} (1 - \\widehat{p}_{i j}).\\] Plus c’est faible, mieux c’est.\nEntropie croisée \\[D_j = - \\sum_{k = 1}^{K}  \\widehat{p}_{jk} \\log(\\widehat{p}_{m k}).\\] Plus c’est faible, mieux c’est.\n\nLe gain d’information est ce que l’on cherche à maximiser lorque l’on choisit comment scinder en deux un noeud donné. Par example, avec l’indice de Gini, le gain d’information est donné par \\[\\text{indice de Gini avant la division} - \\sum_{j = 1}^{2} \\frac{n_j}{n_{1} + n_{2}} G_j,\\] où \\(j = 1, 2\\) dénote les deux morceaux créés par la division, \\(n_j\\) est le nombre d’observations qui tombent dans le morceau \\(j\\) et \\(G_j\\) est l’indice de Gini pour le morceau \\(j\\).\n\n\nChoix du nombre de divisions/feuilles\nL’algorithme va faire croître l’arbre tant qu’on n’aura pas atteint un nombre de feuilles fixé ou tant que le nombre de d’observations dans chaque feuille ne sera pas trop petit. Mais, pas assez de feuilles veut dire manque d’ajustement car classification trop simpliste et inadéquate. Et trop de feuilles n’est pas mieux, car on fait du sur-ajustement et l’arbre n’aura pas une bonne performance sur un jeu de validation.\nÉlage des arbres de classification (pruning): la stratégie commune en pratique est de laisser croître l’arbre et ensuite de l’élaguer de faon à atteindre un compromis entre ajustement aux données d’entrainement et taille de l’arbre (élagage coût-complexité). Si \\(| T |\\) est la taille (nombre de feuilles) de l’arbre \\(T\\), on veut \\[\\min \\sum_{j = 1}^{|T|} c_j + \\alpha | T |,\\] où \\(\\alpha \\geq 0\\) est un hyper-paramètre qui contrôle le compromis et que l’on chosit par validation croisée.\n\n\nAvantages\n\nFonctionnent aussi bien avec des variables continues que catégorielles.\nAucune hypothèse a priori n’est faite sur la distribution des données.\nRobuste aux données extrêmes.\nFaciles à interpréter.\nTiennent implicitement compte des interactions possibles entre les variables.\nSélectionnent implicitement les variables importantes.\nPermettent d’obtenir un modèle non linéaire.\n\n\n\nPoints faibles\n\nNécessitent un grand nombre de données.\nPeuvent être instables dans les résultats qu’elle produit.\nNe fonctionnent pas très bien lorsque certaines des \\(q\\) classes sont rares ou que certaines des modalités de \\(X_j\\) catégorielles sont rares.\n\n\n\nExample",
    "crumbs": [
      "Modules",
      "05 - Supervisée",
      "Arbres"
    ]
  },
  {
    "objectID": "contents/05-supervisee.html",
    "href": "contents/05-supervisee.html",
    "title": "Supervisée",
    "section": "",
    "text": "On considère une population comportant \\(q\\) groupes. On observe \\(p\\) variables \\(X_{1}, \\dots, X_{p}\\) pour chaque individu/objet de la population. On cherche à obtenir un modèle/algortihme pour classer de nouveaux individus/objets dans les bons groupes, c’est-à-dire de prédire \\(Y\\) à partir de \\(X_{1}, \\dots, X_{p}\\).\n\n\n\n\n\n\nExample\n\n\n\n\nRevenue Québce désire identifier les déclarations fiscales méritant d’être examinées de faon plus approfondies (détection de fraude).\nReconnaissance automatique des chiffres et des lettres des codes postaux écrits à la main.\nIdentification de nouveaux clients potentiels.\nFiltrage de courriels indésirables.\nReconnaissance d’images.\n\n\n\nApproche générale\n\nSélectionner un certain nombre d’individus dont on connaît le groupe d’appartenance.\nMesurer \\(p\\) caractéristiques \\(X_{1}, \\dots, X_{p}\\) sur ces individus.\nDiviser ce jeu de données en deux:\n\n\nUn jeu de données pour la modélisation (entrainement, “train”)\nUn jeu de données pour la vérification (valisation, “test”)\n\n\nDévelopper un modèle/algorithme pour classer le mieux possible les individus du jeu de données d’entrainement.\nÉvaluer notre modèle/algorithme sur le jeu de données de valisation.\n(Répéter étapes 3-4-5 avec d’autres modèles/algorithmes et choisir le meilleur).\n\nQuelques méthodes:\n\nAnalyse discriminante\nArbre de classification\nRégression\nClassificateur naïf de Bayes\nMéthode des \\(k\\) plus proches voisins\nSupport vector machine\nRéseaux de neurones.\n\nIl n’y a aucun algorithme qui garantit le meilleur classificateur pour toute situation donnée. Chaque problème est nouveau et on doit tenter de trouver la meilleure façon de procéder par essai et erreur. Ceci étant dit, certains principes s’appliquent plus généralement * Commencer par une exploration des données (p.ex. statistiques descriptives sur toutes les variables prises individuellement, ACP, ACB/ACM, classification non-supervisée) * Tirer avantage de la connaissance du sujet des experts qui nous entourent * Voir si certaines méthodes n’ont pas déjà eu du succès dans des analyses similaires\nLa principale difficulté vient habituellement de la dimension du problème : le nombre de modèles/méthodes possibles pour un problème donné est énorme et croît rapidement avec le nombre de variables disponibles. Parfois, réduire la dimension du problème (ACP, ACB/ACM, classification non-supervisée) peut aider : on applique ces techniques à un sous-ensemble des variables, et on utilise ensuite les scores produits comme prédicteurs dans les algos de classifications Il n’y a pas de recette générale pour savoir quel sous-ensemble choisir … Allez voir sur des sites de concours d’analyse de données (p.ex. Kaggle, KD Nuggets, etc.) et regardez les approches utilisées par les gagnants des concours pour lesquels le problème à résoudre s’apparente un peu au vôtre.",
    "crumbs": [
      "Modules",
      "05 - Supervisée"
    ]
  },
  {
    "objectID": "contents/generalities/03-distance.html",
    "href": "contents/generalities/03-distance.html",
    "title": "Distances",
    "section": "",
    "text": "Dans tout projet d’analyse de données, il est nécessaire de pouvoir quantifier la ressemblance (ou la dissemblance) entre deux observations. Pour cela, on utilise la notion de distance (ou similarité) entre les observations. Le choix de cette distance influence directement les résultats des algorithmes d’apprentissage, de regroupement et de visualisations.",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Distances"
    ]
  },
  {
    "objectID": "contents/generalities/03-distance.html#notion-de-distance",
    "href": "contents/generalities/03-distance.html#notion-de-distance",
    "title": "Distances",
    "section": "Notion de distance",
    "text": "Notion de distance\nUne distance est une fonction mathématique mesurant à quel point deux objets sont éloigné l’un de l’autre dans un espace donnée. Plus la distance est grande, plus les observations somt éloigné.\n\n\n\n\n\n\nDéfinition de mesure de distance\n\n\n\nUne fonction \\(d: \\mathcal{X} \\times \\mathcal{X} \\to \\mathbb{R}\\) est une distance sur un ensemble \\(\\mathcal{X}\\) si, pour tout \\(x, y, z \\in \\mathcal{X}\\), les conditions suivantes sont vérifiées :\n\nnon-négativité: \\(d(x, y) \\geq 0\\);\nséparation: \\(d(x, y) = 0 \\Leftrightarrow x = y\\);\nsymétrie: \\(d(x, y) = d(y, x)\\);\ninégalité triangulaire: \\(d(x, y) \\leq d(x, z) + d(y, z)\\).\n\n\n\n\n\n\n\n\n\nLa distance euclidienne\n\n\n\nLorsque les observations sont représentées par des vecteurs numériques dans \\(\\mathbb{R}^p\\) de même ordre de grandeur, la distance euclidienne est souvent un bon choix.\nSoit \\(x, y \\in \\mathbb{R}^p\\), la distance euclidienne est données par : \\[d(x, y) = \\left\\| x - y \\right\\|_2 = \\left( \\sum_{i = 1}^{p} (x_i - y_i)^2 \\right)^{1/2}.\\]\n\n\n\n\n\n\n\n\nLa distance \\(L_q\\) (ou de Minkowski)\n\n\n\nSoit \\(x, y \\in \\mathbb{R}^p\\), la distance \\(L_q\\) est donnée, pour \\(q &gt; 0\\), par : \\[d(x, y) = \\left\\| x - y \\right\\|_q = \\left( \\sum_{i = 1}^{p} |x_i - y_i|^q \\right)^{1 / q}.\\]\nCas particuliers:\n\nPour \\(q = 1\\), on obtient la distance de Manhattan : \\[d(x, y) = \\left\\| x - y \\right\\|_1 = \\sum_{i = 1}^{p} |x_i - y_i|.\\]\nPour \\(q = 2\\), on obtient la distance euclidienne.\n\n\n\n\n\n\n\n\n\nExemple\n\n\n\nConsidérons le jeu de données suivant :\n\nTaille et poids moyens au Canada (Source: Statistique Canada, Enquête sur la santé dans les collectivités canadiennes (2008)).\n\n\nNom\nTaille\nPoids\n\n\n\n\nAlice\n162.1\n66.8\n\n\nBob\n175.8\n81.6\n\n\n\nLa distance euclidienne entre Alice et Bob est \\[d(\\text{Alice}, \\text{Bob}) = \\sqrt{(162.1 - 175.8)^2 + (66.8 - 81.6)^2} = 20.16.\\]\nLa distance de Manhattan entre Alice et Bob est \\[d(\\text{Alice}, \\text{Bob}) = |162.1 - 175.8| + |66.8 - 81.6| = 28.5.\\]\n\n\nLa distance \\(L_q\\) n’est pas invariante aux changements d’échelle. Par exemple, si on multiplie toutes les composantes d’un vecteur par un facteur \\(\\lambda\\), la distance entre deux vecteurs change du facteur \\(\\lambda\\).\nEn practique, on préfère travailler avec des variables standardisées. Ainsi, en notant, \\(\\mu_i\\), la moyenne, et \\(\\sigma_i\\), l’écart-type de la variable \\(i\\), la distance euclidienne avec des variables standardisées est donnée par : \\[d(x, y) = \\sum_{i = 1}^{p} \\left\\{ \\frac{x_i - \\mu_i}{\\sigma_i} - \\frac{y_i - \\mu_i}{\\sigma_i} \\right\\}^2 = \\sum_{i = 1}^{p} \\left( \\frac{x_i - y_i}{\\sigma_i} \\right)^2.\\]\n\n\n\n\n\n\nPropriété\n\n\n\nLa distance euclidienne avec des variables standardisées est invariante par changement d’échelle.\n\n\n\n\n\n\n\n\nPreuve\n\n\n\n\n\nSoit \\(\\lambda \\neq 0\\) et soit \\(X\\) une variable aléatoire. On a \\(\\mathbb{E}(\\lambda X) = \\lambda \\mathbb{E}(X)\\) et \\(\\mathrm{Var}(\\lambda X) = \\lambda^2 \\mathrm{Var}(X)\\). Donc\n\\[d(\\lambda x, \\lambda y) = \\sum_{i = 1}^{p} \\left\\{ \\frac{\\lambda x_i - \\lambda \\mu_i}{\\lambda \\sigma_i} - \\frac{\\lambda y_i - \\lambda \\mu_i}{\\lambda \\sigma_i} \\right\\}^2 = \\sum_{i = 1}^{p} \\left( \\frac{x_i - y_i}{\\sigma_i} \\right)^2 = d(x, y).\\]",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Distances"
    ]
  },
  {
    "objectID": "contents/generalities/03-distance.html#notion-de-similarité",
    "href": "contents/generalities/03-distance.html#notion-de-similarité",
    "title": "Distances",
    "section": "Notion de similarité",
    "text": "Notion de similarité\nÀ l’opposé de la notion de distance, une mesure de similarité quantifie à quel point deux observations sont proches dans un espace donné. Ainsi, plus la similarité est grande, plus les observations sont proches.\n\n\n\n\n\n\nDéfinition de mesure de similarité\n\n\n\nUne fonction \\(s: \\mathcal{X} \\times \\mathcal{X} \\to \\mathbb{R}\\) est une mesure de similarité sur un ensemble \\(\\mathcal{X}\\) si, pour tout \\(x, y \\in \\mathcal{X}\\), les conditions suivantes sont vérifiées :\n\n\\(s(x, y) \\geq 0\\);\n\\(s(x, y) = s(y, x)\\);\n\\(s(x, x) = 1 \\geq s(x, y)\\).\n\n\n\nUne distance peut se transformer en similarité en posant \\[s(x, y) = \\frac{1}{1 + d(x, y)}.\\]\nCette transformation garantit que plus la distance est grande, plus la similarité est faible. Toutefois, l’inverse n’est pas toujours possible car une mesure de similarité ne respecte pas forcément l’inégalité triangulaire. On peut aussi définir la dissemblance entre deux objets: \\[d^\\star(x, y) = 1 - s(x, y).\\]",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Distances"
    ]
  },
  {
    "objectID": "contents/generalities/03-distance.html#cas-de-variables-qualitatives",
    "href": "contents/generalities/03-distance.html#cas-de-variables-qualitatives",
    "title": "Distances",
    "section": "Cas de variables qualitatives",
    "text": "Cas de variables qualitatives\nLorsque l’on travaille avec des variables qualitatives, les distances numériques habituelles (comme les distances \\(L_p\\)) n’ont généralement pas de sens. Par exemple, si une variable prend ses valeurs dans l’ensemble \\[\\mathcal{X} = \\{ \\text{Rouge}, \\text{Vert}, \\text{Bleu} \\},\\] alors il n’y a pas de sens à calculer la différence entre \\(\\text{Bleu}\\) et \\(\\text{Rouge}\\), car ces modalités ne portent aucune structure numérique intrinsèque et n’ont aucune notion d’ordre ou d’écart.\nUne mauvaise pratique consisterait à attribuer arbitrairement des valeurs numériques aux momdalités (e.g. \\(\\text{Rouge} = 1\\), \\(\\text{Vert} = 2\\), \\(\\text{Bleu} = 3\\)) ce qui introduirait un ordre artificiel entre elles. Cela risquerait de biaiser fortement les analyses.\n\nEncodage \\(1\\) parmi \\(K\\)\nLorsque l’on veut utiliser un modèle se basant sur une notion de distance entre les observations (i.e. la plupart des modèles), on doit utiliser un encodage adapté. L’encodage \\(1\\) parmi \\(K\\) (one-hot encoding) consiste à encoder une variable qualitative à \\(K\\) modalités sous la forme d’un vecteur binaire de dimension \\(K\\), dans lequel une seule entrée est à \\(1\\), les autres à \\(0\\). Ainsi, pour l’exemple de \\(\\mathcal{X} = \\{ \\text{Rouge, Vert, Bleu} \\}\\), on obtiendra l’encodage suivant: “Rouge” donne \\((1, 0, 0)\\), “Vert” donne \\((0, 1, 0)\\) et “Bleu” donne \\((0, 0, 1)\\).\nCette méthode d’encodage a l’avantage de ne pas introduire d’ordre artificiel entre les modalités. Cependant, si la variable a beaucoup de modalités, l’espace de représentation sera de grande dimension, ce qui peut nuire à l’efficacité de certaines méthodes d’analyse.\n\n\nDéfinir une distance adaptée\nUne fois les modalités encodées, on peut définir une distance entre deux observations de variables qualitatives.\n\n\n\n\n\n\nLa distance discrète (ou distance de Hamming)\n\n\n\nSoit \\(\\mathcal{X}\\) un ensemble discret et soient \\(x\\) et \\(y\\) deux observations de \\(X\\), la distance discrète est donnée par \\[d(x, y) = \\begin{cases}\n  0, & \\text{si } x = y,\\\\\n  1, & \\text{si } x \\neq y\n\\end{cases}.\\]\n\n\nPour des vecteurs de variables qualitatives (e.g. la comparaison de plusieurs individus décrits par plusieurs caractéristiques), la distance discrète est la somme des désaccords entre les composantes : \\[d(x, y) = \\sum_{i = 1}^{p} \\mathbb{1}(x_i \\neq y_i),\\] où \\(p\\) est le nombre de variables.\n\n\n\n\n\n\nExemple\n\n\n\nPrenons les caractéristiques de trois personnes.\n\n\n\nTable 1: Caractéristiques de trois personnes.\n\n\n\n\n\nNom\nCouleur\nYeux\nCheveux\n\n\n\n\nAlice\nRouge\nBleu\nBlond\n\n\nBob\nVert\nBleu\nRoux\n\n\nChris\nRouge\nVert\nBlond\n\n\n\n\n\n\nOn calcule la distance entre deux personnes comme le nombre de caractéristiques différentes. Ainsi,\n\\[d(\\text{Alice}, \\text{Bob}) = 1 + 0 + 1 = 2,\\]\n\\[d(\\text{Alice}, \\text{Chris}) = 0 + 1 + 0 = 1,\\]\n\\[d(\\text{Bob}, \\text{Chris}) = 1 + 1 + 1 = 3.\\]\n\n\nPlutôt que de compter les différences, on peut aussi compter les accords et les normaliser :\n\\[s(x, y) = \\frac{1}{p}\\sum_{i = 1}^{p} \\mathbb{1}(x_i = y_i),\\]\nce qui donne une mesure de similarité comprise entre \\(0\\) (aucun accord) et \\(1\\) (identique).\n\n\n\n\n\n\nExemple\n\n\n\nEn reprenant l’exemple précédent (cf. Table 1), on trouve les similarités suivantes :\n\\[s(\\text{Alice}, \\text{Bob}) = \\frac{0 + 1 + 0}{3} = \\frac{1}{3},\\]\n\\[s(\\text{Alice}, \\text{Chris}) = \\frac{1 + 0 + 1}{3} = \\frac{2}{3},\\]\n\\[s(\\text{Bob}, \\text{Chris}) = \\frac{0 + 0 + 0}{3} = 0.\\]\n\n\n\n\nDistance de Jaccard\nLorsque le nombre de variables binaires est grand (e.g. dans le cas où un encodage \\(1\\) parmi \\(K\\) a été fait sur \\(p\\) variables qualitatives), la distance discrète n’est pas forcément très adaptée car le nombre d’accords risque d’être petit par rapport au nombre total de variables (\\(K \\times p\\) dans l’exemple précédent), ce qui va donner de petites distances dans tous les cas. Une des solutions est de se concentrer uniquement sur les attributs qui valent \\(1\\), car généralement, une variable binaire à \\(0\\) n’apporte pas spécialement d’information (en tout cas, moins qu’une variable binaire à \\(1\\)). L’indice de Jaccard (Intersection over Union, IoU) a été introduit pour prendre cela en compte.\n\n\n\n\n\n\nDéfinition : Indice de Jaccard\n\n\n\nConsidérons deux observations \\(x\\) et \\(y\\) de \\(K\\) variables binaires. Toutes les variables peuvent prendre les valeurs \\(0\\) et \\(1\\).\nDéfinissons les quantités suivantes :\n\n\\(M_{11}\\), le nombre de variables à \\(1\\) pour \\(x\\) et \\(y\\);\n\\(M_{10}\\), le nombre de variables à \\(1\\) pour \\(x\\) et \\(0\\) pour \\(y\\);\n\\(M_{01}\\), le nombre de variables à \\(0\\) pour \\(x\\) et \\(1\\) pour \\(y\\);\n\\(M_{00}\\), le nombre de variables à \\(0\\) pour \\(x\\) et \\(y\\).\n\nChaque variable binaire étant forcément comptée, soit dans \\(M_{11}\\), soit dans \\(M_{10}\\), soit dans \\(M_{01}\\), soit dans \\(M_{00}\\), leur somme est donc égale à \\(K\\).\nL’indice de Jaccard est défini comme \\[J(x, y) = \\frac{M_{11}}{M_{10} + M_{01} + M_{11}} = \\frac{M_{11}}{K - M_{00}}.\\]\n\n\nEn faisant attention au cas où les deux observations ne sont constituées que de \\(0\\) (on prend \\(J(x, y) = 1\\) dans ce cas), l’indice de Jaccard est une mesure de similarité.\n\n\n\n\n\n\nPropriété : Distance de Jaccard\n\n\n\nPour deux observations \\(x\\) et \\(y\\) de \\(K\\) variables binaires, la distance de Jaccard est donnée par \\[d(x, y) = 1 - J(x, y).\\]\n\n\n\n\n\n\n\n\nPreuve\n\n\n\n\n\nPour montrer que la distance de Jaccard est bien une distance, on doit montrer les quatres propriétés des distances. Notons d’abord que la distance de Jaccard peut se réécrire comme \\[d(x, y) = \\frac{M_{10} + M_{01}}{M_{01} + M_{10} + M_{11}}.\\]\n\nTous les termes au numérateur et au dénominateur sont positifs, donc \\(d(x, y) \\geq 0\\).\nMontrons que \\(d(x, y) = 0 \\Leftrightarrow x = y\\).\n\nSupposons que \\(d(x, y) = 0\\). Alors \\(M_{01} + M_{10} = 0\\). Donc, il n’y a pas de variables qui valent \\(0\\) pour \\(x\\) et \\(1\\) pour \\(y\\) et inversement. Comme \\(M_{01} + M_{10} + M_{11} &gt; 0\\), on a \\(x = y\\).\nMaintenant, supposons que \\(x = y\\). Alors \\(M_{01} = M_{10} = 0\\). Donc \\(d(x, y) = 0\\).\n\nOn a que \\(d(x, y) = d(y, x)\\) car l’indice de Jaccard est symétrique.\nLa preuve de l’inégalité triangulaire sera faite en exercice (cf. TD))\n\n\n\n\n\n\n\n\n\n\nExemple\n\n\n\nPrenons un questionnaire de \\(5\\) questions fermées. Supposons que la réponse “Oui” soit encodée par \\(1\\) et la réponse “Non” soit encodée par \\(0\\).\n\n\n\nTable 2: Caractéristiques de deux personnes.\n\n\n\n\n\nNom\nQ1\nQ2\nQ3\nQ4\nQ5\n\n\n\n\nAlice\n1\n0\n1\n0\n0\n\n\nBob\n1\n0\n0\n1\n0\n\n\n\n\n\n\nPour la distance entre Alice et Bob, on a \\(M_{11} = 1\\), \\(M_{10} = 1\\), \\(M_{01} = 1\\) et \\(M_{00} = 2\\). Donc, la similarité de Jaccard est donnée par \\(J(\\text{Alice}, \\text{Bob}) = \\frac{1}{3}\\). Ainsi, la distance de Jaccard est \\(d(\\text{Alice}, \\text{Bob}) = 1 - J(x, y) = \\frac{2}{3}\\).",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Distances"
    ]
  },
  {
    "objectID": "contents/generalities/01-stat.html",
    "href": "contents/generalities/01-stat.html",
    "title": "Projet d’analyse de données",
    "section": "",
    "text": "On présente ici les différentes étapes d’un projet d’analyse de données.",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Projet d'analyse de données"
    ]
  },
  {
    "objectID": "contents/generalities/01-stat.html#projet-danalyse-données",
    "href": "contents/generalities/01-stat.html#projet-danalyse-données",
    "title": "Projet d’analyse de données",
    "section": "Projet d’analyse données",
    "text": "Projet d’analyse données\nUn projet d’analyse de données suit généralement une structure bien définie en plusieurs étapes. Nous en dégagons ici cinq principales, chacune avec ses objectifs, ses enjeux et son importance relative dans le succès du projet :\n\nDéfinition des objectifs\nCollecte et préparation des données\nÉlaboration et validation des modèles\nImplémentation et mise en production\nSuivi de la performance et amélioration continue\n\nLors de la planification d’un projet, il faut prendre en compte que chaque étape à une importance différente, mais aussi que chacune ne prend pas le même temps d’exécution. Pyle (1999) donne une estimation du temps de chaque étape, ainsi que de leur importance dans la réussite du projet (donné en pourcentage du total, cf. Table 1).\n\n\n\nTable 1: Découpage d’un projet d’analyse des données.\n\n\n\n\n\nÉtape\nTemps\nImportance\n\n\n\n\nComprendre le problème\n\\(10\\%\\)\n\\(15\\%\\)\n\n\nExplorer la solution\n\\(9\\%\\)\n\\(14\\%\\)\n\n\nImplementer la solution\n\\(1\\%\\)\n\\(51\\%\\)\n\n\nPréparer les données\n\\(60\\%\\)\n\\(15\\%\\)\n\n\nAnalyser les données\n\\(15\\%\\)\n\\(3\\%\\)\n\n\nModéliser les données\n\\(5\\%\\)\n\\(2\\%\\)\n\n\n\n\n\n\nOn remarque deux faits importants. L’importance d’une étape n’est pas proportionnelle au temps passé dessus. Par exemple, l’implémentation de la solution est une étape essentielle (sinon il n’y a pas de résultat), mais peut n’exiger que peu de temps (parfois quelques lignes de code). À l’inverse, la préparation des données, souvent sous-estimée, est généralement chronophage, notamment pour gérer les données manquantes, les données aberrantes, ou encore les éventuels accents pour des données en français.",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Projet d'analyse de données"
    ]
  },
  {
    "objectID": "contents/generalities/01-stat.html#définition-des-objectifs",
    "href": "contents/generalities/01-stat.html#définition-des-objectifs",
    "title": "Projet d’analyse de données",
    "section": "Définition des objectifs",
    "text": "Définition des objectifs\nToute analyse commence par une question claire : que cherche-t-on à accomplir ? Visualiser des données ? Tester une hypothèse ? Prédire un comportement ? Segmenter une population ? Une définition précise des objectifs est essentielle pour orienter les étapes suivantes. Cela permet de guider la collecte et la structuration des données. Cela permet de définir un modèle adéquat (e.g. classification, régression, …). Cela permet de faciliter l’interprétation et la communication des résultats. Cette phase évite aussi les explorations aveugles et les interprétations biaisées.\nComment fait-on en pratique pour formuler un bon objectif ? On pose des questions ! Tout d’abord, il faut clarifier les termes. Qui va utiliser le modèle et comment ? Quelle est la population cible ? Quelle décision dépendra résultats ?\n\n\n\n\n\n\nExemple\n\n\n\nLa Banque National du Canada voudrait lancer un nouveau produit d’épargne et vous donne accès à sa base de données clients.\nMauvais objectif: Analyser les données de la base clients.\nMeilleur objectif: Peut-on prédire quels clients sont susceptibles d’acheter ce nouveau produit d’épargne ?\n\n\n\n\n\n\n\n\nExemple\n\n\n\nL’équipe de hockey des Canadiens de Montréal souhaite mieux connaître ses adversaires pour développer de nouvelles tactiques de jeu.\nMauvais objectif: Analyser les données des adversaires.\nMeilleur objectif: Peut-on caractériser le style de jeu des adversaires pour identifier leurs faiblesses ?\n\n\n\n\n\n\n\n\nExemple\n\n\n\nPharmascience souhaite évaluer l’efficacité d’un nouveau médicament.\nMauvais objectif: Analyser les données du médicament.\nMeilleur objectif: Peut-on concevoir un protocole statistique permettant de tester l’efficacité du médicament ?",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Projet d'analyse de données"
    ]
  },
  {
    "objectID": "contents/generalities/01-stat.html#données",
    "href": "contents/generalities/01-stat.html#données",
    "title": "Projet d’analyse de données",
    "section": "Données",
    "text": "Données\nLes données sont le coeur du sujet. Pour être utile, les données doivent être disponibles et de bonnes qualités. Une fois les objectifs définis, on effectue une traitement préliminaire et une exploration basique des données pour ensuite aller vers des modèles plus développés.\n\nOù trouver des données ?\nRéponse simple : Internet ! Voici une liste de sites (non-exhaustives) qui regroupent des jeux de données :\n\nGoogle datasets;\nKaggle;\nUC Irvine Machine Learning Repository;\nTime Series Machine Learning website;\nPhysionet Database.\n\nOn peut aussi regarder les sites officiels de sources de données que l’on peut trouver pour une grande partie des pays du monde :\n\nCanada: StatCan;\nFrance: data.gouv.fr;\nUSA: data.gov;\nAngleterre: data.gouv.uk;\netc.\n\nPour des données sur des sujets plus spécifiques, les agences gouvernementales sont souvent de bonnes ressources. Par exemple, le Centre Canadien de cartographie et d’observation de la terre fournit les données géospatiales du Canada (ici).\nLorsque que l’on travaille pour une entreprise, on a généralement accès aux sources de données internes, e.g. base de données sur la production, les clients et les employés, les listes de transactions et de clients potentiels, des informations sur les visites web, etc.\n\n\nQualité\nIl y a un dicton populaire en informatique, s’appliquant aussi en analyse de données: “Garbage in, garbage out”. Même le meilleur modèle ne peut compenser des données biaisées, incomplètes ou erronées.\nPour nous assurer de la qualité des données, on pourra se poser les questions suivantes :\n\nLes données sont-elles représentatives de la population cible ?\nSont-elles exactes, complètes, pertinentes ?\nY a-t-il des valeurs manquantes, des doublons, des incohérences ?\n\n\n\nConstitution de la base de données\nUne fois nos données collectées, il faut les charger en mémoire pour ensuite pouvoir faire des analyses. En Python, les librairies pandas et polars permettent de lire la plupart des formats de fichiers auxquels nous aurons affaire. En ce qui concerne R, plusieurs packages sont utilisés selon le format (cf. Table 2).\n\n\n\nTable 2: Différentes libraries pour différents formats de fichiers.\n\n\n\n\n\nFormat\nExtension\nLibrarie\n\n\n\n\nTexte\n.txt; .csv\nreadr\n\n\nExcel\n.xlsx\nreadxl\n\n\nSAS\n.sas7bdat\nhaven\n\n\nSPSS\n.sav; .zsav\nhaven\n\n\nJSON\n.json\njsonlite\n\n\n\n\n\n\nDepuis une dizaine d’année, le concept de “tidy data” a emergé (cf. Wickham (2014)). Chaque jeu de données “tidy” respecte trois principes:\n\nChaque variable est une colonne du tableau.\nChaque observation est une ligne du tableau.\nChaque cellule du tableau contient une valeur unique.\n\nCela permet d’avoir une approche unifiée pour l’analyse de données. De manière général, on essaiera toujours de mettre son jeu de données sous format “tidy”. Le package tidyr en R et les librairies pandas et polars en Python permettent de mettre en forme les données en format “tidy”.\n\n\nExploration et traitement préliminaire\nUne fois les données chargées et mise sous le format “tidy”, une phase d’exploration préliminaire est nécessaire avant l’étape de modélisation. Cette étape, bien que souvent négligée, est très importante, mais elle n’est pas le coeur de ce cours. Cette étape permet de détecter les problèmes potentiels, de mieux comprendre la structure des données et d’orienter les choix méthodologiques. Voici quelques trucs à faire concernant cette première exploration:\n\nNettoyage de données: supprimer les doublons, uniformiser les modalités, vérifier le format des valeurs spéciales, etc.\nExploration des données: identification des modalités rares ou trop nombreuses, analyse des éventuelles asymétries, détection des classes déséquilibrées, identification des valeurs extrêmes ou aberrantes, recherche des corrélations fortes entre les variables, évaluation des valeurs manquantes.",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Projet d'analyse de données"
    ]
  },
  {
    "objectID": "contents/generalities/01-stat.html#élaboration-et-validation-des-modèles",
    "href": "contents/generalities/01-stat.html#élaboration-et-validation-des-modèles",
    "title": "Projet d’analyse de données",
    "section": "Élaboration et validation des modèles",
    "text": "Élaboration et validation des modèles\nCe cours concerne l’élaboration et la validation de modèles. Pour l’instant, on peut retenir quatre composantes principales :\n\nUn espace (mathématique) de représentation: il s’agit du cadre mathématique dans lequel on travaille.\nUne distance (ou similarité): elle permet de comparer les observations entre elles.\nUn modèle (ou algorithme): c’est la méthode utilisée pour apprendre à partir des données.\nUne fonction de coût: elle mesure la qualité du modèle.\n\nCes éléments seront étudiés en détails dans les sections suivantes du cours.",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Projet d'analyse de données"
    ]
  },
  {
    "objectID": "contents/generalities/01-stat.html#mise-en-oeuvre",
    "href": "contents/generalities/01-stat.html#mise-en-oeuvre",
    "title": "Projet d’analyse de données",
    "section": "Mise en oeuvre",
    "text": "Mise en oeuvre\nUne fois le modèle choisi et validé, il peut être déployé en production. La mise en production signifie le rendre opérationnel dans un environnement réel, souvent en automatisant l’ensemble du processus de traitement des données. Généralement, cela consiste à automatiser la collecte, le nettoyage et la transformation des données, à intégrer le modèle créé dans une application ou un système décisionnel, et à générer des rapports ou des prédictions en temps réel ou à intervalles réguliers. Cette partie est le domaine du data engineering. Un data engineer conçoit et maintient la pipeline de traitement depuis la source des données jusqu’à la sortie du modèle.",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Projet d'analyse de données"
    ]
  },
  {
    "objectID": "contents/generalities/01-stat.html#suivi-de-la-performance-et-amélioration",
    "href": "contents/generalities/01-stat.html#suivi-de-la-performance-et-amélioration",
    "title": "Projet d’analyse de données",
    "section": "Suivi de la performance et amélioration",
    "text": "Suivi de la performance et amélioration\nFinalement, une fois que le modèle est mis en production, il faut assurer un suivi de sa performance dans le temps. En effet, les données évoluent, de même que les comportements qu’elles décrivent. Ainsi, les distributions des données peuvent changer (un phénomène appelé data drift), les hypothèses initiales peuvent ne plus être valides ou encore de nouvelles données ou de nouvelles variables peuvent améliorer la performance. Pour surveiller la performance du modèle, on peut faire un monitoring régulier des performances. On peut aussi réentraîner le modèle avec des données récentes ou l’améliorer en intégrant de nouvelles hypothèses.\nUn bon modèle n’est donc pas seulement performant à un instant donné, il est aussi robuste et adaptable dans le temps.",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Projet d'analyse de données"
    ]
  },
  {
    "objectID": "contents/generalities/04-bias-variance.html",
    "href": "contents/generalities/04-bias-variance.html",
    "title": "Biais/Variance",
    "section": "",
    "text": "Cette section est basée sur James et al. (2021), chapitre 2.",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Biais/Variance"
    ]
  },
  {
    "objectID": "contents/generalities/04-bias-variance.html#quel-est-notre-objectif",
    "href": "contents/generalities/04-bias-variance.html#quel-est-notre-objectif",
    "title": "Biais/Variance",
    "section": "Quel est notre objectif ?",
    "text": "Quel est notre objectif ?\nNous souhaitons modéliser la relation entre une variable réponse \\(Y\\), pouvant être quantitative, qualitative ou de nature différente, et un ensemble de \\(p\\) variables explicatives \\(X = (X_{1}, \\dots, X_{p})\\), elles aussi de (potentiellement) différents types. L’idée centrale est qu’il existe un relation entre \\(Y\\) et les variables explicatives \\(X\\). De manière générales, nous modélisons cette relation par le modèle :\n\\[Y = f(X) + \\varepsilon. \\tag{1}\\]\nIci, \\(f\\) est une fonction déterministe (non-aléatoire) représentant l’information systématique que les variables explicatives \\(X_{1}, \\dots, X_{p}\\) apportent sur \\(Y\\), et \\(\\varepsilon\\) est un terme d’erreur aléatoire, modélisant les variations de \\(Y\\) non expliquées par \\(X\\). Dans le cadre de ce cours, nous ferons les hypothèses suivantes : la variable aléatoire \\(\\varepsilon\\) est indépendente de des variables explicatives \\(X\\), \\(\\mathbb{E}[\\varepsilon] = 0\\) et \\(\\mathrm{Var}(\\varepsilon) = \\sigma^2\\). Le modèle Équation 1 est général. Il sert de cadre pour l’ensemble des méthodes que nous allons étudier, même lorsque la forme explicite de \\(f\\) n’est pas connue.\nLa Figure 1 illustre les différents éléments du modèle: les données observées \\((X_i, Y_i)\\), la fonction \\(f\\) (en bleu) et les écarts aléatoires \\(\\varepsilon_i\\) représentés par des lignes pointillées.\n\n\nCode\nlibrary(tibble)\nlibrary(dplyr)\n\ngenerate_noisy_data &lt;- function(n = 100, noise_levels = c(0, 0.1, 0.3, 0.5)) {\n  # x values (avoid 0 for log)\n  x_vals &lt;- seq(0.01, 0.99, length.out = n)\n  \n  # True function\n  f &lt;- function(x) 4 * x * (1 - x) * log(x) + 2\n  \n  # Generate data for each noise level\n  data &lt;- lapply(noise_levels, function(sigma) {\n    y_true &lt;- f(x_vals)\n    y_noisy &lt;- y_true + rnorm(n, mean = 0, sd = sqrt(sigma))\n    \n    tibble(\n      x = x_vals,\n      y = y_noisy,\n      noise = sigma\n    )\n  }) %&gt;% bind_rows()\n  \n  return(data)\n}\n\n# Example usage\nset.seed(123)\n\nnoise_levels &lt;- seq(0, 0.5, by=0.01)\ndf &lt;- generate_noisy_data(noise_levels = noise_levels)\nwrite.csv(df, './data.csv')\n\n\n\n\nCode\ndata = FileAttachment(\"../../include/data/data.csv\").csv({ typed: true })\n\nviewof noise = Inputs.range(\n  [0.01, 0.5], \n  {value: 0.25, step: 0.01, label: tex`\\sigma^2`}\n)\n\nfiltered = data.filter(function(df) {\n  return df.noise == noise;\n})\n\ntrue_curve = data.filter(function(df) {\n  return df.noise == 0;\n})\n\nerrors = filtered.map(f =&gt; {\n  const location = true_curve.find(loc =&gt; loc.x === f.x);\n  return { ...f, y_end: location?.y };\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot({\n  grid: true,\n  x: {\n    domain: [0, 1],\n    label: \"X\",\n  },\n  y: {\n    domain: [0, 3],\n    label: \"Y\",\n  },\n  marks: [\n    Plot.dot(filtered, {x: \"x\", y: \"y\", fill: \"#444444\", r: 3}),\n    Plot.line(true_curve, {x: \"x\", y: \"y\", stroke: \"#B0E1FA\", strokeWidth: 5}),\n    Plot.link(errors, {\n      x1: \"x\",\n      x2: \"x\",\n      y1: \"y\",\n      y2: \"y_end\",\n      stroke: \"#AAAAAA\",\n      strokeDasharray: \"5,5\",\n    })\n  ]\n})\n\n\n\n\n\n\n\n\n\nFigure 1: Les différents éléments du modèle. Les points représentent les données observées \\((X_i, Y_i)\\). La courbe bleue représente la fonction \\(f\\) et les lignes pointillées représentent l’erreur associée à chaque observation.\n\n\n\n\nDans la suite du cours, nous verrons différentes méthodes permettant d’estimer la fonction \\(f\\) à partir de données. Cependant avant d’étudier comment contruire un estimateur \\(\\widehat{f}\\) de \\(f\\), nous allons nous interroger sur la qualité d’un tel estimateur : que signifie “bien estimer” \\(f\\) ? Et comment évaluer la qualité de l’estimation ?\n\n\n\n\n\n\nExemple : Régression linéaire simple\n\n\n\nDans ce cadre très simple, nous faisons l’hypothèse que la fonction \\(f\\) est de la forme : \\(f(x) = a x + b\\). Dans ce cas, l’estimation de la fonction \\(f\\) se résume à l’estimation des coefficients \\(a\\) et \\(b\\).\n\n\n\n\n\n\n\n\nRemarque : Compromis entre exactitude et interprétabilité\n\n\n\nDépendant de l’objectif de l’étude, nous devons généralement faire un choix entre l’exactitude de nos prédictions et l’interprétabilité de notre modèle. Un modèle simple, comme la régression linéaire, sera facile à interpréter mais capturera mal des relations complexes. À l’inverse, un modèle plus flexible, comme une forêt aléatoire, aura de meilleur prédiction, mais sera plus difficilement interprétable. Le choix dépend donc de l’objectif de l’analyse : compréhension ou performance prédictive ?\n\n\n\n\n\n\n\n\nRemarque : No free lunch in statistics\n\n\n\nPourquoi ne pas simplement utiliser le modèle “ultime”, celui qui serait toujours optimal quelque soit le jeu de données ? Parce qu’un tel modèle n’existe pas ! Il n’y a pas de méthode universellement meilleure pour tous les jeux de données et tous les objectifs. Une méthode performante dans un contexte donné peut échouer ailleurs. Il faut donc toujours adapter l’approche au problème (explication, prédiction, classification, …).",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Biais/Variance"
    ]
  },
  {
    "objectID": "contents/generalities/04-bias-variance.html#comment-mesurer-la-qualité-dun-estimateur",
    "href": "contents/generalities/04-bias-variance.html#comment-mesurer-la-qualité-dun-estimateur",
    "title": "Biais/Variance",
    "section": "Comment mesurer la qualité d’un estimateur ?",
    "text": "Comment mesurer la qualité d’un estimateur ?\nUne fois que nous disposons d’un estimateur \\(\\widehat{f}\\) de la fonction \\(f\\), obtenu à partir de \\(n\\) observations \\((y_1, x_1), \\dots, (y_n, x_n)\\), nous cherchons à évaluer la précision des prédictions \\(\\widehat{Y} = \\widehat{f}(X)\\). L’idée est de vérifier dans quelle mesure \\(\\widehat{Y}\\) est proche de la vraie valeur de \\(Y\\).\n\n\n\n\n\n\nDéfinition : Erreur quadratique moyenne\n\n\n\nLorsque \\(Y\\) est une variable quantitative, une mesure classique de la qualité de \\(\\widehat{f}\\) est l’erreur quadratique moyenne (mean square error, MSE) : \\[MSE(Y, \\widehat{Y}) = \\frac{1}{n} \\sum_{i = 1}^{n} \\left( y_i - \\widehat{y}_i\\right)^2 = \\frac{1}{n} \\sum_{i = 1}^{n} \\left( y_i - \\widehat{f}(x_i) \\right)^2,\\] où \\(\\widehat{y}_i = \\widehat{f}(x_i)\\) est la prédiction que \\(\\widehat{f}\\) donne pour l’observation \\(x_i\\).\n\n\nUne MSE faible indique que les prédictions sont proches des observations. Nous pouvons aussi l’interpréter comme la distance moyenne entre les valeurs observées et les valeurs prédites. Nous cherchons donc à avoir une distance moyenne faible.\nDans le cas où \\(Y\\) est une variable qualitative, e.g. une classe ou un label, on utilise une autre mesure : le taux d’erreur.\n\n\n\n\n\n\nDéfinition: Taux d’erreur\n\n\n\nLorsque \\(Y\\) est une variable qualitative, une mesure classique de la qualité de \\(\\widehat{f}\\) est le taux d’erreur (error rate, ER) : \\[ER(Y, \\widehat{Y}) = \\frac{1}{n} \\sum_{i = 1}^{n} \\mathbb{1}(y_i \\neq \\widehat{y}_i) = \\frac{1}{n} \\sum_{i = 1}^{n} \\mathbb{1}(y_i \\neq \\widehat{f}(x_i)).\\] où \\(\\widehat{y}_i = \\widehat{f}(x_i)\\) est la prédiction que \\(\\widehat{f}\\) donne pour l’observation \\(x_i\\).\n\n\nLe taux d’erreur mesure la proportion de mauvaises prédictions. Il s’agit, là encore, d’une mesure de la distance moyenne entre \\(Y\\) et \\(\\widehat{Y}\\), adaptée aux variables qualititatives.",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Biais/Variance"
    ]
  },
  {
    "objectID": "contents/generalities/04-bias-variance.html#le-compromis-biaisvariance",
    "href": "contents/generalities/04-bias-variance.html#le-compromis-biaisvariance",
    "title": "Biais/Variance",
    "section": "Le compromis biais/variance",
    "text": "Le compromis biais/variance\nNotre objectif est souvent de minimiser l’erreur de prédiction, non seulement sur les données observées, mais surtout sur de nouvelles données (récupérée après avoir estimer le modèle). Pour cela, nous nous intéressons à l’erreur de prédiction : \\[\\mathbb{E}\\left[ \\left( Y - \\widehat{Y} \\right)^2 \\right] = \\mathbb{E}\\left[ \\left( Y - \\widehat{f}(X) \\right)^2 \\right].\\]\nCette erreur peut se décomposer en trois composantes :\n\nLe biais : l’erreur due à une approximation systématique, e.g. si on impose un modèle linéaire alors que la relation est non linéaire.\nLa variance : la sensibilité de l’estimateur aux fluctuations de l’échantillon d’apprentissage.\nL’erreur irréductible : la variance intrinsèque du bruit \\(\\varepsilon\\), notée \\(\\sigma^2\\).\n\n\n\n\n\n\n\nDécomposition biais/variance\n\n\n\nOn a : \\[\\mathbb{E}\\left[ (Y - \\widehat{Y})^2 \\right] = \\mathbb{E}\\left[ (Y - \\widehat{f}(X))^2 \\right] = \\mathrm{Biais}(\\widehat{f}(X))^2 + \\mathrm{Var}(\\widehat{f}(X)) + \\sigma^2.\\]\n\n\n\n\n\n\n\n\nPreuve\n\n\n\n\n\nTout d’abord, montrons que l’espérance de l’erreur de l’estimateur se décompose en une partie réductible et en une partie irréductible.\n\\[\\begin{align*}\n\\mathbb{E}\\left[ \\left( Y - \\widehat{Y} \\right)^2 \\right]\n&= \\mathbb{E}\\left[ \\left( Y - \\widehat{f}(X) \\right)^2 \\right] \\\\\n&= \\mathbb{E}\\left[ \\left( f(X) + \\varepsilon - \\widehat{f}(X) \\right)^2 \\right] \\\\\n&= \\mathbb{E}\\left[ \\left( f(X) - \\widehat{f}(X) \\right)^2 \\right] + 2\\mathbb{E}\\left[ \\left( f(X) - \\widehat{f}(X) \\right)\\varepsilon \\right] + \\mathbb{E}[\\varepsilon^2] \\\\\n&= \\mathbb{E}\\left[ \\left( f(X) - \\widehat{f}(X) \\right)^2 \\right] + 2\\mathbb{E}\\left[ \\left( f(X) - \\widehat{f}(X) \\right) \\right] \\underbrace{\\mathbb{E}\\left[ \\varepsilon \\right]}_{= 0} + \\sigma^2 \\\\\n&= \\underbrace{\\mathbb{E}\\left[ \\left( f(X) - \\widehat{f}(X) \\right)^2 \\right]}_{\\text{réductible}} + \\underbrace{\\sigma^2}_{\\text{irréductible}}.\n\\end{align*}\\]\nOn utilise la linéarité de l’espérance et le fait que \\(X\\) et \\(\\varepsilon\\) soient indépendants. On s’intéresse maintenant à la partie “réductible”. L’astuce est de faire apparaître \\(\\mathbb{E}\\left[ \\widehat{f}(X) \\right]\\).\n\\[\\begin{align*}\n\\mathbb{E}\\left[ \\left( f(X) - \\widehat{f}(X) \\right)^2 \\right]\n  &= \\mathbb{E}\\left[ \\left( f(X) - \\mathbb{E}\\left[ \\widehat{f}(X) \\right] + \\mathbb{E}\\left[ \\widehat{f}(X) \\right] - \\widehat{f}(X) \\right)^2 \\right] \\\\\n  &= \\underbrace{\\mathbb{E}\\left[ \\left( f(X) - \\mathbb{E}\\left[ \\widehat{f}(X) \\right] \\right)^2 \\right]}_{\\text{A}} \\\\\n  &\\quad - 2 \\underbrace{\\mathbb{E}\\left[ \\left( f(X) - \\mathbb{E}\\left[ \\widehat{f}(X) \\right] \\right) \\left( \\widehat{f}(X) - \\mathbb{E}\\left[ \\widehat{f}(X) \\right] \\right) \\right]}_{\\text{B}} \\\\\n  &\\quad + \\underbrace{\\mathbb{E}\\left[ \\left( \\widehat{f}(X) - \\mathbb{E}\\left[ \\widehat{f}(X) \\right] \\right)^2 \\right]}_{\\text{C}}.\n\\end{align*}\\]\nA. La fonction \\(f(X)\\) n’étant pas aléatoire, on a \\(\\mathbb{E}\\left[ f(X) \\right] = f(X)\\) et donc\n\\[\\begin{align*}\n\\mathbb{E}\\left[ \\left( f(X) - \\mathbb{E}\\left[ \\widehat{f}(X) \\right] \\right)^2 \\right]\n  &= \\mathbb{E}\\left[ \\left( \\mathbb{E}\\left[ f(X) - \\widehat{f}(X) \\right] \\right)^2 \\right] \\\\\n  &= \\mathbb{E}\\left[ f(X) - \\widehat{f}(X) \\right]^2 \\\\\n  &= \\text{Biais}(\\widehat{f}(X))^2.\n\\end{align*}\\]\nB. En développant l’expression et en utilisant l’indépendance des variables, on trouve que \\(B = 0\\).\nC. En utilisant la définition de la variance,\n\\[\\mathbb{E}\\left[ \\left( \\widehat{f}(X) - \\mathbb{E}\\left[ \\widehat{f}(X) \\right] \\right)^2 \\right] = \\mathrm{Var}(\\widehat{f}).\\]\nFinalement, on a\n\\[\\mathbb{E}\\left[ \\left( f(X) - \\widehat{f}(X) \\right)^2 \\right] = \\text{Biais}(\\widehat{f}(X))^2 + \\mathrm{Var}(\\widehat{f}(X)).\\]\nD’où le résultat.\n\n\n\nCette décomposition met en avant un compromis fondamental en analyse de données :\n\nSi on choisit un modèle peu flexible, le biais sera élevé, mais la variance sera faible.\nSi on choisit un modèle flexible, le biais sera faible, mais la variance peut être très élevée.\n\nNotre objectif est donc de trouver un juste équilibre entre biais et variance, i.e. un modèle qui prédit correctement, tout en étant généralisable à de nouvelles données. La Figure 2 présente un jeu de données et différents estimateurs \\(\\widehat{f}\\). En faisant varier le paramètre \\(\\lambda\\), on obtient des modèles plus ou moins flexible (lorsque \\(\\lambda = 0.15\\), le modèle est flexible et lorsque \\(\\lambda = 1\\), le modèle est rigide). La Figure 3 montre la valeur du biais, de la variance et de la MSE pour les modèles estimés pour la Figure 2. On remarque que plus \\(\\lambda\\) est petit, plus la variance est grande, mais le biais est petit (le modèle est flexible). Inversement, plus \\(\\lambda\\) est grand, plus le biais est grand et la variance petite (le modèle est rigide). La courbe de MSE en fonction du paramètre est une courbe en U. Comme on cherche à minimiser la MSE, i.e. à faire un compromis entre le biais et la variance, on peut prendre \\(\\lambda = 0.5\\).\n\n\nCode\n# Load packages\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\n\nset.seed(42)\n\n# 1. Simulate a single dataset\nn &lt;- 100\nsigma &lt;- 0.3\nx &lt;- sort(runif(n, 0, 1))\ny &lt;- 4 * x * (1 - x) * log(x) + 2 + rnorm(n, 0, sigma)\ndf &lt;- data.frame(x = x, y = y)\n\n# 2. Define grid and spans to compare\nx_grid &lt;- seq(0, 1, length.out = 300)\nspans_to_plot &lt;- c(0.15, 0.3, 0.5, 0.75, 1.0)\n\n# 3. Compute loess fits for each span\nfits &lt;- lapply(spans_to_plot, function(s) {\n  loess_model &lt;- loess(y ~ x, data = df, span = s)\n  y_hat &lt;- predict(loess_model, newdata = data.frame(x = x_grid))\n  data.frame(x = x_grid, y_hat = y_hat, span = paste0(\"λ = \", s))\n})\n\nfit_df &lt;- bind_rows(fits)\n\n# 4. Plot\nggplot() +\n  geom_point(data = df, aes(x, y), color = \"black\", alpha = 0.5, size = 2) +\n  geom_line(data = fit_df, aes(x, y_hat, color = span), size = 1.1) +\n  scale_color_viridis_d(option = \"C\") +\n  labs(\n    x = \"X\", y = \"Y\",\n    color = \"Paramètre\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nFigure 2: Différents estimateurs de la fonction \\(f\\).\n\n\n\n\n\n\n\nCode\n# Load packages\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\n\nset.seed(42)\n\n# Parameters\nn &lt;- 100              # number of observations per dataset\nn_sim &lt;- 100          # number of simulated datasets\nspans &lt;- seq(0.1, 1, length.out = 15)  # LOESS smoothing parameters\nsigma &lt;- 0.1          # noise standard deviation\nx_grid &lt;- seq(0.1, 1, length.out = 200)\nf_true &lt;- 4 * x_grid * (1 - x_grid) * log(x_grid) + 2\n\n# Storage for predictions\nresults &lt;- list()\n\nfor (s in spans) {\n  pred_matrix &lt;- matrix(NA, nrow = length(x_grid), ncol = n_sim)\n  \n  for (sim in 1:n_sim) {\n    x &lt;- sort(runif(n, 0.01, 1.1))\n    y &lt;- 4 * x * (1 - x) * log(x) + 2 + rnorm(n, 0, sigma)\n    df &lt;- data.frame(x = x, y = y)\n    \n    # Fit loess model with span = s\n    model &lt;- loess(y ~ x, data = df, span = s, degree = 2)\n    pred &lt;- predict(model, newdata = data.frame(x = x_grid), )\n    \n    pred_matrix[, sim] &lt;- pred\n  }\n  \n  # For each point in x_grid, compute bias², variance, MSE\n  mean_pred &lt;- rowMeans(pred_matrix, na.rm = TRUE)\n  bias2 &lt;- (mean_pred - f_true)^2\n  var_pred &lt;- apply(pred_matrix, 1, var, na.rm = TRUE)\n  mse &lt;- bias2 + var_pred\n  \n  results[[as.character(s)]] &lt;- data.frame(\n    span = s,\n    Biais2 = mean(bias2),\n    Variance = mean(var_pred),\n    MSE = mean(mse)\n  )\n}\n\n# Combine and reshape results\nresults_df &lt;- bind_rows(results)\nresults_long &lt;- pivot_longer(\n  results_df,\n  cols = c(\"Biais2\", \"Variance\", \"MSE\"),\n  names_to = \"component\", values_to = \"value\"\n)\n\n# Plot\nggplot(results_long, aes(x = span, y = value, color = component)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 2) +\n  scale_color_manual(\n    values = c(\"Biais2\" = \"#0D0887FF\", \"Variance\" = \"#9C179EFF\", \"MSE\" = \"#ED7953FF\")\n  ) +\n  labs(\n    x = \"Paramètre de lissage λ\" ,\n    y = \"\",\n    color = \"\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nFigure 3: Compromis biais/variance.\n\n\n\n\n\nDe manière générale, lorsque la flexibilité augmente, la diminution du biais est plus importante que l’augmentation de la variance, ce qui fait décroître l’erreur de prédiction. Cependant, à partir d’un certain niveau de flexibilité, le biais devient négligeable, et toute baisse supplémentaire est compensée par l’augmentation rapide de la variance. L’erreur de prédiction commence donc à croître. Il en résulte une courbe en U de l’erreur de prédiction en fonction de la flexibilité du modèle : un modèle trop rigide engendre un fort biais, tandis qu’un modèle trop flexible conduit à une trop grande variance.\n\n\n\n\n\n\nRemarque : Pourquoi un compromis ?\n\n\n\nIl est toujours possible de construire un modèle très flexible avec un biais nul, e.g. un modèle qui passe par tous les points d’observations, mais qui aura une variance énorme. À l’opposé, un modèle trop rigide, e.g. une constante, aura un biais très important mais une variance presque nulle. Le compromis biais/variance consiste à choisir un modèle qui contrôle ces deux quantités.",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Biais/Variance"
    ]
  },
  {
    "objectID": "contents/dimension/04-others.html",
    "href": "contents/dimension/04-others.html",
    "title": "Divers",
    "section": "",
    "text": "L’idée est de présenter rapidement d’autres méthodes de changement de dimension.",
    "crumbs": [
      "Modules",
      "04 - Dimension",
      "Divers"
    ]
  },
  {
    "objectID": "contents/dimension/04-others.html#t-sne",
    "href": "contents/dimension/04-others.html#t-sne",
    "title": "Divers",
    "section": "\\(t\\)-SNE",
    "text": "\\(t\\)-SNE",
    "crumbs": [
      "Modules",
      "04 - Dimension",
      "Divers"
    ]
  },
  {
    "objectID": "contents/dimension/04-others.html#umap",
    "href": "contents/dimension/04-others.html#umap",
    "title": "Divers",
    "section": "UMAP",
    "text": "UMAP",
    "crumbs": [
      "Modules",
      "04 - Dimension",
      "Divers"
    ]
  },
  {
    "objectID": "contents/dimension/03-kernel.html",
    "href": "contents/dimension/03-kernel.html",
    "title": "Noyau",
    "section": "",
    "text": "Dans certains cas, réduire la dimension des données n’est pas la chose à faire. Dans certains cas, il est même préférable d’augmenter la dimension des données ! Pourquoi ?\nRegardons l’exemple suivant: ajouter exemple en 2d, type cercle.\nDans ce cas, on s’intéresse à la méthode des noyaux (kernel trick).",
    "crumbs": [
      "Modules",
      "04 - Dimension",
      "Noyau"
    ]
  },
  {
    "objectID": "contents/dimension/03-kernel.html#la-méthode-du-noyau",
    "href": "contents/dimension/03-kernel.html#la-méthode-du-noyau",
    "title": "Noyau",
    "section": "",
    "text": "Dans certains cas, réduire la dimension des données n’est pas la chose à faire. Dans certains cas, il est même préférable d’augmenter la dimension des données ! Pourquoi ?\nRegardons l’exemple suivant: ajouter exemple en 2d, type cercle.\nDans ce cas, on s’intéresse à la méthode des noyaux (kernel trick).",
    "crumbs": [
      "Modules",
      "04 - Dimension",
      "Noyau"
    ]
  },
  {
    "objectID": "contents/remainders/02-probabilities.html",
    "href": "contents/remainders/02-probabilities.html",
    "title": "Probabilités et Statistiques",
    "section": "",
    "text": "Dans cette partie, on présente quelques résultats en probabilités et statistiques dans le cadre de ce cours. Pour plus d’information, vous pouvez vous référer au cours STT-1000, à Wasserman (2010) (en anglais) et à Delmas (2013) (en français).",
    "crumbs": [
      "Modules",
      "02 - Révisions",
      "Probabilités et Statistiques"
    ]
  },
  {
    "objectID": "contents/remainders/02-probabilities.html#modéliser-le-hasard",
    "href": "contents/remainders/02-probabilities.html#modéliser-le-hasard",
    "title": "Probabilités et Statistiques",
    "section": "Modéliser le hasard",
    "text": "Modéliser le hasard\nBeaucoup de phénomènes réels ne sont pas prévisibles et généralement, leurs résultats contiennent une certaine variabilité. Cette variabilité est prise en compte grâce à une mesure de l’incertitude que l’on appelle mesure de probabilités.\n\n\n\n\n\n\nDéfinition\n\n\n\nL’espace d’évènements \\(S\\) est l’ensemble de tous les résultats possibles d’un phénomène. Un évènement est un sous-ensemble de l’espace d’évènements \\(S\\).\n\n\n\n\n\n\n\n\nExemples\n\n\n\n\nSi l’expérience consiste à lancer un pièce, \\(S = \\{0, 1\\}\\). Le résultat de cette expérience ne peut pas être connu à l’avance. Par exemple, \\(E = \\{1\\}\\) est un évènement de \\(S\\).\nSi on s’intéresse à la durée de vie d’un téléphone, \\(S = \\mathbb{R}_{+}\\). On peut aussi choisir \\(S = [0, M]\\), car cette durée de vie n’est probablement pas infini ! L’évènement \\(E = [10, \\infty)\\) représente l’évènement “une durée de vie de plus de 10 unités de temps”.\nPour le nombre de jours sans neige à Québec dans l’année, on peut choisir \\(S = \\mathbb{N}\\). L’évènement \\(E = (0, 5]\\) représente l’évènement “moins de 5 jours sans neige à Québec dans l’année”.\n\n\n\n\n\n\n\n\n\nDéfinition\n\n\n\nUne mesure de probabilités \\(\\mathbb{P}\\) sur \\(S\\) est une application (fonction) définie sur l’espace d’évènements et satisfaisant les propriétés suivantes :\n\nPour chaque évènement \\(E\\), \\(\\mathbb{P}(E) \\in [0, 1]\\).\n\\(\\mathbb{P}(S) = 1\\).\nSoient \\(E_{1}, E_{2}, \\dots\\), une séquence d’évènements (finie ou infinie) mutuellement exclusive, i.e. \\(\\forall i \\neq j, E_{i} \\cap E_{j} = \\varnothing\\). On a \\[\\mathbb{P}(\\bigcup_{n = 1}^{\\infty} E_n) = \\sum_{n = 1}^{\\infty} \\mathbb{P}(E_n).\\]\n\nOn appelle \\(\\mathbb{P}(E)\\), la probabilité de l’évènement \\(E\\).\n\n\nLa définition de mesures de probabilités peut être subjective et lié à l’expérience du statisticien. En reprenant l’exemple 3 sur le nombre de jours sans neige à Québec dans l’année. Une personne venant d’arriver au Canada peut vouloir donner la même probabilité à chacun des jours, alors qu’un Québécois aura plus d’information et pourras faire varier les probabilités en fonction de cette connaissance.\n\n\n\n\n\n\nDéfinition\n\n\n\nDeux évènements \\(E\\) et \\(F\\) sont dits indépendants si \\(\\mathbb{P}(E \\cap F) = \\mathbb{P}(E) \\times \\mathbb{P}(F)\\).\n\n\n\n\n\n\n\n\nDéfinition\n\n\n\nSoient \\(E\\) et \\(F\\), deux évènements, la probabilité conditionelle que \\(E\\) se réalise sachant que \\(F\\) s’est réalisé est définie par : \\[\\mathbb{P}(E \\mid F) = \\frac{\\mathbb{P}(E \\cap F)}{\\mathbb{P}(F)}.\\]\n\n\nDe façon intuitive, deux évènements sont indépendants si la connaissance de l’un ne donne aucune information sur la réalisation de l’autre. On a aussi \\(\\mathbb{P}(E \\mid F) = \\mathbb{P}(E)\\).",
    "crumbs": [
      "Modules",
      "02 - Révisions",
      "Probabilités et Statistiques"
    ]
  },
  {
    "objectID": "contents/remainders/02-probabilities.html#variables-aléatoires",
    "href": "contents/remainders/02-probabilities.html#variables-aléatoires",
    "title": "Probabilités et Statistiques",
    "section": "Variables aléatoires",
    "text": "Variables aléatoires\nEn probabilité, la convention est d’exprimer le résultat d’expériences comme la valeur d’une fonction appelé variable aléatoire. Cette caractérisation est toujours possible.\n\n\n\n\n\n\nDéfinition\n\n\n\nSoit une variable aléatoire \\(X\\). La distribution de cette variable aléatoire est définie par l’application \\(A \\mapsto \\mathbb{P}(X \\in A)\\).\n\n\n\n\n\n\n\n\nDéfinition\n\n\n\nSoit une variable aléatoire \\(X\\). Cette variable aléatoire est discrète si elle prend, au plus, un nombre dénombrable de valeurs. Dans ce cas, la distribution de \\(X\\) est donnée par les probabilités \\(\\mathbb{P}(X = x)\\) pour tout résultat \\(x\\).\n\n\n\n\n\n\n\n\nDéfinition\n\n\n\nSoit une variable aléatoire \\(X\\). Cette variable aléatoire est continue si les probabilités \\(\\mathbb{P}(X \\in A)\\) sont données par des intégrales de la forme \\(\\int_{A} f(x) dx\\) où \\(f: \\mathbb{R}^d \\to \\mathbb{R}_+\\) est une fonction intégrable tel que \\(\\int_{\\mathbb{R}^d} f(x) dx = 1\\). Notons que, pour un résultat \\(x\\) fixé, \\(\\mathbb{P}(X = x) = 0\\).\n\n\n\n\n\n\n\n\nDéfinition\n\n\n\nSoit une variable aléatoire \\(X\\). L’espérance mathématique \\(\\mathbb{E}(X)\\) de \\(X\\) est la valeur moyenne du résultat de \\(X\\) par rapport à sa distribution de probabilité. L’espérance est généralement noté \\(\\mu\\).\n\n\nSoit \\(F\\) un ensemble dénombrable. Une variable aléatoire discrète \\(X\\) a pour espérance \\(\\mathbb{E}(X) = \\sum_{x \\in F} x \\mathbb{P}(X = x)\\). Soit une variable aléatoire continue \\(X\\) ayant pour densité \\(f\\), son espérance est donnée par \\(\\mathbb{E}(X) = \\int_{\\mathbb{R}^d} x f(x) dx\\).\n\n\n\n\n\n\nThéorème de transfert\n\n\n\nSoit une variable aléatoire \\(X\\). Soit \\(g: \\mathbb{R}^d \\mapsto \\mathbb{R}\\) une fonction telle que \\(\\mathbb{E}\\left[ g(X) \\right]\\) existe. On a :\n\nSi \\(X\\) est une variable aléatoire discrète, \\(\\mathbb{E}\\left[ g(X) \\right] = \\sum_{x \\in F} g(x) \\mathbb{P}(X = x)\\);\nSi \\(X\\) est une variable aléatoire continue de densité \\(f\\), \\(\\mathbb{E}\\left[ g(X) \\right] = \\int_{\\mathbb{R}^d} g(x)f(x) dx\\).\n\n\n\n\n\n\n\n\n\nPropriétés: Linéarité de l’espérance\n\n\n\nSoient \\(X\\) et \\(Y\\), deux variables aléatoires, dont les espérances sont définies et soit \\(\\lambda \\in R\\). On a :\n\n\\(\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y)\\);\n\\(\\mathbb{E}(\\lambda X) = \\lambda \\mathbb{E}(X)\\).\n\n\n\n\n\n\n\n\n\nPreuve\n\n\n\n\n\nLa preuve se déduit du théorème de transfert et de la linéarité de l’addition et de l’intégration.\n\n\n\n\n\n\n\n\n\nDéfinition\n\n\n\nSoit \\(X\\) une variable aléatoire telle que l’espérance de son carré existe. La variance de \\(X\\) est définie par \\[\\mathrm{Var}(X) = \\mathbb{E}\\left[ \\left( X - \\mathbb{E}(X) \\right)^2 \\right] = \\mathbb{E}\\left[ X^2 \\right] - \\mathbb{E}\\left[ X \\right]^2.\\]\n\n\nLa variance mesure la dispersion d’une variable aléatoire autour de sa moyenne. On peut aussi s’intéresser à l’écart-type, défini comme la racine carrée de la variance : \\(\\sigma(X) = \\sqrt{\\mathrm{Var}(X)}\\).\n\n\n\n\n\n\nDéfinition\n\n\n\nSoient \\(X\\) et \\(Y\\), deux variables aléatoires et \\(A\\) et \\(B\\), deux évenements. Si les évenements \\(\\left\\{ X \\in A \\right\\}\\) et \\(\\left\\{ Y \\in B \\right\\}\\) sont indépendants, alors on dit que les variables aléatoires \\(X\\) et \\(Y\\) sont indépendantes.\n\n\nDe cette définition, on en déduit que :\n\npour des fonctions \\(f\\) et \\(g\\), les variables aléatoires \\(f(X)\\) et \\(g(Y)\\) sont indépendantes;\nsi les variables aléatoires \\(X\\) et \\(Y\\) sont à valeurs réelles et que leur espérance existe, alors l’espérance du produit \\(XY\\) existe et \\(\\mathbb{E}(XY) = \\mathbb{E}(X) \\times \\mathbb{E}(Y)\\).\n\n\n\n\n\n\n\nDéfinition\n\n\n\nSoit \\(X\\) une variable aléatoire. La fonction de répartition \\(F: \\mathbb{R} \\mapsto [0, 1]\\) de \\(X\\) est définie par \\[F(t) = \\mathbb{P}(X \\leq t), \\quad t \\in \\mathbb{R}.\\]",
    "crumbs": [
      "Modules",
      "02 - Révisions",
      "Probabilités et Statistiques"
    ]
  },
  {
    "objectID": "contents/remainders/02-probabilities.html#vecteurs-aléatoires",
    "href": "contents/remainders/02-probabilities.html#vecteurs-aléatoires",
    "title": "Probabilités et Statistiques",
    "section": "Vecteurs aléatoires",
    "text": "Vecteurs aléatoires\nSupposons que \\(X = (X_{1}, X_{2})\\) est une variable aléatoire de dimension \\(2\\) de densité \\(f_{X}\\). On appelle généralement les variables aléatoires de dimension supérieure à \\(1\\), des vecteurs aléatoires. Les densités de \\(X_{1}\\) et \\(X_{2}\\) sont appelées les densités marginales. Lorsque \\(X_{1}\\) et \\(X_{2}\\) sont indépendantes, on a : \\[f_X(x, y) = f_{X_{1}}(x) \\cdot f_{X_{2}}(y), \\quad (x, y) \\in \\mathbb{R}^2.\\]\n\n\n\n\n\n\nExemple de la loi normale multidimensionnelle\n\n\n\nOn dit qu’un vecteur aléatoire \\(X\\) de dimension \\(p\\) suit une loi normale multidimensionnelle de moyenne \\(\\mu\\) et de variance \\(\\Sigma\\), si sa densité est donnée par \\[f_X(x) = \\frac{1}{(2 \\pi)^{p /2}} \\cdot \\frac{1}{(\\text{det} \\Sigma)^{1/2}} \\cdot \\exp\\left\\{ -\\frac{1}{2}\\left( x - \\mu \\right)^\\top \\Sigma^{-1} \\left( x - \\mu \\right) \\right\\}, \\quad x \\in \\mathbb{R}^p.\\]\nOn note \\(X \\sim \\mathcal{N}_{p}(\\mu, \\Sigma)\\).\n\n\nEn statistiques, une quantité importante à mesurer est la dépendance linéaire entre \\(X_{1}\\) et \\(X_{2}\\). Pour cela, on peut utiliser la covariance ou la correlation.\n\n\n\n\n\n\nDéfinition\n\n\n\nSoit \\(X = (X_{1}, X_{2})\\) un vecteur aléatoire tel que l’espérance du carré de \\(X_{1}\\) et de \\(X_{2}\\) existe. La covariance entre \\(X_{1}\\) et \\(X_{2}\\) est donnée par \\[\\mathrm{Cov}(X_{1}, X_{2}) = \\mathbb{E}\\left[ (X_{1} - \\mathbb{E}(X_{1})) (X_{2} - \\mathbb{E}(X_{2}))\\right].\\]\nLa corrélation entre \\(X_{1}\\) et \\(X_{2}\\) est une version de la covariance normalisée par l’écart-type des variables aléatoires. Elle est donnée par \\[\\mathrm{Corr}(X_{1}, X_{2}) = \\frac{\\mathrm{Cov}(X_{1}, X_{2})}{\\sigma(X_{1}) \\sigma(X_{2})}.\\]\n\n\nOn peut interpréter le signe de la covariance et de la corrélation. Si elles sont strictement positives, \\(X_{1}\\) et \\(X_{2}\\) ont tendance à aller dans la même direction. Si \\(X_{1}\\) augmente, alors \\(X_{2}\\) aussi, et inversement. Si elles sont strictement négatives, \\(X_{1}\\) et \\(X_{2}\\) ont tendance à aller dans des directions opposées. Si \\(X_{1}\\) augmente, alors \\(X_{2}\\) diminue, et inversement. Si la covariance est égales à \\(0\\), il n’y a pas de règles et \\(X_{1}\\) et \\(X_{2}\\) sont dites orthogonales.\n\n\n\n\n\n\nPropriétés\n\n\n\nSoit \\(X = (X_{1}, X_{2})\\) un vecteur aléatoire. On a\n\n\\(\\mathrm{Cov}(X_{1}, X_{2}) = \\mathbb{E}(X_{1}X_{2}) - \\mathbb{E}(X_{1})\\mathbb{E}(X_{2})\\);\n\\(\\mathrm{Cov}(X_{1}, X_{2}) = \\mathrm{Cov}(X_{2}, X_{1})\\);\n\\(\\mathrm{Cov}(X_{1} + \\lambda Y_{1}, X_{2}) = \\mathrm{Cov}(X_{1}, X_{2}) + \\lambda \\mathrm{Cov}(Y_{1}, X_{2})\\).\n\n\n\n\n\n\n\n\n\nPreuve\n\n\n\n\nOn trouve le résultat en développement le produit dans la définition de la covariance.\nEn utilisant le point 1. et la commutativité de la multiplication.\nEn utilisant le point 1. et la linéarité de l’espérance.",
    "crumbs": [
      "Modules",
      "02 - Révisions",
      "Probabilités et Statistiques"
    ]
  },
  {
    "objectID": "contents/remainders/02-probabilities.html#estimation",
    "href": "contents/remainders/02-probabilities.html#estimation",
    "title": "Probabilités et Statistiques",
    "section": "Estimation",
    "text": "Estimation\nEn practique, nous n’avons pas une connaissance parfaite de nos vecteurs aléatoires, mais seulement des réalisations de ceux-ci (que l’on appelle échantillon). Notons \\(x_{1}, \\dots, x_{n}\\), \\(n\\) réalisations indépendantes d’un vecteur aléatoire \\(X\\) de moyenne \\(\\mu\\) et de variance \\(\\Sigma\\).\nL’estimateur de la moyenne \\(\\mu\\) est donné par \\[\\widehat{\\mu} = \\overline{X} \\coloneqq \\frac{1}{n} \\sum_{i = 1}^{n} x_i.\\]\nL’estimateur de la variance \\(\\Sigma\\) est donné par \\[\\widehat{\\Sigma} \\coloneqq \\frac{1}{n - 1}\\sum_{i = 1}^{n} (x_i - \\widehat{\\mu})(x_i - \\widehat{\\mu})^\\top.\\]\nPourquoi divise t-on cette somme par \\(n -1\\) et non par \\(n\\) pour estimer la variance ? Si l’on divise par \\(n\\), \\(\\widehat{\\Sigma}\\) est un estimateur biaisé de la variance. En effet, il faut prendre en compte que l’on utilise un estimateur biaisé de la moyenne dans l’estimateur de la variance et donc corriger pour cette estimation.\nNotons \\(D = \\{\\text{diag}(\\widehat{\\Sigma})\\}^{1/2}\\), la matrice des écarts-types calculés sur l’échantillon. On peut estimer la matrice des corrélations sur l’échantillon par \\[\\widehat{R} = D^{-1} \\widehat{\\Sigma} D^{-1}.\\]",
    "crumbs": [
      "Modules",
      "02 - Révisions",
      "Probabilités et Statistiques"
    ]
  },
  {
    "objectID": "contents/remainders/03-programming.html",
    "href": "contents/remainders/03-programming.html",
    "title": "Programmation",
    "section": "",
    "text": "Dans cette partie, on présente quelques références sur les bases de la programmation dans différents langages. Ce cours ne spécifie pas de langage à utiliser, vous êtes donc libre de choisir celui qui vous convient le mieux pour faire les différents exercices, ainsi que votre projet. Dans tous les cas, il y a un ensemble de bonnes pratiques qui permet d’avoir un code lisible, compréhensible et réutilisable. Vous trouvez un (rapide) guide des bonnes pratiques en programmation à ce lien.",
    "crumbs": [
      "Modules",
      "02 - Révisions",
      "Programmation"
    ]
  },
  {
    "objectID": "contents/remainders/03-programming.html#r",
    "href": "contents/remainders/03-programming.html#r",
    "title": "Programmation",
    "section": "R",
    "text": "R\nR est un langage de programmation spécialisé dans l’analyse statistique et la visualisation de données. Il est gratuit, open-source et disponible sur Windows, macOS et Linux. Régulièrement mis à jour, de nouveaux packages sont disponibles chaque jour (cf. CRAN).\nVoici un guide qui présente les bases de R: Apprendre R en Y minutes et un guide de bonnes pratiques en R. Enfin, un point important du langage R est l’opérateur pipe. Celui-ci permet de rendre le code plus clair. Vous pouvez trouver une explication de cette opérateur ici.",
    "crumbs": [
      "Modules",
      "02 - Révisions",
      "Programmation"
    ]
  },
  {
    "objectID": "contents/remainders/03-programming.html#python",
    "href": "contents/remainders/03-programming.html#python",
    "title": "Programmation",
    "section": "Python",
    "text": "Python\nPython est un langage de programmation généraliste. Il est gratuit, open-source et disponible sur Windows, macOS et Linux. Bien que généraliste, il y a une importante communauté autour du l’analyse de données, machine learning en Python. Ainsi, les méthodes usuelles ont déjà été implementées, e.g. dans le package sklearn, mais si besoin, il est possible d’aller voir le code pour le modifier.\nVoici un guide qui présente les bases de Python: Apprendre Python en Y minutes et un guide de bonnes pratiques en Python.",
    "crumbs": [
      "Modules",
      "02 - Révisions",
      "Programmation"
    ]
  },
  {
    "objectID": "contents/remainders/03-programming.html#julia",
    "href": "contents/remainders/03-programming.html#julia",
    "title": "Programmation",
    "section": "Julia",
    "text": "Julia\nJulia est aussi un langage de programmation généraliste. C’est un langage bien plus récent que ses deux compères, R et Python (début des années 2010 pour Julia vs. début des années 1990 pour R et Python). Il peut donc sembler moins mature sur certains points, mais la plupart des méthodes d’analyse de données classiques ont été implémentées. De même que R et Python, ce langage est gratuit, open-source et disponible sur les principaux systèmes d’exploitation. Julia a l’avantage d’être plus rapide que R et Python. Il inclut aussi un support natif d’appel à des librairies en C ou en Fortran, et un support non-natif d’appel à des librairies en R et Python.\nVoici un guide qui présente les bases de Julia: Learn Julia in Y minutes (il n’y a pas de version française pour l’instant) et un guide de bonnes pratiques en Julia (en anglais).",
    "crumbs": [
      "Modules",
      "02 - Révisions",
      "Programmation"
    ]
  },
  {
    "objectID": "contents/remainders/03-programming.html#sas",
    "href": "contents/remainders/03-programming.html#sas",
    "title": "Programmation",
    "section": "SAS",
    "text": "SAS\nSAS est un langage de programmation propriétaire spécialisé dans l’analyse de données. Bien qu’utilisé dans certaines industries, e.g. pharmaceutique, son utilisation tend à diminuer. De plus, la license à renouveler tous les ans, l’absence de communauté en ligne (pour avoir de l’aide, à part la documentation officielle, il n’y a pas grand chose) et l’impossibilité de voir le code des différentes procédures font que je déconseille l’utilisation de SAS dans le cadre de ce cours. Cependant, si vous le voulez, l’université peut fournir des licenses moyennant paiement.",
    "crumbs": [
      "Modules",
      "02 - Révisions",
      "Programmation"
    ]
  },
  {
    "objectID": "slides/01-introduction-slides.html#test",
    "href": "slides/01-introduction-slides.html#test",
    "title": "Introduction",
    "section": "Test",
    "text": "Test\nCoucou"
  },
  {
    "objectID": "informations/schedule.html",
    "href": "informations/schedule.html",
    "title": "Plan",
    "section": "",
    "text": "Le plan est donné à titre indicatif.\n\n\n\nSemaine\nDate\nDurée\nPlan\nÉvaluations",
    "crumbs": [
      "Informations",
      "Plan"
    ]
  },
  {
    "objectID": "informations/evaluations.html",
    "href": "informations/evaluations.html",
    "title": "Évaluations",
    "section": "",
    "text": "Voici les différents examens prévus pour ce module.\n\n\n\nTitre\nDate\nMode de travail\nPondération\n\n\n\n\nExamen 1\n\nIndividuel\n25%\n\n\nExamen 2\n\nIndividuel\n50%\n\n\nProjet\n\nEn équipe\n25%\n\n\n\n\nIdentification. Lors d’un examen, une carte d’identité avec photo admissible doit être déposée sur le coin de votre table. Les cartes admissibles sont la carte de l’Université Laval en plastique, un permis de conduire canadien, une carte d’assurance-maladie avec photo émise par une province canadienne ou un passeport canadien ou étranger.",
    "crumbs": [
      "Informations",
      "Évaluations"
    ]
  },
  {
    "objectID": "informations/evaluations.html#modalités-dévaluations",
    "href": "informations/evaluations.html#modalités-dévaluations",
    "title": "Évaluations",
    "section": "",
    "text": "Voici les différents examens prévus pour ce module.\n\n\n\nTitre\nDate\nMode de travail\nPondération\n\n\n\n\nExamen 1\n\nIndividuel\n25%\n\n\nExamen 2\n\nIndividuel\n50%\n\n\nProjet\n\nEn équipe\n25%\n\n\n\n\nIdentification. Lors d’un examen, une carte d’identité avec photo admissible doit être déposée sur le coin de votre table. Les cartes admissibles sont la carte de l’Université Laval en plastique, un permis de conduire canadien, une carte d’assurance-maladie avec photo émise par une province canadienne ou un passeport canadien ou étranger.",
    "crumbs": [
      "Informations",
      "Évaluations"
    ]
  },
  {
    "objectID": "informations/evaluations.html#informations-détaillées-sur-les-évaluations",
    "href": "informations/evaluations.html#informations-détaillées-sur-les-évaluations",
    "title": "Évaluations",
    "section": "Informations détaillées sur les évaluations",
    "text": "Informations détaillées sur les évaluations\nExamen 1\nDate et lieu:\nMode de travail: Individuel\nPondération: 25%\nRemise de l’évaluation:\nDirectives de l’évaluation: Tout le contenu du cours est susceptible d’être a l’examen.\nMatériel autorisé: pas de restriction.\nInformation supplementaire: lien.\nExamen 2\nDate et lieu:\nMode de travail: Individuel\nPondération: 50%\nRemise de l’évaluation:\nDirectives de l’évaluation: Tout le contenu du cours est susceptible d’être à l’examen.\nMatériel autorisé: pas de restriction.\nProjet\nDate et lieu:\nMode de travail: En équipe\nPondération: 25%\nRemise de l’évaluation:\nDirectives de l’évaluation:\nMatériel autorisé: pas de restriction.",
    "crumbs": [
      "Informations",
      "Évaluations"
    ]
  },
  {
    "objectID": "informations/evaluations.html#échelle-des-cotes",
    "href": "informations/evaluations.html#échelle-des-cotes",
    "title": "Évaluations",
    "section": "Échelle des cotes",
    "text": "Échelle des cotes\n\n\n\nCote\n% minimum\n% maximum\n\n\n\n\nA+\n92\n100\n\n\nA\n88\n91.99\n\n\nA-\n84\n87.99\n\n\nB+\n80\n83.99\n\n\nB\n75\n79.99\n\n\nB-\n70\n74.99\n\n\nC+\n65\n69.99\n\n\nC\n60\n64.99\n\n\nC-\n55\n59.99\n\n\nD+\n52\n54.99\n\n\nD\n50\n51.99\n\n\nE\n0\n49.99",
    "crumbs": [
      "Informations",
      "Évaluations"
    ]
  },
  {
    "objectID": "informations/evaluations.html#détails-sur-les-modalités-dévaluation",
    "href": "informations/evaluations.html#détails-sur-les-modalités-dévaluation",
    "title": "Évaluations",
    "section": "Détails sur les modalités d’évaluation",
    "text": "Détails sur les modalités d’évaluation\nConformément à la politique du Département de mathématiques et de statistique en matière d’amélioration et de consolidation de la connaissance du français, la qualité de l’écrit sera sanctionnée dans tous les travaux et examens. Un maximum de 10% des points pourra être enlevé pour la qualité de la langue et de la rédaction.\nAucun retard n’est accepté pour la remise des travaux.\nToute reprise d’évaluation accordée par la politique de reprise d’évaluation du Département aura lieu lors des dates de reprises officielles de la faculté. Pour toute demande de révision de note, vous devez suivre la procédure du chapitre 4 du Réglement des études. Vous trouverez un formulaire à remplir à l’adresse suivante: lien.",
    "crumbs": [
      "Informations",
      "Évaluations"
    ]
  },
  {
    "objectID": "informations/evaluations.html#absence-à-une-activité-obligatoire",
    "href": "informations/evaluations.html#absence-à-une-activité-obligatoire",
    "title": "Évaluations",
    "section": "Absence à une activité obligatoire",
    "text": "Absence à une activité obligatoire\nCes modalités s’appliquent en vertu des articles 4.41 et 4.42 du Réglement des études de l’Université Laval:\n\nArticle 4.41: Tout défaut de se soumettre à une activité d’évaluation entraîne la note de zéro pour cette activité d’évaluation, à moins que l’étudiante ou l’étudiant ne démontre que cette omission est attribuable à des motifs sérieux.\nArticle 4.42: La reprise d’une évaluation est possible pour des motifs sérieux. Elle se fait selon les modalités prévues par l’unité responsable de l’activité de formation.\n\nLa reprise d’une évaluation peut donc execptionnellement être autorisée pour des motifs jugés sérieux, dans la mesure où la procédure décrite ci-dessous est respectée.\nMotifs d’absence jugés sérieux\nLes motifs suivants sont jugés sérieux et donc acceptables pour demander une reprise d’évaluation:\n\nmaladie ou accident empêchant de se déplacer;\nhospitalisation;\nmaladie grave ou décès d’un proche;\nparticipation à une activité sportive de haut niveau;\nconvocation en cour de justice.\n\nProcédure à suivre\nDès que possible et au plus tard cinq (5) jours ouvrables après la date de l’évaluation (ou dans certains cas, avant la date de l’évaluation, dès que le motif sera connu), l’étudiante ou l’étudiant qui veut faire une demande de reprise d’évaluation doit remplir et soumettre le formulaire électronique “Demande de reprise d’une évaluation” en prenant soin d’y joindre les pièces justificatives requises.\nPour avoir plus de détail sur les procédures à suivre et les motifs sérieux pouvant donner droit à une reprise d’évaluation, consulter le document “Modalités et procédure de reprise d’une évaluation sommative à la Faculté des sciences et de génie” disponible sur le site web de la FSG.\nDans certains cas, la ou le responsable du cours pourrait adopter une procédure simplifiée de gestion des demandes de reprises d’évaluation, tout en respectant les critères décrits dans cette politique. Dans ces cas, des explications particulières seront données à cet effet dans le plan de cours et présentées lors de la première séance.",
    "crumbs": [
      "Informations",
      "Évaluations"
    ]
  },
  {
    "objectID": "informations/evaluations.html#politique-sur-lutilisation-dappareils-électroniques",
    "href": "informations/evaluations.html#politique-sur-lutilisation-dappareils-électroniques",
    "title": "Évaluations",
    "section": "Politique sur l’utilisation d’appareils électroniques",
    "text": "Politique sur l’utilisation d’appareils électroniques\nLa politique sur l’utilisation d’appareils électroniques de la Faculté des Sciences et de Génie peut être consultée à l’adresse: lien.",
    "crumbs": [
      "Informations",
      "Évaluations"
    ]
  },
  {
    "objectID": "informations/evaluations.html#politique-sur-le-plagiat-et-la-fraude-académique",
    "href": "informations/evaluations.html#politique-sur-le-plagiat-et-la-fraude-académique",
    "title": "Évaluations",
    "section": "Politique sur le plagiat et la fraude académique",
    "text": "Politique sur le plagiat et la fraude académique\nRègles disciplinaires\nTout étudiant qui commet une infraction au Règlement disciplinaire à l’intention des étudiants de l’Université Laval dans le cadre du présent cours, notamment en matière de plagiat, est passible des sanctions qui sont prévues dans ce règlement. Il est très important pour tout étudiant de prendre connaissance des articles 23 à 46 du Règlement disciplinaire. Celui-ci peut être consulté à l’adresse suivante: lien.\nPlagiat\nTout étudiant est tenu de respecter les règles relatives au plagiat. Constitue notamment du plagiat le fait de:\n\ncopier textuellement un ou plusieurs passages provenant d’un ouvrage sous format papier ou électronique sans mettre ces passages entre guillemets et sans en mentionner la source;\nrésumer l’idée originale d’un auteur en l’exprimant dans ses propres mots (paraphraser) sans en mentionner la source;\ntraduire partiellement ou totalement un texte sans en mentionner la provenance;\nremettre un travail copié d’un autre étudiant (avec ou sans l’accord de cet autre étudiant);\nremettre un travail téléchargé d’un site d’achat ou d’échange de travaux scolaires.\n\nL’Université Laval étant abonnée à un service de détection de plagiat, il est possible que l’enseignant soumette vos travaux pour analyse.",
    "crumbs": [
      "Informations",
      "Évaluations"
    ]
  },
  {
    "objectID": "informations/evaluations.html#étudiants-ayant-une-situation-de-handicap-liée-à-une-limitation-fonctionnelle",
    "href": "informations/evaluations.html#étudiants-ayant-une-situation-de-handicap-liée-à-une-limitation-fonctionnelle",
    "title": "Évaluations",
    "section": "Étudiants ayant une situation de handicap liée à une limitation fonctionnelle",
    "text": "Étudiants ayant une situation de handicap liée à une limitation fonctionnelle\nAfin de bénéficier de mesures d’accommodement pour les cours ou les examens, un rendez-vous avec une conseillère ou un conseiller du Centre d’aide aux étudiants travaillant en Accueil et soutien aux étudiants en situation de handicap (ACSESH) est nécessaire. Pour ce faire, les étudiants présentant une situation de handicap liée à une limitation fonctionnelle permanente doivent visiter le site “Accommodement” et prendre un rendez-vous, le plus tôt possible.\nAu cours de la semaine qui suit l’autorisation des mesures, leur activation doit être effectuée dans “Accommodement” pour assurer leur mise en place.\nLes étudiants ayant déjà obtenu des mesures d’accommodements scolaires doivent procéder à l’activation de leurs mesures pour les cours et/ou les examens dans “Accommodement” afin que celles-ci puissent être mises en place. Il est à noter que l’activation doit s’effectuer au cours de deux premières semaines de cours.\nLes étudiants concernés recevront par la suite des facultés et départements responsables de leurs cours les informations détaillées sur les modalités permettant d’appliquer les mesures d’accommodement identifiées.",
    "crumbs": [
      "Informations",
      "Évaluations"
    ]
  },
  {
    "objectID": "informations/mcq.html",
    "href": "informations/mcq.html",
    "title": "QCM",
    "section": "",
    "text": "Le premier examen est un questionaire à choix multiples avec quantification de l’incertitude.\nL’ utilisation de degrés de certitude permet à l’étudiant et à l’étudiante d’évaluer le niveau de connaissance de la réponse donnée. La barème des notes, basé sur la théorie des décision (Leclercq et al. 1993), peut sembler bizarre mais il a été fait de tel manière que:\n\ndire la vérité soit la stratégie qui rapporte le plus de points;\nceux qui s’auto-évaluent bien gagnent plus de points que si l’on appliquait un barème correctif tenant compte des probabilités d’avoir la réponse correcte aléatoirement.\n\n\n\n\nSi vous condidérez que votre réponse a une probabilité d’être correcte comprise entre…\n\n\nChoisissez le degré de certitude…\n\n\nVous obtiendrez les points suivants en case de réponse…\n\n\n\n\n\n\n\n\ncorrecte\n\n\nincorrecte\n\n\n\n\n0% et 25%\n\n\n0\n\n\n+13\n\n\n+4\n\n\n\n\n25% et 50%\n\n\n1\n\n\n+16\n\n\n+3\n\n\n\n\n50% et 70%\n\n\n2\n\n\n+17\n\n\n+2\n\n\n\n\n70% et 85%\n\n\n3\n\n\n+18\n\n\n0\n\n\n\n\n85% et 95%\n\n\n4\n\n\n+19\n\n\n-6\n\n\n\n\n95% et 100%\n\n\n5\n\n\n+20\n\n\n-10\n\n\n\nGénéralement, les étudiants s’auto-estiment avec réalisme, et sont avantagés par les degrés de certitude. Leur score obtenu est meilleur que s’il avait été calculé uniquement sur la base du nombre de réponses justes.",
    "crumbs": [
      "Informations",
      "Évaluations",
      "QCM"
    ]
  },
  {
    "objectID": "informations/mcq.html#information-sur-le-premier-examen",
    "href": "informations/mcq.html#information-sur-le-premier-examen",
    "title": "QCM",
    "section": "",
    "text": "Le premier examen est un questionaire à choix multiples avec quantification de l’incertitude.\nL’ utilisation de degrés de certitude permet à l’étudiant et à l’étudiante d’évaluer le niveau de connaissance de la réponse donnée. La barème des notes, basé sur la théorie des décision (Leclercq et al. 1993), peut sembler bizarre mais il a été fait de tel manière que:\n\ndire la vérité soit la stratégie qui rapporte le plus de points;\nceux qui s’auto-évaluent bien gagnent plus de points que si l’on appliquait un barème correctif tenant compte des probabilités d’avoir la réponse correcte aléatoirement.\n\n\n\n\nSi vous condidérez que votre réponse a une probabilité d’être correcte comprise entre…\n\n\nChoisissez le degré de certitude…\n\n\nVous obtiendrez les points suivants en case de réponse…\n\n\n\n\n\n\n\n\ncorrecte\n\n\nincorrecte\n\n\n\n\n0% et 25%\n\n\n0\n\n\n+13\n\n\n+4\n\n\n\n\n25% et 50%\n\n\n1\n\n\n+16\n\n\n+3\n\n\n\n\n50% et 70%\n\n\n2\n\n\n+17\n\n\n+2\n\n\n\n\n70% et 85%\n\n\n3\n\n\n+18\n\n\n0\n\n\n\n\n85% et 95%\n\n\n4\n\n\n+19\n\n\n-6\n\n\n\n\n95% et 100%\n\n\n5\n\n\n+20\n\n\n-10\n\n\n\nGénéralement, les étudiants s’auto-estiment avec réalisme, et sont avantagés par les degrés de certitude. Leur score obtenu est meilleur que s’il avait été calculé uniquement sur la base du nombre de réponses justes.",
    "crumbs": [
      "Informations",
      "Évaluations",
      "QCM"
    ]
  },
  {
    "objectID": "tp/02-revision-tp.html",
    "href": "tp/02-revision-tp.html",
    "title": "TP: Révision",
    "section": "",
    "text": "Vous pouvez faire les exercices dans le langage de votre choix."
  },
  {
    "objectID": "tp/02-revision-tp.html#exercice-1-estimer-pi",
    "href": "tp/02-revision-tp.html#exercice-1-estimer-pi",
    "title": "TP: Révision",
    "section": "Exercice 1: Estimer \\(\\pi\\)",
    "text": "Exercice 1: Estimer \\(\\pi\\)\nDans cet exercice, on se propose d’estimer \\(\\pi\\) grâce à la méthode de Monte-Carlo. Le méthode de Monte-Carlo est une méthode algorithmique permettant d’estimer des quantités en utilisant des tirages aléatoires. Pour estimer \\(\\pi\\), l’idée est de générer des points dans un carré de façon uniforme et ensuite de compter la proportion de ces points qui sont dans le cercle unité.\n\nGénérer un nombre \\(n\\) de points \\((x, y)\\) dans un carré de longueur \\(2\\) centré à l’origine, i.e. \\(x \\in [-1, 1]\\) et \\(y \\in [-1, 1]\\).\nPour chaque point \\(n\\), déterminer si le point appartient au cercle unité.\nCalculer la proportion du nombre de points dans le cercle unité.\nÀ partir du résultat précédent, estimer \\(\\pi\\).\nNotons \\(\\widehat{\\pi}(n)\\), l’estimateur de \\(\\pi\\) utilisant \\(n\\) points générés. Tracer l’erreur d’estimation \\(\\left| \\pi - \\widehat{\\pi}(n) \\right|\\) en fonction de \\(n\\)."
  },
  {
    "objectID": "tp/02-revision-tp.html#exercice-2-estimation-dintégrale",
    "href": "tp/02-revision-tp.html#exercice-2-estimation-dintégrale",
    "title": "TP: Révision",
    "section": "Exercice 2: Estimation d’intégrale",
    "text": "Exercice 2: Estimation d’intégrale\nDans cette exercice, on se propose d’estimer \\[I = \\int_{-1}^{1} \\sqrt{1 - x^2} dx .\\]\n\nCalculer \\(I\\) en utilisant une primitive.\nIl est possible d’estimer \\(I = \\int_{-1}^{1} f(x) dx\\) à l’aide des sommes de Riemann \\(\\widehat{I}(n) = \\frac{1}{n}\\sum_{i = 1}^{n} f(\\frac{i}{n}), i = 1, \\dots, n\\). Estimer \\(I\\) en utilisant les sommes de Riemann.\nL’intégrale \\(I\\) peut être vu comme l’espérance d’un variable aléatoire. \\(I = \\mathbb{E}[f(U)]\\), où \\(U \\sim \\mathcal{U}(-1, 1)\\). On peut estimer \\(I\\) en utilisant \\(\\widetilde{I}(n) = \\frac{1}{n} \\sum_{i = 1}^{n} f(u_i)\\), où les \\(u_i\\) sont des réalisations de la variable aléatoire \\(U\\). Estimer \\(I\\) en utilisant cette méthode.\nComparer la qualité de ces deux estimateurs de \\(I\\) en fonction de \\(n\\)."
  },
  {
    "objectID": "tp/02-revision-tp.html#exercice-3-la-loi-des-gaz-parfaits",
    "href": "tp/02-revision-tp.html#exercice-3-la-loi-des-gaz-parfaits",
    "title": "TP: Révision",
    "section": "Exercice 3: La loi des gaz parfaits",
    "text": "Exercice 3: La loi des gaz parfaits\nDans cet exercice, on se propose de vérifier la loi des gaz parfaits à partir des données. On rappelle que la loi des gaz parfaits est donnée par \\(PV = nRT\\) où :\n\n\\(P\\) est la pression à l’intérieur du volume considéré en Pascal (Pa);\n\\(V\\) est le volume du gaz en m\\(^3\\);\n\\(n\\) est la quantité de matière en mole (mol);\n\\(R = 8.314\\) est la constante universelle des gaz parfaits en J.mol\\(^{-1}\\).K\\(^{-1}\\);\n\\(T\\) est la température à l’intérieur du volume considéré en Kelvin (K).\n\nOn conduit une expérience consistant à chauffer une quantité fixe de gaz dans un récipient fermé de volume fixé. La température \\(T\\) en Kelvin et la pression \\(P\\) en kPa sont enregistrées. On trouve les résultats suivants :\n\ntemperature = [\n  406, 296, 272, 449, 483, 439, 460, 276, 321, 462, 408, 322, 285,\n  411, 491, 359, 453, 486, 413, 350, 263, 456, 390, 462, 389, 494,\n  303, 496, 336, 460\n]\n\npression = [\n  1365, 982, 898, 1486, 1596, 1481, 1506, 906, 1085, 1542, 1367,\n  1072, 955, 1379, 1633, 1186, 1499, 1606, 1378, 1156, 867, 1514,\n  1306, 1525, 1287, 1665, 1020, 1635, 1118, 1529\n]\n\n\nTracer la pression en fonction de la température. Est-ce que le graphique est linéaire ?\nConstruire la matrice \\(X = (1 | \\text{temperature})\\). La première colonne de \\(X\\) est une colonne de \\(1\\) et la deuxième colonne de \\(X\\) est le vecteur des températures.\nCalculer le vecteur \\(\\beta = (X^{\\top} X)^{-1} X^{\\top} Y\\) où \\(Y\\) est le vecteur des pressions.\nQuelle est l’interprétation physique des éléments du vecteur \\(\\beta\\) ?\nÀ quelle valeur de \\(\\beta_0\\), le premier coefficient de \\(\\beta\\), devrait-on s’attendre dans le cadre d’un gaz parfait ? Est-ce le cas ici ? Pourquoi ?\nSupposons que le volume de gaz est de \\(10\\)dm\\(^3\\). Estimer la quantité de matière \\(n\\) en mole utilisé pour avoir les données."
  },
  {
    "objectID": "tp/03-generalities-tp.html",
    "href": "tp/03-generalities-tp.html",
    "title": "TP: Généralités",
    "section": "",
    "text": "Vous pouvez faire les exercices dans le langage de votre choix."
  },
  {
    "objectID": "informations/general.html",
    "href": "informations/general.html",
    "title": "Informations générales",
    "section": "",
    "text": "Faculté des sciences et de génie\nDépartement de mathématiques et de statistique",
    "crumbs": [
      "Informations",
      "Générales"
    ]
  },
  {
    "objectID": "informations/general.html#stt-2200-analyse-de-données",
    "href": "informations/general.html#stt-2200-analyse-de-données",
    "title": "Informations générales",
    "section": "STT-2200: Analyse de données",
    "text": "STT-2200: Analyse de données\nFormule d’enseignement: Présentiel\nTemps consacré:\n\nCours: 2h\nLaboratoire: 1h\nTravail personnel: 6h\nTotal: 9h\n\nCrédits: 3\nPréalables:\n\nACT-2000 ou STT-1000 ou STT-1300 ou STT-1900\nMAT-1200 ou ACT-2002\nSTT-1100 ou IFT-4902 ou ECN-2090 ou GLO-1901 ou IFT-1004\n\nPlage horaire:\n\n\n\nType\nJour\nHoraire\nDates\n\n\n\n\nLabo\nMardi\n\n\n\n\nClasse\nVendredi",
    "crumbs": [
      "Informations",
      "Générales"
    ]
  },
  {
    "objectID": "informations/general.html#coordonnées-et-disponibilités",
    "href": "informations/general.html#coordonnées-et-disponibilités",
    "title": "Informations générales",
    "section": "Coordonnées et disponibilités",
    "text": "Coordonnées et disponibilités\nEnseignant: Steven Golovkine\nLocal: VCH-2209\nE-mail: steven.golovkine@mat.ulaval.ca\nDisponibilités: Je suis disponible pour vous rencontrer sur rendez-vous par couriel ou sans rendez-vous du lundi au jeudi entre 8h et 10h.\n\nL’Université reconnaît le droit à la déconnexion des professeures et professeurs, des personnes chargées de cours et des autres membres du personnel enseignant. Cela signifie que ces personnes ne sont pas tenues de consulter les messages qui leur sont envoyés (courriel, boîte vocale, message dans un forum, etc.) pendant les soirs, fins de semaine, jours fériés et vacances. La personne qui aura envoyé un message durant ces périodes devra donc s’attendre à recevoir une réponse dans un délai raisonnable, calculé à partir de la reprise des heures normales de travail.",
    "crumbs": [
      "Informations",
      "Générales"
    ]
  },
  {
    "objectID": "informations/materials.html",
    "href": "informations/materials.html",
    "title": "Matériel",
    "section": "",
    "text": "Cette page regroupe différentes ressources utiles pour le cours.\nThe Elements of Statistical Learning: Data Mining, Inference and Prediction, 2nd Edition\nAuteurs: Trevor Hastie, Robert Tibshirani et Jerome Friedman\nÉditeur: Springer (New York, 2009)\nISBN: 0-387-84857-0\nLien: site web des authors\nAn Introduction to Statistical Learning: with application in R, 2nd Edition\nAuteurs: Gareth James, Daniela Witten, Trevor Hastie et Robert Tibshirani\nÉditeur: Springer (New York, 2021)\nISBN: 1-0716-1417-4\nLien: site web des authors\nAn Introduction to Statistical Learning: with application in Python\nAuteurs: Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani et Jonathan Taylor\nÉditeur: Springer (Suisse, 2023)\nISBN: 3-031-38746-3\nLien: site web des authors",
    "crumbs": [
      "Informations",
      "Matériel"
    ]
  },
  {
    "objectID": "informations/description.html",
    "href": "informations/description.html",
    "title": "Description du cours",
    "section": "",
    "text": "Dans ce cours, nous visons à introduire des méthodes qui permettront aux étudiantes et étudiants d’étudier un jeu de données de “haute dimension” (ici, “haute” est pris dans le sens où l’on ne peut pas faire un simple graphique de l’ensemble des variables pour toutes les observations) sans avoir recours à un modèle probabiliste. Les techniques que l’on y enseigne servent à réduire la dimension des données, identifier certains liens entre les variables, visualiser les données ou à diviser le jeu de données en groupes/classes.\nSans négliger la théorie, l’accent sera mis sur l’aspect pratique de l’analyse des données et l’utilisation d’un langage de programmation, que ce soit R, Python ou autre.",
    "crumbs": [
      "Informations",
      "Description"
    ]
  },
  {
    "objectID": "informations/description.html#objectifs",
    "href": "informations/description.html#objectifs",
    "title": "Description du cours",
    "section": "",
    "text": "Dans ce cours, nous visons à introduire des méthodes qui permettront aux étudiantes et étudiants d’étudier un jeu de données de “haute dimension” (ici, “haute” est pris dans le sens où l’on ne peut pas faire un simple graphique de l’ensemble des variables pour toutes les observations) sans avoir recours à un modèle probabiliste. Les techniques que l’on y enseigne servent à réduire la dimension des données, identifier certains liens entre les variables, visualiser les données ou à diviser le jeu de données en groupes/classes.\nSans négliger la théorie, l’accent sera mis sur l’aspect pratique de l’analyse des données et l’utilisation d’un langage de programmation, que ce soit R, Python ou autre.",
    "crumbs": [
      "Informations",
      "Description"
    ]
  },
  {
    "objectID": "informations/description.html#place-du-cours-dans-le-programme",
    "href": "informations/description.html#place-du-cours-dans-le-programme",
    "title": "Description du cours",
    "section": "Place du cours dans le programme",
    "text": "Place du cours dans le programme\nCe cours est généralement suivi par des étudiants du baccalauréat en statistique lors de leur deuxième année de formation. C’est aussi un cours à option en actuariat, en mathématique ainsi que dans certains programmes de génie et d’administration.\nTous les étudiants doivent s’assurer d’avoir suivi au minimum un cours d’algèbre (ex. MAT-1200) et un cours de statistique de base (ex. STT-1000), car la majorité des méthodes d’analyse de données s’appuient sur ces notions.\nLes étudiants devraient aussi avoir une certaine familiarité avec les concepts algorithmiques de base, ainsi qu’avec (au moins) un langage de programmation.",
    "crumbs": [
      "Informations",
      "Description"
    ]
  },
  {
    "objectID": "informations/description.html#objectifs-spécifiques",
    "href": "informations/description.html#objectifs-spécifiques",
    "title": "Description du cours",
    "section": "Objectifs spécifiques",
    "text": "Objectifs spécifiques\nÀ la fin du cours, l’étudiant ou l’étudiante devrait être capable :\n\nde comprendre et décrire succinctement les fondements théoriques des méthodes d’analyse de données étudiées;\nd’identifier correctement les situations où l’emploi de ces méthodes est indiqué;\nd’utiliser efficacement un langage de programmation pour mettre en oeuvre ces méthodes;\nd’analyser et d’interpréter judicieusement les résultats découlant de l’analyse;\nde formuler par écrit les conclusions de l’analyse, dans le respect des limites de la méthodologie.",
    "crumbs": [
      "Informations",
      "Description"
    ]
  },
  {
    "objectID": "informations/description.html#équipement-informatique",
    "href": "informations/description.html#équipement-informatique",
    "title": "Description du cours",
    "section": "Équipement informatique",
    "text": "Équipement informatique\nVous pourriez avoir besoin d’un ordinateur, de haut-parleurs ou d’un casque d’écoute, d’un microphone, d’une webcam et d’une connexion Internet avec fil à large bande ou sans fil. Pour vérifier les paramètres de configuration minimaux selon le système d’exploitation, nous vous invitons à visiter cette page.\nDe plus, ce cours peut nécessiter des besoins logiciels particuliers qui seront alors décrits dans d’autres sections du plan de cours, le cas échéant.",
    "crumbs": [
      "Informations",
      "Description"
    ]
  },
  {
    "objectID": "informations/description.html#fonctionnement",
    "href": "informations/description.html#fonctionnement",
    "title": "Description du cours",
    "section": "Fonctionnement",
    "text": "Fonctionnement\nLes cours et examens auront lieu en présentiel les mardi et vendredi matin, mais le matériel sera disponible en ligne. De façon générale, la séance du vendredi sera une séance magistrale et la séance du mardi sera dédiée à des exercices pratiques réalisés de façon autonome par les étudiants avec le soutien de l’enseignant.",
    "crumbs": [
      "Informations",
      "Description"
    ]
  },
  {
    "objectID": "informations/description.html#approches-pédagogiques",
    "href": "informations/description.html#approches-pédagogiques",
    "title": "Description du cours",
    "section": "Approches pédagogiques",
    "text": "Approches pédagogiques\nL’approche pédagogique privilégiée est l’exposé interactif (vendredi) en alternance avec des périodes de laboratoires (mardi). L’approche pédagogique est très axée sur l’apprentissage actif et exige un engagement soutenu des étudiants tout au long de la session.",
    "crumbs": [
      "Informations",
      "Description"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STT-2200: Analyse de données",
    "section": "",
    "text": "Bienvenue à tous au cours STT-2200 de l’automne 2025.\nVous trouverez sur ce site toute les informations nécessaire pour les cours, les différents travaux et les examens. Les contenus seront mis à jour au cours de la session avec les corrigés de certains travaux. Je vous invite à regarder les différents modules avant les cours.\nCe site a été créé en s’aidant des notes de cours de Aurélien Nicosia et de Thierry Duchesne.\nCe site a été créé avec Quarto.\n\n\n\nData trap (xkcd:2582)."
  },
  {
    "objectID": "contents/remainders/01-linear-algebra.html",
    "href": "contents/remainders/01-linear-algebra.html",
    "title": "Algèbre linéaire",
    "section": "",
    "text": "Dans cette partie, on présente quelques résultats d’algèbre linéaire utiles dans le cadre de ce cours. Pour plus d’information, vous pouvez vous référer au cours MAT-1200, à Deisenroth, Faisal, et Ong (2020) (en anglais) et à Grifone (2024) (en français).",
    "crumbs": [
      "Modules",
      "02 - Révisions",
      "Algèbre linéaire"
    ]
  },
  {
    "objectID": "contents/remainders/01-linear-algebra.html#quelques-propriétés-matricielles",
    "href": "contents/remainders/01-linear-algebra.html#quelques-propriétés-matricielles",
    "title": "Algèbre linéaire",
    "section": "Quelques propriétés matricielles",
    "text": "Quelques propriétés matricielles\nNotons \\(M_{n, m}(\\mathbb{R})\\), l’ensemble des matrices à \\(n\\) lignes et \\(m\\) colonnes dont les entrées appartiennent à \\(\\mathbb{R}\\). Notons \\(M_{n}(\\mathbb{R})\\), l’ensemble des matrices carrées de taille \\(n\\), i.e. à \\(n\\) lignes et \\(n\\) colonnes dont les entrées appartiennent à \\(\\mathbb{R}\\). Soient \\(M\\), \\(N\\) et \\(P\\) des matrices appartenant à \\(M_{n, m}(\\mathbb{R})\\). Soient \\(A\\) et \\(B\\) des matrices appartenant à \\(M_{n}(\\mathbb{R})\\). Notons \\(I_n\\) la matrice identité de taille \\(n\\), i.e. qui contient des \\(1\\) sur le diagonale et des \\(0\\) sur les éléments hors de la diagonale. Soient \\(u\\) et \\(v\\) appartenant à \\(\\mathbb{R}^n\\), i.e. des vecteurs colonnes de taille \\(n\\).\n\n\n\n\n\n\nPropriétés de l’inverse de matrices\n\n\n\nSupposons que les matrices \\(A\\) et \\(B\\) soient inversibles. Alors le produit matriciel \\(AB\\) est inversible et est donné par:\n\\[(AB)^{-1} = B^{-1} A^{-1}.\\]\n\n\n\n\n\n\n\n\nPreuve\n\n\n\n\n\nPosons \\(C = AB\\) et \\(D = B^{-1} A^{-1}\\). Alors\n\\[\\begin{align*}\n  CD &= A B B^{-1} A^{-1} \\\\\n     &= A A^{-1} \\\\\n     &= I_n\n\\end{align*}\\]\nDe la même façon, on trouve que \\(DC = I_n\\). Ainsi, \\(AB\\) est inversible et son inverse est donné par \\(B^{-1} A^{-1}\\).\n\n\n\n\n\n\n\n\n\nPropriétés du déterminant de matrices\n\n\n\nConsidérant les matrices définies en début de section, on a :\n\n\\(\\text{det}(A^\\top) = \\text{det}(A)\\),\n\\(\\text{det}(AB) = \\text{det}(A)\\text{det}(B)\\),\n\\(\\text{det}(A^{-1}) = 1 / \\text{det}(A)\\).\n\n\n\n\n\n\n\n\n\nPreuve\n\n\n\n\n\nLes preuves des propriétés \\(1\\) et \\(2\\) sont techniques et sont omises, mais peuvent être trouvées, par exemple, ici. Pour ce qui est de la troisième propriété, par définition, on a \\(A A^{-1} = I_n\\). Le déterminant de \\(I_n\\) est égale à \\(1\\) (produit des éléments sur la diagonale). Donc \\(\\text{det}(A A^{-1}) = 1\\). Or, d’après la deuxième propriété, \\(\\text{det}(A A^{-1}) = \\text{det}(A)\\text{det}(A^{-1})\\). On a donc bien \\(\\text{det}(A^{-1}) = 1 / \\text{det}(A)\\).\n\n\n\n\n\n\n\n\n\nPropriétés de la trace de matrices\n\n\n\nConsidérant les matrices définies en début de section, on a :\n\n\\(\\text{tr}(A) = \\text{tr}(A^{\\top})\\),\n\\(\\text{tr}(A + B) = \\text{tr}(A) + \\text{tr}(B)\\),\n\\(\\text{tr}(MN^{\\top}) = \\text{tr}(N^{\\top}M)\\).\n\n\n\n\n\n\n\n\n\nPreuve\n\n\n\n\n\nPour une matrice carré \\(A\\), notons \\(a_{ij}\\), l’élément de la matrice \\(A\\) à la ligne \\(i\\) et à la colonne \\(j\\). La trace de \\(A\\) est donnée par la somme des éléments diagonaux, i.e. \\(\\text{tr}(A) = \\sum_{i = 1}^{n} a_{ii}\\).\n\nLa transposition ne changeant pas les éléments diagonaux, le résultat est direct.\nNotons \\(C = A + B\\). Comme \\(A\\) et \\(B\\) sont des matrices carrées, \\(C\\) est une matrice carrée. On a \\(c_{ij} = a_{ij} + b_{ij}\\) pour tout \\(i, j = 1, \\dots, n\\). Donc \\[\\text{tr}(A + B) = \\text{tr}(C) = \\sum_{i = 1}^{n} c_{ii} = \\sum_{i = 1}^{n} a_{ii} + b_{ii} = \\sum_{i = 1}^{n} a_{ii} + \\sum_{i = 1}^{n} b_{ii} = \\text{tr}(A) + \\text{tr}(B).\\]\nLes matrices \\(M N^{\\top}\\) et \\(N^{\\top} M\\) sont carrées, de dimension respectives \\(n \\times n\\) et \\(m \\times m\\), on peut donc bien calculer leur trace. Notons \\(C = M N^{\\top}\\) et \\(D = N^{\\top} M\\). \\[\\text{tr}(M N^{\\top}) = \\text{tr}(C) = \\sum_{i = 1}^{n} c_{ii} = \\sum_{i = 1}^{n} \\sum_{j = 1}^{m} m_{ij} n_{ji} = \\sum_{j = 1}^{m} \\sum_{i = 1}^{n} n_{ji} m_{ij} = \\sum_{j = 1}^{m} d_{jj} = \\text{tr}(D)  = \\text{tr}(N^{\\top} M).\\]\n\n\n\n\n\n\n\n\n\n\nDéfinition\n\n\n\n\nSoit \\(A\\) une matrice symétrique appartenant à \\(M_n(\\mathbb{R})\\). \\(A\\) est définie positive si \\(u^\\top A u &gt; 0\\) pour tout \\(u \\in \\mathbb{R}^n\\) tel que \\(u \\neq 0\\).\nSoit \\(A\\) appartenant à \\(M_n(\\mathbb{R})\\). \\(A\\) est orthogonal si \\(A^\\top A = A A^\\top = I_n\\).",
    "crumbs": [
      "Modules",
      "02 - Révisions",
      "Algèbre linéaire"
    ]
  },
  {
    "objectID": "contents/remainders/01-linear-algebra.html#valeurs-et-vecteurs-propres",
    "href": "contents/remainders/01-linear-algebra.html#valeurs-et-vecteurs-propres",
    "title": "Algèbre linéaire",
    "section": "Valeurs et vecteurs propres",
    "text": "Valeurs et vecteurs propres\n\n\n\n\n\n\nDéfinition\n\n\n\nSoit \\(A\\) appartenant à \\(M_n(\\mathbb{R})\\). On dit que \\(\\lambda \\in \\mathbb{R}\\) est une valeur propre de \\(A\\) s’il existe un vecteur \\(u \\in \\mathbb{R}^n\\) non nul tel que \\[Au = \\lambda u. \\tag{1}\\] Le vecteur \\(u\\) est appelé vecteur propre de \\(A\\) correspondant à la valeur propre \\(\\lambda\\).\nL’ensemble des nombres réels \\(\\lambda\\) satisfaisant Équation 1 est appelé spectre de la matrice \\(A\\) et noté \\(\\text{sp}(A)\\).\n\n\n\n\n\n\n\n\nPropriété des vecteurs propres\n\n\n\n\nSi \\(u\\) est un vecteur propre de \\(A\\) correspondant à une valeur propre \\(\\lambda\\), alors le vecteur \\(cu\\), \\(c \\in \\mathbb{R}^\\star\\) est également un vecteur propre de \\(A\\) correspondant à \\(\\lambda\\).\nSi \\(A\\) est symétrique et \\(u_{1}\\) et \\(u_{2}\\) sont des vecteurs propres correspondant à des valeurs propres différentes de \\(A\\), alors \\(u_{1}\\) et \\(u_{2}\\) sont orthogonaux, i.e. \\(u_{1}^\\top u_{2} = 0\\).\n\n\n\n\n\n\n\n\n\nPreuve\n\n\n\n\n\n\nSoit \\(c \\in \\mathbb{R}^\\star\\) et \\(u\\) un vecteur propre de \\(A\\) associé à la valeur propre \\(\\lambda\\). On a : \\[A(cu) = cAu = c \\lambda u = \\lambda (cu).\\] Donc, le vecteur \\(cu\\) est aussi vecteur propre de \\(A\\) associé à la valeur propre \\(\\lambda\\).\nSoient \\(\\lambda_{1}\\) et \\(\\lambda_{2}\\), les valeurs propres associées à \\(u_{1}\\) et \\(u_{2}\\), tel que \\(\\lambda_{1} \\neq \\lambda_{2}\\). On a \\(A u_{1} = \\lambda_{1} u_{1}\\) et \\(A u_{2} = \\lambda_{2} u_{2}\\). Ensuite \\[\\lambda_{1} u_{1}^{\\top} u_{2} = u_{1}^\\top A u_{2} = \\lambda_{2} u_{1}^\\top u_{2}.\\] Cela implique que \\((\\lambda_{1} - \\lambda_{2})u_{1}^\\top u_{2} = 0\\). Or, \\(\\lambda_{1} \\neq \\lambda_{2}\\). Donc, nécessairement, \\(u_{1}^\\top u_{2} = 0\\).\n\n\n\n\nCette deuxième propriété nous sera utile lorque l’on s’intéressera à la réduction de dimension et, en particulier, à l’analyse en composantes principales.\n\n\n\n\n\n\nCaractérisation de matrices avec ses éléments propres\n\n\n\n\nSi \\(A\\) est symétrique, alors toutes ses valeurs propres sont réelles.\nSi \\(A\\) est définie positive, alors toutes ses valeurs propres sont strictement positives.\n\n\n\n\n\n\n\n\n\nPreuve\n\n\n\n\n\n\nConsidérons le cas plus général où \\(A\\) est une matrice hermitenne. La matrice \\(A\\) est égale la transposé de son conjugué, noté \\(A^*\\). Notons \\(\\lambda\\) une valeur propre associée à un vecteur propre \\(u\\), éventuellement complexe. On a : \\[\\begin{align}\n\\overline{u}^{\\top} A u &= \\overline{u}^\\top \\lambda u = \\lambda \\overline{u}^{\\top} u, \\\\\n\\overline{u}^\\top A u &= \\overline{u}^\\top A^* u = \\overline{Au}^\\top u = \\overline{\\lambda} \\overline{u}^\\top u.\n\\end{align}\\] Cela implique que \\((\\lambda - \\overline{\\lambda}) \\overline{u}^{\\top} u = 0\\). Comme \\(u \\neq 0\\), on a \\(\\lambda = \\overline{\\lambda}\\). Donc \\(\\lambda \\in \\mathbb{R}\\).\nConsidérons \\(u\\), vecteur propre de \\(A\\) associé à la valeur propre \\(\\lambda\\). On a que \\(u^{\\top} A u = \\lambda u^{\\top} u\\). Or, comme \\(u \\neq 0\\), \\(u^{\\top}u \\neq 0\\). Donc \\[\\lambda = \\frac{u^{\\top} A u}{u^{\\top} u}.\\] Comme \\(A\\) est définie postive, \\(u^{\\top} A u &gt; 0\\) pour tout vecteur \\(u\\) non nul. On en déduit que \\(\\lambda &gt; 0\\).",
    "crumbs": [
      "Modules",
      "02 - Révisions",
      "Algèbre linéaire"
    ]
  },
  {
    "objectID": "contents/remainders/01-linear-algebra.html#diagonalisation-de-matrices",
    "href": "contents/remainders/01-linear-algebra.html#diagonalisation-de-matrices",
    "title": "Algèbre linéaire",
    "section": "Diagonalisation de matrices",
    "text": "Diagonalisation de matrices\n\n\n\n\n\n\nDéfinition\n\n\n\nSoit \\(A\\) appartenant à \\(M_n(\\mathbb{R})\\). On dit que \\(A\\) est diagonalisable s’il existe une matrice \\(P\\) appartenant à \\(M_n(\\mathbb{R})\\) non-singulière et une matrice diagonale \\(D\\) appartenant à \\(M_n(\\mathbb{R})\\) telles que \\[P^{-1} A P = D \\Longleftrightarrow A = P D P^{-1}.\\]\n\n\n\n\n\n\n\n\nThéorème de décomposition spectrale\n\n\n\nSoit \\(A\\) une matrice symmétrique appartenant à \\(M_n(\\mathbb{R})\\) et \\(\\lambda_{1}, \\dots, \\lambda_n\\), ses \\(n\\) valeurs propres. Alors, il existe une matrice orthogonal \\(P\\) appartenant à \\(M_n(\\mathbb{R})\\) telle que \\[A = P \\Lambda P^\\top, \\quad\\text{où}\\quad \\Lambda = \\text{diag}(\\lambda_1, \\dots, \\lambda_n).\\]\n\n\nSi \\(A\\) admet \\(n\\) valeurs propres positives distinctes, alors on peut prendre \\(P\\) comme étant la matrice dont la \\(k\\)-ième colonne est le vecteur propre normé correspondant à la \\(k\\)-ième valeur propre \\(\\lambda_k\\) de \\(A\\).\nSoit deux matrices symétriques, \\(A\\) et \\(B\\), comment déterminer le vecteur \\(u\\) tel que \\(u^{\\top} A u\\) soit maximal, sachant que \\(u^{\\top} B u = 1\\) ? Il suffit de prendre \\(u\\) comme le vecteur propre de \\(B^{-1}A\\) associé à \\(\\lambda\\) la valeur propre maximale de \\(B^{-1}A\\). On obtient ainsi \\[u^{\\top} A u = u^{\\top}\\lambda M u = \\lambda U^{\\top} M u = \\lambda.\\]\n\n\n\n\n\n\nCaractérisation du déterminant et de la trace de matrices avec ses éléments propres\n\n\n\nSi \\(A\\) a comme valeurs propres (réelles, mais pas forcément distinctes) \\(\\lambda_{1}, \\dots, \\lambda_{n}\\), alors\n\n\\(\\text{det}(A) = \\prod_{i = 1}^{n} \\lambda_i\\)\n\\(\\text{tr}(A) = \\sum_{i = 1}^{n} \\lambda_i.\\)\n\n\n\n\n\n\n\n\n\nPreuve\n\n\n\n\n\nEn utilisant le théorème de décomposition spectrale, il existe une matrice \\(P\\) inversible tel que \\(A = P \\Lambda P^{-1}\\), où \\(\\Lambda\\) est une matrice diagonale contenant les valeurs propres. On a donc, pour le déterminant,\n\\[\\text{det}(A) = \\text{det}(P \\Lambda P^{-1}) = \\text{det}(P)\\text{det}(\\Lambda)\\text{det}(P^{-1}) = \\text{det}(P)\\text{det}(\\Lambda)\\text{det}(P)^{-1} = \\text{det}(\\lambda) = \\prod_{i = 1}^{n} \\lambda_i, \\]\net, pour la trace,\n\\[\\text{tr}(A) = \\text{tr}(P \\Lambda P^{-1}) = \\text{tr}(P^{-1} P \\Lambda) = \\text{tr}(\\Lambda) = \\sum_{i = 1}^{n} \\lambda_i.\\]",
    "crumbs": [
      "Modules",
      "02 - Révisions",
      "Algèbre linéaire"
    ]
  },
  {
    "objectID": "contents/dimension/02-mca.html",
    "href": "contents/dimension/02-mca.html",
    "title": "ACM",
    "section": "",
    "text": "L’analyse en composantes principales concerne des données continues. Que faire lorsque les variables sont rapportées dans des tableaux de contingences où alors comme réponses à des questionnaires à choix multiples ? Que faire lorsque les variables sont catégorielles ? Il est possible de faire la même chose que pour l’ACP pour des variables catégorielles, cette méthode s’appelle l’analyse des correspondances (AC). Cette méthode permet de représenter graphiquement des tableaux de fréquence. Pour des tableaux de fréquences croisant deux variables, on parlera d’analyse des correspondances bianires (ACB) ou alors d’analyse factorielle des correspondances (AFC). Pour des tableaux de fréquences croisant troix variables ou plus, on parlera d’analyse des correspondances multiples (ACM).\n\n\n\n\n\n\nExamples\n\n\n\nLa boussole électorale de Radio-Canada. Étude sur les clients d’une compagnie de télécom. Relation entre la couleur des yeux et des cheveux.",
    "crumbs": [
      "Modules",
      "04 - Dimension",
      "ACM"
    ]
  },
  {
    "objectID": "contents/dimension/02-mca.html#introduction",
    "href": "contents/dimension/02-mca.html#introduction",
    "title": "ACM",
    "section": "",
    "text": "L’analyse en composantes principales concerne des données continues. Que faire lorsque les variables sont rapportées dans des tableaux de contingences où alors comme réponses à des questionnaires à choix multiples ? Que faire lorsque les variables sont catégorielles ? Il est possible de faire la même chose que pour l’ACP pour des variables catégorielles, cette méthode s’appelle l’analyse des correspondances (AC). Cette méthode permet de représenter graphiquement des tableaux de fréquence. Pour des tableaux de fréquences croisant deux variables, on parlera d’analyse des correspondances bianires (ACB) ou alors d’analyse factorielle des correspondances (AFC). Pour des tableaux de fréquences croisant troix variables ou plus, on parlera d’analyse des correspondances multiples (ACM).\n\n\n\n\n\n\nExamples\n\n\n\nLa boussole électorale de Radio-Canada. Étude sur les clients d’une compagnie de télécom. Relation entre la couleur des yeux et des cheveux.",
    "crumbs": [
      "Modules",
      "04 - Dimension",
      "ACM"
    ]
  },
  {
    "objectID": "contents/dimension/02-mca.html#notation",
    "href": "contents/dimension/02-mca.html#notation",
    "title": "ACM",
    "section": "Notation",
    "text": "Notation\nNotation: Soit \\(K = (k_{ij})\\), où \\(k_{ij}\\) est le nombre d’individus appartenant à la classe \\(i \\in \\{ 1, \\dots, n \\}\\) et à la catégorie \\(j \\in \\{ 1, \\dots, p \\}\\).\nTableau des fréquences relatives: Comme les fréquences sont proportionnelles à la taille d’échantillon \\(n\\), le tableau des fréquences relatives contient plus d’information : \\(F = (f_{ij})\\), dans lequel \\[f_{ij} = \\frac{k_{ij}}{k_{\\bullet\\bullet}} = \\frac{k_{ij}}{\\sum_{l = 1}^{n} \\sum_{m = 1}^{p} k_{lm}}.\\]\nLes marges du tableau correspondent à la somme des colonnes pour chaque ligne et de la somme des lignes pour chaque colonne: \\[\\begin{align}\nf_{i \\bullet} &= \\sum_{j = 1}^{p} f_{ij} = \\frac{k_{i \\bullet}}{k_{\\bullet\\bullet}}, \\quad 1 \\leq i \\leq n; \\\\\nf_{\\bullet j} &= \\sum_{i = 1}^{n} f_{ij} = \\frac{k_{\\bullet j}}{k_{\\bullet\\bullet}}, \\quad 1 \\leq j \\leq p.\n\\end{align}\\]\nLes fréquences relatives estiment des probabilités. Dans le cas d’un tableau de fréquences croisant deux variables, sous l’hypothèse d’indépendance, les fréquences relatives devraient être telles qu’on ne s’éloigne pas trop de la relation \\[f_{ij} = f_{i \\bullet} f_{\\bullet j}, \\quad i \\in \\{ 1, \\dots, n \\}, j \\in \\{ 1, \\dots, p \\}.\\]\nStatistique du \\(\\chi^{2}\\): on peut tester si les différences entre \\(f_{ij}\\) et \\(f_{i \\bullet} f_{\\bullet j}\\) sont significatives à l’aide du test du \\(\\chi^2\\): \\[T = \\sum_{i = 1}^{n} \\sum_{j = 1}^{p} \\frac{\\left( k_{ij} - \\mathbb{E}(k_{ij}) \\right)^2}{\\mathbb{E}(k_{ij})} = \\sum_{i = 1}^{n} \\sum_{j = 1}^{p} \\frac{\\left( k_{ij} - \\frac{k_{i \\bullet}k_{\\bullet j}}{k_{\\bullet\\bullet}} \\right)^2}{\\left( \\frac{k_{i \\bullet} k_{\\bullet j}}{k_{\\bullet\\bullet}} \\right)}.\\]\nSi les variables sont indépendantes, la statistique \\(T\\) dit être proche de \\(0\\).\nOn peut aussi s’intéresser à la contribution de chaque cellule à la valeur globale de la statistique \\(T\\). Cela permet d’obtenir le profil de chaque ligne \\(i\\) et de chaque colonne \\(j\\). \\[\\begin{align}\nL_i &= \\left( \\frac{k_{i 1}}{k_{i \\bullet}}, \\dots, \\frac{k_{i p}}{k_{i \\bullet}} \\right) &= \\left( \\frac{f_{i 1}}{f_{i \\bullet}}, \\dots, \\frac{f_{i p}}{f_{i \\bullet}} \\right) \\\\\nC_j &= \\left( \\frac{k_{1 j}}{k_{\\bullet j}}, \\dots, \\frac{k_{n j}}{k_{\\bullet j}} \\right) &= \\left( \\frac{f_{1 j}}{f_{\\bullet j}}, \\dots, \\frac{f_{n j}}{f_{\\bullet j}} \\right)\n.\n\\end{align}\\]\nLe profil-ligne moyen est donné par \\[\\left( \\sum_{i = 1}^{n} f_{i \\bullet} \\frac{f_{i 1}}{f_{i \\bullet}}, \\dots, \\sum_{i = 1}^{n} f_{i \\bullet} \\frac{f_{i p}}{f_{i \\bullet}} \\right) = \\left( f_{\\bullet 1}, \\dots, f_{\\bullet p} \\right).\\] Le profil-colonne moyen est donné par \\[\\left( \\sum_{j = 1}^{p} f_{{\\bullet j}} \\frac{f_{1 j}}{f_{\\bullet j}}, \\dots, \\sum_{j = 1}^{p} f_{\\bullet j} \\frac{f_{n j}}{f_{\\bullet j}} \\right) = \\left( f_{{1 \\bullet}}, \\dots, f_{n \\bullet} \\right).\\]\nEn cas d’indépendance, on a, pour tout \\(i \\in \\{ 1, \\dots, n \\}\\) et \\(j \\in \\{ 1, \\dots, p \\}\\), \\[\\left( \\frac{f_{i 1}}{f_{i \\bullet}}, \\dots, \\frac{f_{i p}}{f_{i \\bullet}} \\right) = \\left( f_{\\bullet 1}, \\dots, f_{\\bullet p} \\right) \\quad\\text{et}\\quad\n\\left( \\frac{f_{1 j}}{f_{\\bullet j}}, \\dots, \\frac{f_{n j}}{f_{\\bullet j}} \\right) = \\left( f_{{1 \\bullet}}, \\dots, f_{n \\bullet} \\right).\\]\nLa dépendance entre les variables est fonction de la ressemblance entre les profils des lignes et les profils des colonnes. On peut mesurer et visualiser cette de diverses manières.\nOn peut mesurer la distance entre deux profils-lignes avec la distance du \\(\\chi^2\\), qui tient compte de l’importance de chaque colonne: \\[d^2(i, i^\\prime) = \\sum_{j = 1}^{p} \\frac{1}{f_{\\bullet j}} \\left( \\frac{f_{ij}}{f_{i \\bullet}} - \\frac{f_{i^\\prime j}}{f_{i^\\prime j}} \\right)^2.\\]\nOn peut écrire cela sous forme matricielle. Notons \\(D_n = \\text{diag}(f_{i \\bullet}\\) et \\(D_p = \\text{diag}(f_{\\bullet j}\\). On a que la matrice \\(D_n^{-1}F\\) a pour lignes les profils-lignes et la matrice \\(D_p^{-1}F^{\\top}\\) a pour lignes les profils-colonnes.\nEn utilisant ces matrices, la distance du \\(\\chi^2\\) au carré est de la forme \\(x^{\\top}D_p^{-1}x\\) pour un point-ligne \\(x \\in \\mathbb{R}^p\\) et de la forme \\(x^{\\top}D_n^{-1}x\\) pour un point-colonne \\(x \\in \\mathbb{R}^n\\).",
    "crumbs": [
      "Modules",
      "04 - Dimension",
      "ACM"
    ]
  },
  {
    "objectID": "contents/dimension/02-mca.html#analyse-factorielle-des-correspondances",
    "href": "contents/dimension/02-mca.html#analyse-factorielle-des-correspondances",
    "title": "ACM",
    "section": "Analyse factorielle des correspondances",
    "text": "Analyse factorielle des correspondances\nL’analyse factorielle des correspondances est une approche graphique permettant de représenter simultanément les profils-lignes appartenant à \\(\\mathbb{R}^p\\) et les profils-colonnes appartenant à \\(\\mathbb{R}^n\\) d’un tableau de fréquences. On cherche donc un espace en deux dimensions où projeter les profils lignes et colonnes de sorte que les points dans cet espace soient le plus près possible des points originaux au sens de la distance du \\(\\chi^2\\). L’analyse des correspondances est très similaire à une double ACP.\nAnalyse directe (sur les lignes): les lignes de la matrice \\(D_n^{-1}F \\in \\mathbb{R}^p\\). On cherche à les représenter dans cet espace muni de la distance \\(x^{\\top} D_p^{-1} x\\).\nAnalyse duale (sur les colonnes): les colonnes de la matrice \\(D_p^{-1}F^{\\top} \\in R^n\\). On cherche à les représenter dans cet espace muni de la distance \\(x^{\\top} D_n^{-1} x\\).\nPremier axe factoriel de l’analyse directe: on cherche le vecteur \\(u \\in \\mathbb{R}^p\\) tel que \\[\\left( u^{\\top} D_p^{-1} F^{\\top} D_n^{-1} \\right) D_n \\left( D_n^{-1} F D_p^{-1} u \\right).\\] soit maximal, sachant que \\(u^{\\top} D_p^{-1} u = 1\\). La solution est donnée par le vecteur propre principal de \\[D_p \\left( D_p^{-1} F^{\\top} D_n^{-1} F D_p^{-1} \\right) = F^{\\top} D_n^{-1} F D_p^{-1} \\equiv S.\\]\nLes formules des coordonnées dans le système d’axes sont plutôt complexes et pas très parlantes… mais à remarquer:\n\n\\(S\\) et \\(T\\) ont les mêmes \\(p\\) premières valeurs propres.\nEn centrant les profils lignes et colonnes, on peut illustrer le résultat des deux graphiques sur les mêmes axes.",
    "crumbs": [
      "Modules",
      "04 - Dimension",
      "ACM"
    ]
  },
  {
    "objectID": "contents/dimension/02-mca.html#centre-de-gravité-et-inertie",
    "href": "contents/dimension/02-mca.html#centre-de-gravité-et-inertie",
    "title": "ACM",
    "section": "Centre de gravité et inertie",
    "text": "Centre de gravité et inertie\nLes logiciels produisent généralement un graphique centré en \\((0, 0)\\). Il s’agit d’une analyse relative aux centres de gravité des lignes et des colonnes. Cette pratique est à la fois commune et commode. En fait, la masse de la \\(i\\)e ligne est \\(f_{i \\bullet}\\), soit la proportion des observations qui tombent sur cette ligne. De faon similaire, la masse de la \\(j\\)e colonne est \\(f_{\\bullet j}\\). Le centre de gravité des lignes est la moyenne des profils-lignes, mais pondérée par la masse de chaque ligne, et similairement pour les profils-colonnes.\nLe centre de gravité des lignes est défini par \\(G_L = \\left( g_{1}, \\dots, g_{p} \\right)^top\\), où \\[g_j = \\sum_{i = 1}^{n} f_{i \\bullet} \\frac{f_{i j}}{f_{i \\bullet}} = \\sum_{i = 1}^{n} f_{i j} = f_{\\bullet j}, \\quad 1 \\leq j \\leq p.\\]\nDe même, le centre de gravité des colonnes est défini par \\[G_C = \\left( f_{1 \\bullet}, \\dots, f_{n \\bullet} \\right)^top.\\]\nCentrage des lignes: \\[\\frac{f_{i j}}{f_{i \\bullet}} - g_{j} = \\frac{f_{i j}}{f_{i \\bullet}} - f_{\\bullet j} = \\frac{f_{i j} - f_{i \\bullet} f_{\\bullet j}}{f_{i \\bullet}}.\\] de sorte que, pour tout \\(i \\in \\{ 1, \\dots, n \\}\\), \\[\\sum_{j = 1}^{p} \\frac{f_{i j} - f_{i \\bullet}f_{\\bullet j}}{f_{i \\bullet}} = 0.\\]\nL’analyse ne se fait plus sur \\[S = F^{\\top} D_n^{-1} F D_p^{-1},\\] mais plutôt sur \\(S^\\star = (s_{j j^\\prime}^\\star),\\) où \\[s_{j j^\\prime}^\\star = \\sum_{i = 1}^{n} \\frac{\\left( f_{i j} - f_{i \\bullet} f_{\\bullet j} \\right) \\left( f_{i j^\\prime} - f_{i \\bullet} f_{\\bullet j^\\prime} \\right)}{f_{i \\bullet} f_{\\bullet j^\\prime}}.\\]\nPar définition, \\[\\text{tr}(S^\\star) = \\sum_{j = 1}^{p} \\sum_{i = 1}^{n} \\frac{\\left( f_{i j} - f_{i \\bullet}f_{\\bullet j} \\right)^2}{f_{i \\bullet} f_{\\bullet j}}.\\]\nOn retrouve l’expression de la statistique du \\(\\chi^2\\) servant à tester l’indépendance entre deux variables.\nOn peut prouver que \\(s_{j j^\\prime}^\\star = s_{j j^\\prime} - f_{\\bullet j},\\) où \\[s_{j j^\\prime} = \\sum_{i = 1}^{n} \\frac{f_{i j}f_{i j^\\prime}}{f_{i \\bullet} f_{\\bullet j^\\prime}}.\\] Ceci entraîne que ces deux matrices ont les mêmes \\(p\\) premiers vecteurs propres normalisés.\nCoordonnées des points-lignes. La projection du \\(i\\)e point-ligne sur l’axe \\(j\\) est donnée par \\[\\left( D_n^{-1} F \\phi_j \\right)_i = \\frac{1}{f_{i \\bullet}} \\sum_{j^\\prime = 1}^{p} f_{i j^\\prime} \\phi_{j j^\\prime} = \\sqrt{\\lambda_j} \\Psi_{j i} \\equiv \\widehat{\\Psi}_{j i}.\\] De plus, \\[\\sum_{i = 1}^{n} f_{i \\bullet} \\widehat{\\Psi}^2_{j i} = \\sum_{i = 1}^{n} f_{i \\bullet} \\left( \\sqrt{\\lambda_j} \\Psi_{j i} \\right)^2 = \\lambda_j.\\]\nCoordonnées des point-colonne. La projection du \\(k\\)e point-ligne sur l’axe \\(j\\) est donnée par \\[\\left( D_p^{-1} F^{\\top} \\psi_j \\right)_k = \\frac{1}{f_{\\bullet k}} \\sum_{i = 1}^{n} f_{i k} \\psi_{j i} = \\sqrt{\\lambda_j} \\Phi_{j k} \\equiv \\widehat{\\Phi}_{j k}.\\] De plus, \\[\\sum_{k = 1}^{p} f_{\\bullet k} \\widehat{\\Phi}^2_{j k} = \\sum_{k = 1}^{p} f_{\\bullet k} \\left( \\sqrt{\\lambda_j} \\Phi_{j k} \\right)^2 = \\lambda_j.\\]\nL’inertie absolue du \\(i\\)e point-ligne sur l’axe \\(j\\) est \\(f_{i \\bullet}\\widehat{\\Psi}_{j i}^2\\). L’inertie relative du \\(i\\)e point-ligne sur l’axe \\(j\\) est \\[\\frac{f_{i \\bullet} \\widehat{\\Psi}_{j i}^2}{\\lambda_j}.\\]\nL’inertie absolue du \\(k\\)e point-colonne sur l’axe \\(j\\) est \\(f_{\\bullet k}\\widehat{\\Phi}_{j k}^2\\). L’inertie relative du \\(k\\)e point-colonne sur l’axe \\(j\\) est \\[\\frac{f_{\\bullet k} \\widehat{\\Phi}_{j k}^2}{\\lambda_j}.\\]\nL’inertie totale est \\(I = T / k_{\\bullet\\bullet}\\).\nla qualité de la représentation du \\(k\\)e point-colonne dans l’axe \\(j\\) est donnée par \\[\\frac{d_j^2(k, G_C)}{d^2(k, G_c)} = \\cos^2(\\theta_{k j}),\\] où \\(\\theta_{k j}\\) est l’angle entre le point \\(k\\) et sa projection sur l’axe \\(j\\).\nInterprétation:\n\nPlus les \\(\\cos^2(\\theta_{k j})\\) sont élevés, mieux les points sont représentés sur l’axe \\(j\\).\nCeci ne signifie pas pour autant que les points sont près du centre du graphique.\nLes points éloignés du centre de gravité se distinguent du centre de gravité.\nUne interprétation semblable existe pour les points-lignes.",
    "crumbs": [
      "Modules",
      "04 - Dimension",
      "ACM"
    ]
  },
  {
    "objectID": "contents/dimension/02-mca.html#example",
    "href": "contents/dimension/02-mca.html#example",
    "title": "ACM",
    "section": "Example",
    "text": "Example",
    "crumbs": [
      "Modules",
      "04 - Dimension",
      "ACM"
    ]
  },
  {
    "objectID": "contents/dimension/02-mca.html#analyse-des-correspondances-multiples",
    "href": "contents/dimension/02-mca.html#analyse-des-correspondances-multiples",
    "title": "ACM",
    "section": "Analyse des correspondances multiples",
    "text": "Analyse des correspondances multiples\nL’analyse des correspondances multiples est une généralisation de l’analyse des correspondances binaires. Elle permet la representation graphique de tableaux de fréquences contnant plus de deux variables. Un exemple classique d’un tableau de fréquences avec plus de deux variables est le tableau présentant les réponses d’individus à un questionnaire contenant \\(Q\\) questions à choix multiples.\nTrès utile pour visualiser les résultats d’une étude par questionnaire.\nL’ACM peut aussi être vue comme une version de l’ACP quand les variables sont catégorielles:\n\nl’analyse duale permet de voir les individus ayant des profils de réponses similaires\non peut obtenir des scores continus pour les individus qui capturent une grande partie de l’information\ndonc aussi utile pour scorer les résultats d’une étude par questionnaire dans un but éventuel de partitionnement, par exemple\n\nEn général, pour un questionnaire contenant \\(Q\\) questions, on a un tableau de la forme suivante: \\[Z = \\left[ Z_1 \\mid \\cdots \\mid Z_{Q} \\right].\\]\nNotation:\n\n\\(Q\\): nombre de questions\n\\(n\\): nombre d’individus répondant au questionnaire\n\\(p_q\\): nombre de modalités (choix de réponses) de la question \\(q\\).\n\\(p = p_{1} + p_{Q}\\)\n\nPotentiel problème: plus le nombre de questions est grand, plus il y aura de cellules vides. C’est aussi le cas si le nombre de réponses aux questions est important. La proportion de cellules non vides est \\[\\frac{nQ}{np} = \\frac{Q}{p}.\\].\nSi toutes les questions ont le même nombre de choix de réponses, alors \\(p_{1} = \\dots = p_{Q} = \\frac{p}{Q}\\), de sorte que \\[\\frac{Q}{p} = \\frac{1}{p_{1}} \\longrightarrow 0, \\quad\\text{quand}~ p_{1} \\rightarrow \\infty.\\]\nLe tableau résumé est un tableau de taille \\(n \\times Q\\). Il contient le numéro de la modalité associée à la réponse de chaque individu pour chacune des questions.\nLa tableau de Burt est une autre faon de présenter un tableau de fréquences contenant plus de deux variables. Étant donné un tableau logique \\(Z = \\left[ Z_{1} \\mid \\cdots \\mid Z_{Q} \\right]\\), le tableau de Burt associé est la matrice carrée \\(p \\times p\\) définie comme étant \\[ B = \\begin{pmatrix}\n  Z_1^\\top Z_1 & \\cdots & Z_1^\\top Z_Q \\\\\n  \\vdots & \\ddots & \\vdots \\\\\n  Z_Q^\\top Z_1 & \\cdots & Z_Q^\\top Z_Q\n\\end{pmatrix}.\\]\n\n\n\n\n\n\nPropriétés de \\(Z_q^\\top Z_q\\)\n\n\n\n\n\\(Z_{q}^\\top Z_q\\) est une matrice diagonale \\(p_q \\times p_q\\) présentant les réponses à la \\(q\\)e question.\nL’élément \\((j, j)\\) de la matrice \\(Z_q^\\top Z_q\\) est égal au nombre d’individus \\(d_{jj}\\) qui appartiennent à la \\(j\\)e catégorie de la \\(q\\)e question.\n\\(Z_{q}^\\top Z_{r}\\) est le tableau de fréquences présentant les répones au x \\(q\\)e et \\(r\\)e questions.\nL’élément \\((j, k)\\) de la matrice \\(Z_q^\\top Z_r\\) est égal au nombre d’individus \\(d_{jk}\\) qui appartiennent à la \\(j\\)e catégorie de la \\(q\\)e question et à la \\(k\\)e catégorie de la \\(r\\)e question.\n\n\n\nD’un point de vue mathématique, l’ACM est une AFC effectuée sur la matrice logique \\(Z\\) ou sur le tableau de Burt \\(B\\). On peut démontrer que l’on obtient les mêmes facteurs, et ce, peu importe la matrice utilisé pour l’analyse.\n\n\n\n\n\n\nNote\n\n\n\nOn peut créé un graphique comme l’AFC. Cependant, en ACM, la distance entre les points de même couleur et la géométrie globale du graphique ne peuvent pas s’interpréter comme en AFC. En fait, on s’intéresse aux points qui sont dans une même direction par rapport à l’origine.",
    "crumbs": [
      "Modules",
      "04 - Dimension",
      "ACM"
    ]
  },
  {
    "objectID": "contents/dimension/02-mca.html#example-1",
    "href": "contents/dimension/02-mca.html#example-1",
    "title": "ACM",
    "section": "Example",
    "text": "Example",
    "crumbs": [
      "Modules",
      "04 - Dimension",
      "ACM"
    ]
  },
  {
    "objectID": "contents/dimension/01-pca.html",
    "href": "contents/dimension/01-pca.html",
    "title": "ACP",
    "section": "",
    "text": "Il y a plusieurs raisons de vouloir changer le dimension des données. Il est possible que la dimension des données soit trop importante pour avoir une visualisation intéressante, que la dimension actuelle ne permette pas une bonne séparation des classes dans les données, etc.",
    "crumbs": [
      "Modules",
      "04 - Dimension",
      "ACP"
    ]
  },
  {
    "objectID": "contents/dimension/01-pca.html#changer-de-dimension---pourquoi-faire",
    "href": "contents/dimension/01-pca.html#changer-de-dimension---pourquoi-faire",
    "title": "ACP",
    "section": "",
    "text": "Il y a plusieurs raisons de vouloir changer le dimension des données. Il est possible que la dimension des données soit trop importante pour avoir une visualisation intéressante, que la dimension actuelle ne permette pas une bonne séparation des classes dans les données, etc.",
    "crumbs": [
      "Modules",
      "04 - Dimension",
      "ACP"
    ]
  },
  {
    "objectID": "contents/dimension/01-pca.html#analyse-en-composantes-principales",
    "href": "contents/dimension/01-pca.html#analyse-en-composantes-principales",
    "title": "ACP",
    "section": "Analyse en composantes principales",
    "text": "Analyse en composantes principales\nL’analyse en composantes principales (ACP) est une méthode permettant de réduire la dimension d’un jeu de données tout en conservant le plus d’information possible. Cette méthode est utilisée lorsque l’on a \\(n\\) observations de \\(p\\) variables continues avec \\(p\\) trop “grand” pour nos besoins.\nPourquoi l’ACP est-elle utilisée ?\n\nVisualisation d’un jeu de données;\nRéduction du nombre de variables de \\(p\\) à \\(p^{\\prime} \\ll p\\) pour faciliter la construction de modèle. Exemples: analyse de texte, analyse de données génétique;\nEffectuer une rotation d’axes pour simplifier la structure de corrélation;\nCompression de données.\n\nLa méthode a été introduite par H. Hotelling dans (Hotelling 1933).\nVisualiser, comprendre, modéliser, classifier des données sont toutes des tâches beacoup simples à accomplir si le nomnre de variables dans un jeu de données est faible. Si un jeu de données comprend un grand nombre de variables, une première question que l’on peut se poser est: “Est-il possible de réduire la dimension du problème sans trop perdre d’information ?”. En omettant tout simplement des variables, on risque de perdre beaucoup d’information utile. Une meilleure solution consiste à trouver des combinaisons linéaires des variables en vue de conserver le maximum d’information sur le jeu de données.\n\n\n\n\n\n\nExample\n\n\n\n\nComparer des équipes de hockey sur la base de six statistiques de fin de saison.\nComparer la criminalité entre états sur la base des taux de sept types de crimes différents.\nCompresser des images formées de \\(1084 \\times 1084\\) pixels.\nIdentifier le nombre de variantes d’un type de tumeur à partir du degré d’expression de millions de gènes.\n\n\n\n\nLes maths\nSoit un vecteur aléatoire composé de \\(p\\) variables \\(X = \\left( X_{1}, \\dots, X_p \\right)\\) ayant comme matrice de variance \\(\\Sigma\\). On aimerait définir une première composante principale, \\[Y_{1} = \\alpha_{1}^{\\top} X = \\sum_{i = 1}^{p} \\alpha_{1i}X_i,\\] de sorte que la variance de \\(Y_{1}\\) soit maximale. L’idée est simple: on désire combiner \\(p\\) variables en une seule, mais en “capturant” la plus grande partie possible de la variabilité.\nIl faut d’abord ajouter une contrainte sur \\(\\alpha_{1}\\), puisque sinon on n’aurait qu’à prendre \\(\\alpha_{1i} = \\pm \\infty\\) et on aurait \\(\\mathrm{Var}(Y_{1}) = +\\infty\\) ce qui est définitivement maximal ! On verra qu’il est pratique de contraindre \\(\\alpha_{1}\\) de sorte qu’il ait une norme égale à \\(1\\).\n\nCalcul de la première composante:\n\n\\[\\mathrm{Var}(Y_1) = \\alpha_1^\\top \\Sigma \\alpha_{1} \\]\nLe problème est donc de maximiser \\[F(\\alpha_{1} = \\alpha_{1}^\\top \\Sigma \\alpha_1, \\quad\\text{s.c.}\\quad \\alpha_1^\\top \\alpha_1 = 1.\\]\nOn peut récrire ce problème à l’aide des multiplicateurs de Lagrange, soit maximiser \\[F(\\alpha_1, \\lambda) = \\alpha_1^\\top \\Sigma \\alpha_1 - \\lambda (\\alpha_1^\\top \\alpha_1 -1 ),\\] où \\(\\lambda\\) est un multiplicateur de Lagrange.\nPour solutionner ce problème, on dérive \\(F\\) par rapport à \\(\\alpha_{1}\\) et à \\(\\lambda\\).\n\\[\\begin{cases}\n\\frac{\\partial F(\\alpha_{1}, \\lambda)}{\\partial \\alpha_{1}} = 2 \\Sigma \\alpha_{1} - 2 \\lambda \\alpha_{1} \\\\\n\\frac{\\partial F(\\alpha_{1}, \\lambda)}{\\partial \\lambda} = 1 - \\alpha_{1}^\\top \\alpha_{1}\n\\end{cases}\n.\\]\nEnsuite, on égalise à \\(0\\), ce qui donne: \\[\\begin{cases}\n\\Sigma \\alpha_{1} = \\lambda \\alpha_{1} \\\\\n\\alpha_{1}^\\top \\alpha_{1} = 1\n\\end{cases}\n.\\] La seconde équation est bien entendue notre contrainte. La première équation est celle qui nous intéresse. En utilisant cette équation et la définition des éléments propres, on déduit que\n\n\\(\\alpha_{1}\\) est un vecteur propre (normé) de \\(\\Sigma\\);\n\\(\\lambda\\) est la valeur propre correspondante.\n\nOn a donc que \\[\\mathrm{Var}(Y_{1}) = \\alpha_{1}^\\top \\Sigma \\alpha_{1} = \\lambda \\alpha_{1}^\\top \\alpha_1 = \\lambda.\\] Puisque l’on veut maximiser cette quantité, on conclut que:\n\n\\(\\lambda = \\lambda_{1}\\), la plus grande valeur propre de \\(\\Sigma\\);\n\\(\\alpha_{1}\\), le vecteur propre normé correspondant.\n\n\nCalcul de la deuxième composante:\n\nOn poursuit simultanément deux objectifs:\n\nConserver le maximum de variation présente dans \\(X\\);\nSimplifier la structure de dépendancce pour faciliter l’interprétation et assurer la stabilité numérique d’éventuelles méthodes qui utiliseront les composantes principales obtenues.\n\nÉtant donné \\(Y_{1}\\), la deuxième composante principale \\(Y_{2} = \\alpha_{2}^\\top X\\) est définie telle que\n\n\\(\\mathrm{Var}(Y_{2}) = \\alpha_{2}^\\top \\Sigma \\alpha_{2}\\) est maximale;\n\\(\\alpha_{2}^\\top \\alpha_{2} = 1\\);\n\\(\\mathrm{Cov}(Y_{1}, Y_{2}) = 0\\).\n\nOn a que \\[\\mathrm{Cov}(Y_{1}, Y_{2}) = \\mathrm{Cov}(\\alpha_{1}^\\top X, \\alpha_{2}^\\top X) = \\alpha_{1}^\\top \\Sigma \\alpha_{2} = \\alpha_{2}^\\top \\Sigma \\alpha_{1} = \\lambda_{1} \\alpha_{2}^\\top \\alpha_{1}.\\]\nOn cherche donc le vecteur \\(\\alpha_{2}\\) qui maximise: \\[F(\\alpha_{2}, \\lambda, \\kappa) = \\alpha_{2}^\\top \\Sigma \\alpha_{2} - \\lambda (\\alpha_{2}^\\top \\alpha_{2} - 1) - \\kappa (\\alpha_{2}^\\top \\alpha_{1} - 0).\\]\nDe même que pour la première composante, on dérive \\(F\\) par rapport à \\(\\alpha_{2}\\), \\(\\lambda\\) et \\(\\kappa\\).\n\\[\\begin{cases}\n\\frac{\\partial F(\\alpha_{2}, \\lambda, \\kappa)}{\\partial \\alpha_{2}} = 2 \\Sigma \\alpha_{2} - 2 \\lambda \\alpha_{2} - \\kappa \\alpha_1 \\\\\n\\frac{\\partial F(\\alpha_{2}, \\lambda, \\kappa)}{\\partial \\lambda} = 1 - \\alpha_{2}^\\top \\alpha_{2} \\\\\n\\frac{\\partial F(\\alpha_{2}, \\lambda, \\kappa)}{\\partial \\kappa} = - \\alpha_2^\\top \\alpha_1\n\\end{cases}\n\\]\nEn égalisant les équations à \\(0\\), on retrouve les deux équations des contraintes, ainsi que\n\\[2 \\Sigma \\alpha_{2} - 2 \\lambda \\alpha_{2} - \\kappa \\alpha_{1} = 0.\\]\nEn multipliant cette équation à gauche et à droite par \\(\\alpha_{1}^\\top\\), on trouve\n\\[2 \\alpha_{1}^\\top \\Sigma \\alpha_{2} - 2 \\alpha_{1}^\\top \\lambda \\alpha_{2} - \\kappa \\alpha_{1}^\\top \\alpha_{1} = 0.\\]\nOr \\(\\alpha_{1}^\\top \\Sigma = \\lambda_{1} \\alpha_{1}^\\top\\), et \\(\\lambda_{1}^\\top \\alpha_{1} = 1\\), donc \\[2 \\alpha_{1}^\\top \\lambda \\alpha_{2} - 2 \\alpha_{1}^\\top \\lambda \\alpha_{2} - \\kappa \\alpha_{1}^\\top \\alpha_{1} = 0 \\implies - \\kappa = 0.\\]\nEn substituant ce résulat, on obtient \\[\\Sigma \\alpha_{2} = \\lambda \\alpha_{2}.\\]\net donc \\(\\lambda\\) est une autre valeur propre de \\(\\Sigma\\). Puisque \\[\\mathrm{Var}(Y_{2} = \\alpha_{2}^\\top \\Sigma \\alpha_{2} = \\alpha_{2}^\\top \\lambda \\alpha_{2} = \\lambda,\\] on a que cette variance est maximale si \\(\\lambda = \\lambda_{2}\\), la deuxième plus grande valeur propre de \\(\\Sigma\\), et conséquemment \\(\\alpha_{2}\\) est le vecteur propre normé correspondant.\nOn peut généraliser ce résultat en utilisant des maximisations successives. On en conclut que \\[Y_k = \\alpha_k^\\top X,\\] où \\(\\alpha_k\\) est le vecteur propre normé associé à \\(\\lambda_k\\), la \\(k\\)e plus grande valeur propre de \\(\\Sigma\\).\n\nNotation matricielle:\n\nPour définir simultanément et de facon plus compacte les composantes principales, on pose \\[Y = AX,\\] où \\[A = \\left( \\alpha_{1}, \\dots, \\alpha_{p} \\right) = \\begin{pmatrix}\n  \\alpha_{1, 1} & \\alpha_{2, 1} & \\cdots & \\alpha_{p, 1} \\\\\n  \\alpha_{1, 1} & \\alpha_{2, 2} & \\cdots & \\alpha_{p, 1} \\\\\n  \\vdots & \\vdots & \\ddots & \\vdots \\\\\n  \\alpha_{1, p} & \\alpha_{2, p} & \\cdots & \\alpha_{p, p}\n\\end{pmatrix}.\\]\n\n\n\n\n\n\nPropriétés de \\(A\\)\n\n\n\n\nLes colonnes de la matrice \\(A\\) sont les vecteurs propres de \\(\\Sigma\\);\n\\(A^{\\top} A = A A^{\\top} = I_p\\);\n\\(A^{\\top} = A^{-1}\\);\n\\(\\Sigma A = A \\Lambda\\), où \\(\\Lambda = \\text{diag}(\\lambda_{1}, \\dots, \\lambda_p)\\);\n\\(\\mathrm{Var}(Y) = A^{\\top} \\Sigma A = \\Lambda \\implies \\mathrm{Cov}(Y_i, Y_j) = 0\\) si \\(i \\neq j\\) et \\(\\mathrm{Var}(Y_i) = \\lambda_i \\geq \\mathrm{Var}(Y_j) = \\lambda_j\\) si et seulement si \\(i \\leq j\\).\n\n\n\nUne mesure globale de la variation presente dans les données est donnée par la trace de la matrice \\(\\Sigma\\): \\[\\text{tr}(\\Sigma) = \\text{tr}(\\Lambda) = \\sum_{i = 1}^{p} \\lambda_i.\\]\nLa proportion de variation expliquée par la composante principale \\(Y_i\\) est \\[\\frac{\\lambda_i}{\\lambda_{1} + \\cdots + \\lambda_p}.\\]\nSimilairement, les \\(m\\) première composantes expliquent \\[\\frac{\\sum_{i = 1}^{m} \\lambda_i}{\\sum_{i = 1}^{p} \\lambda_i} \\times 100\\%.\\] de la variabilité dans les variables.",
    "crumbs": [
      "Modules",
      "04 - Dimension",
      "ACP"
    ]
  },
  {
    "objectID": "contents/generalities/02-spaces.html",
    "href": "contents/generalities/02-spaces.html",
    "title": "Espaces",
    "section": "",
    "text": "Avant de pouvoir modéliser ou analyser des données, il est fondamental de bien comprendre la nature des variables que l’on manipule. En effet, le type de variables détermine :\nDans cette section, nous présentons les types de variables les plus courants, ainsi que les espaces associés.",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Espaces"
    ]
  },
  {
    "objectID": "contents/generalities/02-spaces.html#unité-statistique",
    "href": "contents/generalities/02-spaces.html#unité-statistique",
    "title": "Espaces",
    "section": "Unité statistique",
    "text": "Unité statistique\nUne unité statistique est l’élément de base sur lequel une observation est effectué. Moralement, c’est le “porteur” de l’information qui est utilisé pour déterminer le niveau d’agrégation de l’analyse. L’unité statistique est un choix du modélisateur.\n\n\n\n\n\n\nExemples\n\n\n\n\nDans le cas d’une enquête sur les revenus, on peut choisir l’individu comme unité.\nDans le cas d’une étude sur les classes d’un lycée, on peut choisir la classe comme unité.\nDans le cas d’une base de données d’imagerie médicale, on choisir l’image comme unité.\n\n\n\n\n\n\n\n\n\nParfois, une même base de données peut être analysée à plusieurs niveaux.\n\n\n\nUne image est constituée de pixels, chacun pouvant être décrit par des variables numériques (e.g. valeurs RVB, opacité, …). On peut choisir d’analyser chaque pixel, et donc prendre le pixel pour unité, ou bien analyser chaque image comme un tout, et donc prendre l’image comme unité.",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Espaces"
    ]
  },
  {
    "objectID": "contents/generalities/02-spaces.html#types-de-variables",
    "href": "contents/generalities/02-spaces.html#types-de-variables",
    "title": "Espaces",
    "section": "Types de variables",
    "text": "Types de variables\nOn distingue généralement quatre types de variables, que l’on identifie au niveau de la plus petite unité statistique du jeu de données.\n\n\n\n\n\n\nVariable numérique (ou quantitative)\n\n\n\nUne variable numérique (ou quantitative) est une variable dont les valeurs sont des nombres représentant une quantité mesurable.\nExemples: revenu en dollars, masse, âge, …\n\n\n\n\n\n\n\n\nVariable ordinale\n\n\n\nUne variable ordinale est une variable qualitative (ou catégorielle) dont les modalités peuvent être ordonnées naturellement, sans que l’écart entre les modalités soit quantifiable.\nExemples: niveau de revenu (faible, moyen ou élevé), niveau de satisfaction (“tout-à-fait en désaccord”, “en désaccord”, “pas d’avis”, “d’accord”, “tout-à-fait d’accord”), …\n\n\n\n\n\n\n\n\nVariable nominale symétrique\n\n\n\nUne variable nominale symétrique est une variable qualitative (ou catégorielle) dont toutes les modalités sont aussi informatives l’une que l’autre.\nExemples: nationalité, filière de formation, …\n\n\n\n\n\n\n\n\nVariable nominale asymétrique\n\n\n\nUne variable nominale asymétrique est une variable qualitative (ou catégorielle) dont l’une des modalités a un statut particulier, souvent plus fréquente ou considérée comme la valeur “par défaut”. Ainsi, avoir deux observations avec la valeur “par défaut” de cette variable nominale asymétrique ne nous apprend pas grand chose sur celles-ci; alors que on peut retirer beaucoup plus d’information de deux observations qui n’ont pas la valeur “par défaut”.\nExemples: présence ou absence d’un symptôme, transaction frauduleuse ou non, …\n\n\nBien que ces types de variables soient les plus communs, on peut trouver beaucoup d’autres types de variables. Par exemple, on peut s’intéresser à de la comparaison de courbes, de textes, d’images, de réseaux, etc. Dans ces situations, le choix de la représentation dépend du niveau auquel on souhaite se placer, et donc de l’unité statistique.",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Espaces"
    ]
  },
  {
    "objectID": "contents/generalities/02-spaces.html#espaces-associés",
    "href": "contents/generalities/02-spaces.html#espaces-associés",
    "title": "Espaces",
    "section": "Espaces associés",
    "text": "Espaces associés\nUne fois que nos données ont été collectés, la première étape d’une analyse statistique consiste à choisir un espace mathématique dans lequel travailler. Cette espace, que l’on appelle parfois espace d’observation et que l’on note \\(\\mathcal{X}\\), dépend du type de données observées. Il constitue le cadre formel dans lequel nos variables prennent leurs valeurs, et il guide les choix méthodologiques qui suivront.\n\n\n\n\n\n\nCas d’une variable numérique\n\n\n\nLorsque l’on observe un variable numérique (e.g. la température d’un pays), l’espace naturel dans lequel travailler est l’ensemble des réels, \\(\\mathcal{X} = \\mathbb{R}\\). Dans certains cas, on peut restreindre cet espace à un intervalle spécifique. Par exemple, si on s’intéresse à la taille d’une personne, on peut prendre \\(\\mathcal{X} = [0, +\\infty)\\) car la variable considérée ne peut pas être négative.\n\n\n\n\n\n\n\n\nCas d’une variable nominale (ou qualitative, ou catégorielle)\n\n\n\nPour une variable nominal, l’espace est un ensemble fini de modalité, l’ensemble des modalités prises par la variable. Par exemple, si on étudie les résultats d’un lancer de dés, la variable peut prendre les valeurs \\(1\\) à \\(6\\), et l’espace associé sera donc \\(\\mathcal{X} = \\{ 1, 2, 3, 4, 5, 6 \\}\\).\n\n\nLorsque les données sont plus conplexes, il faut choisir des espaces plus adaptés. Pour de l’analyse de courbes ou de signaux, on peut travailler dans un espace de fonctions. Par exemple, on peut considérer l’espace des fonctions continues sur un intervalle fermé \\([a, b]\\), noté \\(\\mathcal{X} = \\mathcal{C}([a, b])\\). Pour de l’analyse de texte (vu comme une séquence de caractères), l’espace de travail peut être un alphabet. Par exemple, on peut considérer \\(\\mathcal{X} = \\{ \\text{A}, \\text{B}, \\dots, \\text{Z} \\}\\).\nSouvent, on observe plusieurs variables en même temps, e.g. la taille, le poids et le sexe d’un individus. Dans ce cas, l’espace d’observation sera le produit cartésien (aussi appelé ensemble produit) des espaces associés à chaque variable : \\[\\mathcal{X} = \\mathcal{X}_1 \\times \\mathcal{X}_2 \\times \\dots \\mathcal{X}_p,\\] où \\(p\\) est le nombre de variables. Dans le cas où on observe \\(p\\) variables numérique, on notera plus simplement \\(\\mathcal{X} = \\mathbb{R}^p\\)",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Espaces"
    ]
  },
  {
    "objectID": "contents/generalities/05-model-evaluation.html",
    "href": "contents/generalities/05-model-evaluation.html",
    "title": "Évaluation de modeles",
    "section": "",
    "text": "Cette section est basée sur James et al. (2021), chapitre 5.\nNous avons vu dans la section précédente comment mesurer la qualité d’un estimateur : en utilisant l’erreur quadratique moyenne pour une variable quantitative et le taux d’erreur pour une variable qualitative. Cependant, si on calcule l’erreur en utilisant que les données observées, on risque de sous-estimer les vraies erreurs car la fonction \\(\\widehat{f}\\) a été apprise à l’aide des données observées et donc s’adapte à celles-ci. En effet, on pourrait donc juste prendre un modèle plus flexible qui s’ajustera mieux aux données observées et donc avoir une plus petite valeur de l’erreur. Mais si le modèle s’adapte trop aux données observées, il risque de ne pas être aussi bon si on l’applique sur de nouvelles données. En pratique, on souhaiterait un jeu de données d’entraînement sur lequel on apprend le modèle et un jeu de données de test sur lequel on calcule l’erreur de prédiction pour ajuster le modèle.\nGénéralement, nous n’avons pas accès à un jeu de données de test pour estimer l’erreur de prédiction sur celui-ci. Dans cette section, on va voir deux méthodes permettant d’estimer l’erreur de prédiction de test en découpant le jeu de données d’entraînement en sous-ensemble et en estimant \\(f\\) sur ces sous-ensemble.",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Évaluation de modeles"
    ]
  },
  {
    "objectID": "contents/generalities/05-model-evaluation.html#jeu-de-données-de-validation",
    "href": "contents/generalities/05-model-evaluation.html#jeu-de-données-de-validation",
    "title": "Évaluation de modeles",
    "section": "Jeu de données de validation",
    "text": "Jeu de données de validation\nL’idée du jeu de données de validation est très simple. On divise aléatoirement le jeu de données d’entraînement en deux parties : une partie qui va effectivement servir à entrainer le modèle et l’autre partie qui va servir à estimer l’erreur de prédiction.\nAdd schema!\nAdd exemple!\n\n\n\n\n\n\nComment choisir comment découper le jeu de données ?\n\n\n\nLa réponse simple : avec de la pratique et une connaissance du domaine. S’il y a beaucoup de données, on peut faire 50-50. Sinon, on peut partir un 70-30.\n\n\nDésavantage de la méthode :\n\nL’erreur de prédiction calculée sur le jeu de données de validation peut être très variable. En effet, elle dépend du nombre d’observations dans le jeu de validation et de quelles sont ses données.\nOn a moins de données pour apprendre le modèle. Comme les modèles ont tendance à moins bien apprendre avec moins de données, l’estimation de l’erreur sur le jeu de validation a tendance à surestimer l’erreur que l’on aurait avec un jeu de test et un modèle appris sur le jeu de données complet.",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Évaluation de modeles"
    ]
  },
  {
    "objectID": "contents/generalities/05-model-evaluation.html#validation-croisée",
    "href": "contents/generalities/05-model-evaluation.html#validation-croisée",
    "title": "Évaluation de modeles",
    "section": "Validation croisée",
    "text": "Validation croisée\nComme l’approche par jeu de données de validation, la validation croisée consiste à faire des sous-ensembles du jeu de données. L’approche consiste à découper de façon aléatoire l’ensemble des observations en \\(K\\) groupes de taille équivalanetes. Le premier sous-ensemble est utilisé comme jeu de données de validation et le modèle est appris sur les \\(K - 1\\) autres sous-ensembles. L’erreur de prédiction est calculé sur le premier sous-ensemble. Cette procédure est faite \\(K\\) fois; à chaque un différent sous-ensemble est utilisé comme jeu de données de validation. À la fin, on a donc \\(K\\) valeurs pour l’erreur de prédiction. On calcule enfin la moyenne des \\(K\\) valeurs de prédiction.\nAdd schema!\nAdd exemple!\n\n\n\n\n\n\nComment choisir le nombre de sous-ensemble ?\n\n\n\nEn pratique, on utilise \\(K = 5\\) ou \\(K = 10\\). Cela a un avantage computationnel car le modèle doit être appris \\(K\\) fois.",
    "crumbs": [
      "Modules",
      "03 - Généralités",
      "Évaluation de modeles"
    ]
  },
  {
    "objectID": "contents/02-revisions.html",
    "href": "contents/02-revisions.html",
    "title": "Révisions",
    "section": "",
    "text": "Slides: link\nTD: link\nTP: link",
    "crumbs": [
      "Modules",
      "02 - Révisions"
    ]
  },
  {
    "objectID": "contents/02-revisions.html#sommaire",
    "href": "contents/02-revisions.html#sommaire",
    "title": "Révisions",
    "section": "Sommaire",
    "text": "Sommaire\n\nAlgèbre linéaire\nProbabilités et statistiques\nAlgorithmique / Programmation\n\n\n\n\nPrediction (xkcd:2370).",
    "crumbs": [
      "Modules",
      "02 - Révisions"
    ]
  },
  {
    "objectID": "contents/04-dimension.html",
    "href": "contents/04-dimension.html",
    "title": "Dimension",
    "section": "",
    "text": "Slides: link",
    "crumbs": [
      "Modules",
      "04 - Dimension"
    ]
  },
  {
    "objectID": "contents/supervised/05-ensemble.html",
    "href": "contents/supervised/05-ensemble.html",
    "title": "Ensemble",
    "section": "",
    "text": "On se rend compte qu’en présence de grands jeux de données, il est plus facile d’avoir une classification performante en combinant les prévisions de plusieurs classificateurs faibles qu’en construisant un seul classificateur très complexe. On appelle méthode d’ensemble une méthode qui consiste à déduire une prévision unique à partir des prévisions de plusieurs modèles.\nIl existe plusieurs stratégies pour combiner les prévisions de modèles multiples : * Moyenne des probabilités prescrites par chaque modèle. * Vote de majorité * Approche de type “sélection de variables” utilisée en régression, mais on prend un modèles au lieu d’une variable. * Bagging, boosting, forêts aléatoires",
    "crumbs": [
      "Modules",
      "05 - Supervisée",
      "Ensemble"
    ]
  },
  {
    "objectID": "contents/supervised/05-ensemble.html#bagging",
    "href": "contents/supervised/05-ensemble.html#bagging",
    "title": "Ensemble",
    "section": "Bagging",
    "text": "Bagging\nLa méthode consiste à\n\nSélectionner \\(B\\) échantillons “bootstrap” (tirage avec remise).\nConstruire un arbre de classification avec chacun des échantillons “bootstrap”\nPrédire la classe d’une nouvelle observation avec chacun des \\(B\\) arbres\nAttribuer à la nouvelle observation la classe dans laquelle elle est prédite le plus souvent. On peut calculer un score qui est la moyenne des probabilités prédites par chaque arbre.\n\nLa méthode du bagging augmente la stabilité des prédictions. Cependant, il est plus difficile d’interpréter l’importance de chaque variable dans le processus de classification. On peut procéder ainsi: * additionner la réduction de l’indice de Gini pour toutes les divisions basées sur une certaine variable; * calculer la moyenne de ces réductions sur tous les arbres * exprimer la moyenne de réduction de chaque variable en pourcentage de la moyenne de réduction maximale observée sur l’ensemble des variables.",
    "crumbs": [
      "Modules",
      "05 - Supervisée",
      "Ensemble"
    ]
  },
  {
    "objectID": "contents/supervised/05-ensemble.html#forêts-aléatoires",
    "href": "contents/supervised/05-ensemble.html#forêts-aléatoires",
    "title": "Ensemble",
    "section": "Forêts aléatoires",
    "text": "Forêts aléatoires\nTrès similaire à la méthode du bagging; la méthode des forêts aléatoires considère elle aussi \\(B\\) arbres obtenus à partir de \\(B\\) échantillons bootstrap.\nL’idée est que lors de la construction des \\(B\\) arbres, dans la méthode des forêts aléatoires avant chaque division on choisit aléatoirement \\(m&lt;p\\) des variables \\(X_1,\\ldots,X_p\\) et on ne considère que ces \\(m\\) variables pour la division optimale. Un choix commun est \\(m\\approx\\sqrt{p}\\).\nL’avantage de procéder ainsi est de décorréler les arbres obtenus, puisque le gros point faible de la méthode du bagging est que les \\(B\\) arbres obtenus se ressemblent souvent beaucoup.",
    "crumbs": [
      "Modules",
      "05 - Supervisée",
      "Ensemble"
    ]
  },
  {
    "objectID": "contents/supervised/05-ensemble.html#boosting",
    "href": "contents/supervised/05-ensemble.html#boosting",
    "title": "Ensemble",
    "section": "Boosting",
    "text": "Boosting\nL’idée derrière cette approche est de créer des arbres de faon successive en donnant un poids plus élevé aux observations mal classées par les arbres précédents. Il est important d’utiliser des arbres peu performants (très, très simples)} et de laisser le boosting déterminer les bons poids à fournir à ces arbres.\nIl existe plusieurs variantes à ce type d’approche * boosting adaptatif (AdaBoost); * boosting par descente du gradient (gradient boosting).",
    "crumbs": [
      "Modules",
      "05 - Supervisée",
      "Ensemble"
    ]
  },
  {
    "objectID": "contents/supervised/05-ensemble.html#descente-du-gradient-stochastique",
    "href": "contents/supervised/05-ensemble.html#descente-du-gradient-stochastique",
    "title": "Ensemble",
    "section": "Descente du gradient stochastique",
    "text": "Descente du gradient stochastique\nOn doit choisir un nombre \\(M\\) d’itérations, la taille \\(J\\) de l’arbre de classification à construire à chaque itération (on suggère quelque chose de petit, comme \\(4\\le J\\le 8\\)), la fraction \\(f\\) des données d’entrainement à échantillonner “au hasard” à chaque itération (on suggère \\(0.5\\le f\\le 0.8\\)).\nOn construit un premier arbre de taille \\(J\\) au jeu de données, disons \\(T_1\\). Pour \\(m=2,\\ldots,M\\): * On calcule les erreurs de prévisions (pseudo-résidus) obtenus avec l’arbre \\(T_{m-1}\\) pour chaque observation. * On échantillonne une fraction \\(f\\) du jeu de données d’entrainement et on construit un nouvel arbre de taille \\(J\\), disons \\(t_m\\), pour ces données, mais ce coup-ci en utilisant les pseudo-résidus comme variable à prédire. * On calcule un multiplicateur \\(\\gamma_m\\) qui minimise une certaine fonction de perte. * On pose \\(T_m=T_{m-1}+\\gamma_mt_m\\).\n\nLe mode d’échantillonnage aléatoire à l’étape 3: donner une probabilité d’être sélectionnée plus élevée aux observations pour lesquelles le pseudo-résidu est plus loin de 0\nLa fonction de perte calculée à l’étape 4, la façon dont elle est optimisée, le poids qu’elle donne à chaque observation\nInclusion de pénalités de régularisation pour prévenir le sur-ajustement\nImplémentation informatique (XGBoost vs LightGBM, utilisation de GPU, etc.)",
    "crumbs": [
      "Modules",
      "05 - Supervisée",
      "Ensemble"
    ]
  },
  {
    "objectID": "contents/supervised/05-ensemble.html#tuning",
    "href": "contents/supervised/05-ensemble.html#tuning",
    "title": "Ensemble",
    "section": "Tuning",
    "text": "Tuning\nToute m'ethode de classification requiert qu’on règle (tune) la valeur des hyper-paramètres.\nMême si ce n’est pas un théorème, on semble très souvent observer le phénomène que plus la méthode est puissante, plus son réglage est difficile (p.ex. plusieurs hyper-paramètres, sensibilité à la valeur des hyper-paramètres, etc.)\n\nAnalyse discriminante: linéaire ou quadratique? ; probabilités a priori\nArbres de classification: indice d’impureté ; nombre de feuilles maximal ; profondeur maximale ; nombre minimal d’observations dans un noeud avant de tenter un scission ; nombre minimal d’observations dans une feuille\nBagging: Arbres de classification + nombre d’échantillons bootstrap (\\(B\\))\nForêts aléatoires: Bagging + nombre de variables à considérer pour chaque division (\\(m\\))\nBoosting: Arbres de classification + fraction du jeu de données à échantillonner (\\(f\\)) + quelques autres hyper-paramètres selon la variante …",
    "crumbs": [
      "Modules",
      "05 - Supervisée",
      "Ensemble"
    ]
  },
  {
    "objectID": "contents/misc/good-practices.html",
    "href": "contents/misc/good-practices.html",
    "title": "Bonnes pratiques de programmation",
    "section": "",
    "text": "Cette page est basé sur un document qu’Aurélien Nicosia (ULaval) a créé en 2023 appelé “Bonnes pratiques de programmation en R”. Celui-ci a été mis à jour et écrit dans un contexte plus général.\nPeu importe le langage informatique, employer de bonnes pratiques de programmation signifie respecter certaines normes afin de créer du “bon” code. On peut donc se demander ce qu’est un “bon” code. Pour moi, un “bon” code est un code qui remplit trois objectifs:\nPourquoi est-ce souhaitable d’adopter de bonnes pratiques ? Cela permet que le code soit compris et utilisé par n’importe qui (et en particulier, soi-même dans le futur). À long terme, les bonnes pratiques apportent une augmentation de notre productivité en évitant les répétitions inutiles."
  },
  {
    "objectID": "contents/misc/good-practices.html#objectif-1-produire-les-résultats-escomptés",
    "href": "contents/misc/good-practices.html#objectif-1-produire-les-résultats-escomptés",
    "title": "Bonnes pratiques de programmation",
    "section": "Objectif 1 : Produire les résultats escomptés",
    "text": "Objectif 1 : Produire les résultats escomptés\nLa priorité lors du développement de tout code informatique est certainement l’écriture d’un code qui réalise bien ce qu’il doit réaliser. Donc, un “bon”” code doit produire les bons résultats. Pour y arriver, le code doit d’abord être fonctionnel, c’est-à-dire ne pas contenir de bogues. Pour s’assurer d’écrire du code qui fonctionne correctement, il faut simplement le tester. Il vaut mieux tester fréquemment, à chaque petit ajout, plutôt que de produire beaucoup de code avant de le tester. Ainsi, il y a beaucoup moins de débogage à faire. Un courant de pensée en informatique prône même l’écriture des tests avant l’écriture du code (test driven development). Cependant, une meilleure pratique est de formaliser les tests afin de pouvoir facilement les lancer à nouveau lors de modifications futures apportées au code."
  },
  {
    "objectID": "contents/misc/good-practices.html#objectif-2-code-facile-à-maintenir",
    "href": "contents/misc/good-practices.html#objectif-2-code-facile-à-maintenir",
    "title": "Bonnes pratiques de programmation",
    "section": "Objectif 2 : Code facile à maintenir",
    "text": "Objectif 2 : Code facile à maintenir\nMaintenir un code informatique signifie de s’assurer qu’il continue de fonctionner correctement dans le futur, malgré les modifications qui lui sont apportées. Un code utilisé fréquemment est un code appelé à être mis à jour, soit pour y ajouter des fonctionnalités, soit pour corriger des bogues non détectés par les tests, mais découverts par des utilisateurs. Reprendre un code écrit par quelqu’un d’autre, ou écrit par nous-mêmes quelques mois auparavant, n’est pas toujours une tâche facile. Cependant, s’il s’agit d’un code correctement écrit, il ne devrait pas être trop difficile à comprendre et à modifier.\nLa maintenance d’un code est basé sur trois principes: son versionnage, sa compréhensibilité et sa réutilisabilité.\nLe principe du versionnage est d’utiliser un logiciel qui enregistre les différentes modifications faites sur le code. Le plus connu est Git. Il permet de naviguer entre les différentes versions de votre code, de créer plusieurs versions (appelée branches), de collaborer à plusieurs sur un même code. C’est vraiment un indispensable à avoir dans sa panoplie. Le versionnage peut ensuite être enregistré sur Github qui gère la machinerie sous-jacente. À titre d’exemple, ce site utilise Git et Github pour son versionnage et vous pouvez voir les différentes versions ici.\nUn code compréhensible est clair et se lit bien (presque comme du texte). Il comporte souvent des instructions qui parlent d’elles-mêmes. Ces instructions sont typiquement succinctes, car une instruction trop longue effectue souvent plusieurs tâches difficilement discernables. Si la lecture d’une instruction ne permet pas à un programmeur initié dans le langage informatique employé de comprendre ce qu’elle réalise, il est alors recommandé d’insérer un commentaire dans le code pour expliquer à quoi sert l’instruction. En plus de commentaires pour expliquer certains instructions, toutes fonctions devraient être documentées. La documentation d’une fonction devrait contenir: un texte explicatif de ce que fait la fonction, une description des arguments acceptés en entrée, une description des résultats produits et un exemple d’utilisation. Lorsque que l’on programme, il est aussi de bon ton de suivre un guide de style. Un guide de style est un ensemble de règles sur lesquelles les développeurs se sont mis d’accord et qui permet d’avoir une syntaxe similaire à travers les différents projets. En R, vous pouvez utiliser le guide de style du tidyverse. En Python, vous pouvez utiliser le guide de style PEP8 écrit par le créateur de Python. Et en Julia, vous pouvez utiliser le guide de style fournit avec le manuel du langage. Vous pouvez utiliser un linter, un outil d’analyse de code statique pour vous aidez à respecter ces guides de styles. À noter que ces guides de style sont des recommendations et il n’y a rien d’obligatoire à les suivre. Certaines règles se contredisant, je vous recommanderai même de ne pas en suivre certaines.\nLa façon la plus commune d’avoir un code facile à réutiliser est d’en faire des fonctions que l’on peut ensuite partager à travers un package."
  },
  {
    "objectID": "contents/misc/good-practices.html#objectif-3-code-suffisamment-rapide",
    "href": "contents/misc/good-practices.html#objectif-3-code-suffisamment-rapide",
    "title": "Bonnes pratiques de programmation",
    "section": "Objectif 3 : Code suffisamment rapide",
    "text": "Objectif 3 : Code suffisamment rapide\nAprès nous être assurés que notre code fonctionne correctement et qu’il est facilement maintenable, nous pouvons nous préoccuper de son temps d’exécution. Bien qu’il ne s’agisse pas du critère le plus important pour définir ce qu’est du “bon” code, c’est tout de même un critère à ne pas négliger, car un code trop lent risque de ne pas être utilisé. Pour produire du code computationnellement efficace, il faut :\n\nmettre en pratique quelques trucs simples, i.e. utiliser les syntaxes optimisées des différents langages;\ncomparer le temps d’exécution de différentes façons de programmer une tâche;\nparfois faire du calcul en parallèle;\nparfois programmer des bouts de code dans un autre langage plus bas niveau."
  },
  {
    "objectID": "contents/misc/good-practices.html#en-résumé",
    "href": "contents/misc/good-practices.html#en-résumé",
    "title": "Bonnes pratiques de programmation",
    "section": "En résumé",
    "text": "En résumé\nEn résumer, pour adopter de bonnes pratiques de programmation, il faut :\n\nTester son code fréquemment son code.\nUtiliser un logiciel de gestion de versions.\nDocumenter son code.\nRespecter un guide de style.\nFactoriser son code en créant des fonctions et des packages.\nOptimiser le temps d’exécution."
  },
  {
    "objectID": "contents/misc/pipe.html",
    "href": "contents/misc/pipe.html",
    "title": "Opérateur pipe en R",
    "section": "",
    "text": "Cette page est basé sur un document qu’Aurélien Nicosia (ULaval) a créé en 2023 appelé “Opérateur pipe”. Celui-ci a été mis à jour.\nDepuis la version 4.1.0 de R, sorti en mai 2021, le langage a introduit l’opérateur pipe |&gt; en s’inspirant de ce que faisait le package magrittr. À partir de R 4.3.0, le guide de style du tidyverse recommande l’utilisation de l’opérateur pipe de base, et non celui de magrittr.\n\n\n\n\n\n\nRaccourcis clavier\n\n\n\nDans RStudio, le raccourci clavier pour insérer l’opérateur pipe est:\n\nSous Windows : Ctrl + Shift + M\nSous macOS : ⌘ + ⇧ + M\n\n\n\nCet opérateur introduit une façon d’enchaîner les intructions et de passer des arguments à des fonctions de manière plus lisible que la manière classique.\nPour résumer le fonctionnement de cette opérateur, voici comment il transforme quelques appels de fonctions:\n\nf(x) devient x |&gt; f();\nf(x, y) devient x |&gt; f(y);\nh(g(f(x))) devient x |&gt; f() |&gt; g() |&gt; h().\n\nCette opérateur permet de mettre en avant la séquence d’actions et non l’objet sur lequel la séquence d’actions est faite. Cela rend le code plus lisible (et avoir un code lisible est une bonne pratique). En lisant de gauche à droite l’instruction h(g(f(x))), nous voyons d’abord l’appel à la fonction h, puis l’appel à la fonction g et finalement l’appel à la focntion f. Pourtant, l’évaluation de cette instruction se fait dans le sens inverse. En effet, R va d’abord :\n\névaluer f(x);\npuis, il passera le résultat à la fonction g et retournera le résultat;\nqui sera passé à la fonction h et le résultat final sera retourné.\n\nSi nous voulons écrire un code qui reflète l’ordre des évaluations correctement, nous pourrions écrire :\n\nres1 &lt;- f(x)\nres2 &lt;- g(res1)\nh(res2)\n\nCe code a cependant le défaut de créer des objects que nous souhaitons pas nécessairement conserver. L’opérateur |&gt; n’a pas ce défaut ! En effet, une instruction écrite en utilisant l’opérateur |&gt; permet de suivre l’ordre des évaluations, sans créer d’objets inutilement en mémoire.\nPour encore plus de clarté, il est possible d’étendre sur plusieurs lignes un instruction contenant plusieurs opérateur |&gt; de façon à avoir une fonction par ligne :\n\nx |&gt; \n  f() |&gt; \n  g() |&gt; \n  h()\n\nSi l’argument que nous souhaitons passer avec l’opérateur |&gt; n’est pas celui en première position, il faut utiliser _ comme suit avec un paramètre nommé: f(y, z = x) devient x |&gt; f(y, z = _).\nPrenons un exemple pour illustrer l’utilisation de l’opérateur |&gt;. Supposons que nous avons la chaîne de caractères suivantes :\n\ntext &lt;- \"Ceci est un example\"\n\net que nous souhaitons la corriger—remplacer “example” par “exemple” et ajouter un point à la fin—avec l’intruction suivante :\n\npaste0(gsub(pattern = \"example\", replacement = \"exemple\", x = text), \".\")\n\n[1] \"Ceci est un exemple.\"\n\n\nCette instruction est un peu difficile à lire en raison de l’appel à la fonction gsub imbriqué dans un appel de fontion paste0. Nous pourrions la réécrire comme suit avec l’opérateur |&gt; :\n\ntext |&gt; \n  gsub(pattern = \"example\", replacement = \"exemple\", x = _) |&gt; \n  paste0(\".\")\n\n[1] \"Ceci est un exemple.\"\n\n\nPrenons un autre exemple numérique. On souhaite faire le calcul suivant : \\[\\frac{(2 + 4) \\times 8}{2}.\\]\nPour cela, nous avons besoin de quelques fonctions mathématiques.\n\nadd &lt;- function(x, y) {\n  x + y\n}\n\nmul &lt;- function(x, y) {\n  x * y\n}\n\ndiv &lt;- function(x, y) {\n  x / y\n}\n\nOn peut faire le calcul de trois manières différentes:\n\n# En créant différents objets \nres1 &lt;- add(2, 4)\nres2 &lt;- mul(res1, 8)\nres3 &lt;- div(res2, 2)\nprint(res3)\n\n[1] 24\n\n# En imbriquant les fonctions\nres &lt;- div(mul(add(2, 4), 8), 2)\nprint(res)\n\n[1] 24\n\n# Avec l'opérateur pipe \nres &lt;- 2 |&gt;\n  add(4) |&gt; \n  mul(8) |&gt; \n  div(2)\nprint(res)\n\n[1] 24"
  },
  {
    "objectID": "contents/08-conclusion.html",
    "href": "contents/08-conclusion.html",
    "title": "Conclusion",
    "section": "",
    "text": "Y a-t-il des algorithmes/stratégies/critères pour identifier les bonnes valeurs des hyper-paramètres (en ACP, en regroupement hiérarchique, arbres, méthodes d’ensemble) ?\nComment définir/construire les variables \\(X_1,\\ldots,X_p\\) (feature engineering) ?\nComment identifier les données aberrantes et décider si on les enlève ou les garde ?\nComment scinder les données en entrainement vs validation ?\nLes données sont-elles représentatives de la “population cible” ?\nOn fait quoi si pour certaines observations, des valeurs de certaines variables sont manquantes ?",
    "crumbs": [
      "Modules",
      "08 - Conclusion"
    ]
  },
  {
    "objectID": "contents/unsupervised/01-kmeans.html",
    "href": "contents/unsupervised/01-kmeans.html",
    "title": "\\(k\\)-means",
    "section": "",
    "text": "Algorithme des \\(k\\)-moyennes:\n\\[\\mu_{k} = \\frac{1}{N_k} \\sum_{i: C(i) = k} x_i, \\quad k = 1, \\dots, K,\\]\noù \\(N_{k}\\) est le nombre d’observations dans le group \\(k\\).\nExample\nInconvénients des \\(k\\)-means:\nExpliciter chaque nconvénients et de potentielles solutions.",
    "crumbs": [
      "Modules",
      "06 - Non-supervisée",
      "$k$-means"
    ]
  },
  {
    "objectID": "contents/unsupervised/01-kmeans.html#k-médoides",
    "href": "contents/unsupervised/01-kmeans.html#k-médoides",
    "title": "\\(k\\)-means",
    "section": "\\(k\\)-médoides",
    "text": "\\(k\\)-médoides\nOn n’utilise plus le centre, mais l’observation qui minimise les distances dans chaque groupe. La médiane plutôt que la moyenne.\nAvantages:\n\nPermet d’intégrer des variables ordinales\nRobuste\nPermet de bien spécifier la matrix de distance\n\nInconvénients:\n\nIl faut connaître le nombre de groupes.",
    "crumbs": [
      "Modules",
      "06 - Non-supervisée",
      "$k$-means"
    ]
  },
  {
    "objectID": "contents/01-introduction.html",
    "href": "contents/01-introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Slides: link",
    "crumbs": [
      "Modules",
      "01 - Introduction"
    ]
  },
  {
    "objectID": "contents/01-introduction.html#quest-ce-que-lanalyse-de-données",
    "href": "contents/01-introduction.html#quest-ce-que-lanalyse-de-données",
    "title": "Introduction",
    "section": "Qu’est-ce que l’analyse de données ?",
    "text": "Qu’est-ce que l’analyse de données ?\nL’analyse de données est un ensemble de méthodes permettant de retirer de l’information d’un jeu de données. On parle aussi d’apprentissage statistique (statistical learning). L’idée est d’utiliser des modèles statistiques pour comprendre comment les données sont structurées et comment elles intéragissent l’une avec l’autre.\n\n\n\n\n\n\nExemple\n\n\n\nImaginons que vous êtes employé par l’Organisation des Nations Unies (ONU). Votre mission est d’analyser l’espérance de vie à travers le monde. Pour cela, vous disposez d’une mesure de l’espérance de vie dans chaque pays membre de l’ONU, bien sûr, mais aussi le PIB par habitant, les montants des dépenses liés à la santé, le taux de fertilité, le taux d’urbanisation, le niveau d’éducation du pays, etc. Le but de l’analyse de données est de trouver des liens entre ses différentes variables et la variable d’intérêt, l’espérance de vie, de visualiser ces données, et éventuellement de prédire l’espérance de vie à partir des autres variables.",
    "crumbs": [
      "Modules",
      "01 - Introduction"
    ]
  },
  {
    "objectID": "contents/01-introduction.html#objectifs-du-cours",
    "href": "contents/01-introduction.html#objectifs-du-cours",
    "title": "Introduction",
    "section": "Objectifs du cours",
    "text": "Objectifs du cours\nDans ce cours, on cherche à introduire des méthodes qui permettent une étude d’un jeu de données de “haute dimension” (dans le sens où l’on ne peut pas faire un simple graphique de l’ensemble des variables pour chaque observation) sans avoir recours à un modèle probabiliste. Les différentes techniques que l’on va voir peuvent servir à:\n\nvisualiser les données;\nréduire la dimension des données;\nidentifier certains liens entre les variables;\ndiviser le jeu de données en groupes/classes.\n\nCe cours n’a pas vocation à être exhaustif, dans le sens de présenter toutes les méthodes possibles. Ce cours n’a pas non plus vocation à être à l’état de l’art, dans le sens où on ne s’intéressera pas aux derniers développements en apprentissage machine. Ce cours n’est pas non plus un cours de programmation.\nPour finir cette indroduction, voici un passage de Statistical Rethinking de Richard McElreath (McElreath 2020) trouvant résonnance dans ce cours.\n\nStatistics courses […] tend to resemble horosscopes. There are two senses to this resemblance. First, in order to remain plausibly correct, they must remain tremendously vague. This is because the targets of the advice, for both horoscopes and statistical advice, are diverse. But only the most general advice applies to all cases. A horoscope uses only the basic facts of birth to forecast life events, and a […] statistical guide uses only the basic facts of measurement and design to dictate a model. It is easy to do better, once more detail is available. In the case of statistical analysis, it is tipically only the scientist whho can provide that detail, not the statistician. Second, there are strong incentives for both astrologers and statisticians to exaggerate the power and importance of their advice. No one likes an astrologer who forecasts doom, and few want a statistician who admits the answers as desired are not in the data as collected. Scientists desire results, and they will buy and attend to statisticians and statistical procedures that promise them. What we end up with is too often horoscopic: vague and optimistic, but still claiming critical importance.\n\n\n\n\nMachine learning (xkcd:1838).",
    "crumbs": [
      "Modules",
      "01 - Introduction"
    ]
  },
  {
    "objectID": "td/02-revision-td.html",
    "href": "td/02-revision-td.html",
    "title": "TD: Révision",
    "section": "",
    "text": "Dans ce problème, on cherche à modéliser la répartition des vélos en libre service dans les différentes stations de l’université Laval. Le campus comporte cinq stations pouvant acceuillir un total de \\(136\\) vélos (lien): Abitibi-Prince (ABP), Alphone-Desjardins (ADJ), Charles-De Koninck (DKN), Ferdinand-Vandry (VND) et PEPS.\nSupposons que tous les vélos sont retournés à une des cinq stations à la fin de la journée, i.e. pour chaque jour, il y a un moment dans la journée (par exemple, à minuit), où tous les vélos sont à une certaine station. Nous pouvons donc nous intéresser à ces stations à ce moment de la journée pour chaque jour. Nous cherchons à modéliser les movements des vélos de minuit pour un jour donné jusqu’à minuit du jour suivant. Nous trouvons que :\n\npour les vélos empruntés à ABP, \\(50\\%\\) y retourne, \\(10\\%\\) vont à ADJ, \\(20\\%\\) vont à DKN et \\(20\\%\\) vont à VND.\npour les vélos empruntés à ADJ, \\(30\\%\\) y retourne, \\(10\\%\\) vont à ABP, \\(10\\%\\) vont à DKN, \\(10\\%\\) vont à VND et \\(40\\%\\) vont au PEPS.\npour les vélos empruntés à DKN, \\(80\\%\\) y retourne, \\(5\\%\\) vont à ADJ, et \\(15\\%\\) vont au PEPS.\npour les vélos empruntés à VND, \\(50\\%\\) y retourne, \\(20\\%\\) vont à ABP, \\(5\\%\\) vont à ADJ, \\(15\\%\\) vont à DKN et \\(10\\%\\) vont au PEPS.\npour les vélos empruntés au PEPS, \\(0\\%\\) y retourne, \\(25\\%\\) vont à ABP, \\(25\\%\\) vont à ADJ, \\(25\\%\\) vont à DKN et \\(25\\%\\) vont à VND.\n\n\nFaire un graphe de la situation.\nÉcrire la matrice \\(T\\) tel que chaque entrée \\(t_{ij}\\) corresponde à la probabilité de passer de la station \\(i\\) à la station \\(j\\), \\(i, j \\in \\{ \\text{ABP}, \\text{ADJ}, \\text{DKN}, \\text{VND}, \\text{PEPS} \\}\\). On appelle cette matrice, la matrice de transition.\nQuelle est la probabilité qu’un vélo soit à la station PEPS au jour 2 sachant qu’il était à la station ADJ au début ?\nSupposons qu’il y ait \\(20\\) vélos à ABP, \\(35\\) vélos à ADJ, \\(26\\) vélos à DKN, \\(45\\) à VND et \\(10\\) au PEPS. En utilisant une diagonalisation de la matrice \\(T\\), donner la répartition des vélos après \\(10\\) jours."
  },
  {
    "objectID": "td/02-revision-td.html#exercice-1-un-problème-de-vélo",
    "href": "td/02-revision-td.html#exercice-1-un-problème-de-vélo",
    "title": "TD: Révision",
    "section": "",
    "text": "Dans ce problème, on cherche à modéliser la répartition des vélos en libre service dans les différentes stations de l’université Laval. Le campus comporte cinq stations pouvant acceuillir un total de \\(136\\) vélos (lien): Abitibi-Prince (ABP), Alphone-Desjardins (ADJ), Charles-De Koninck (DKN), Ferdinand-Vandry (VND) et PEPS.\nSupposons que tous les vélos sont retournés à une des cinq stations à la fin de la journée, i.e. pour chaque jour, il y a un moment dans la journée (par exemple, à minuit), où tous les vélos sont à une certaine station. Nous pouvons donc nous intéresser à ces stations à ce moment de la journée pour chaque jour. Nous cherchons à modéliser les movements des vélos de minuit pour un jour donné jusqu’à minuit du jour suivant. Nous trouvons que :\n\npour les vélos empruntés à ABP, \\(50\\%\\) y retourne, \\(10\\%\\) vont à ADJ, \\(20\\%\\) vont à DKN et \\(20\\%\\) vont à VND.\npour les vélos empruntés à ADJ, \\(30\\%\\) y retourne, \\(10\\%\\) vont à ABP, \\(10\\%\\) vont à DKN, \\(10\\%\\) vont à VND et \\(40\\%\\) vont au PEPS.\npour les vélos empruntés à DKN, \\(80\\%\\) y retourne, \\(5\\%\\) vont à ADJ, et \\(15\\%\\) vont au PEPS.\npour les vélos empruntés à VND, \\(50\\%\\) y retourne, \\(20\\%\\) vont à ABP, \\(5\\%\\) vont à ADJ, \\(15\\%\\) vont à DKN et \\(10\\%\\) vont au PEPS.\npour les vélos empruntés au PEPS, \\(0\\%\\) y retourne, \\(25\\%\\) vont à ABP, \\(25\\%\\) vont à ADJ, \\(25\\%\\) vont à DKN et \\(25\\%\\) vont à VND.\n\n\nFaire un graphe de la situation.\nÉcrire la matrice \\(T\\) tel que chaque entrée \\(t_{ij}\\) corresponde à la probabilité de passer de la station \\(i\\) à la station \\(j\\), \\(i, j \\in \\{ \\text{ABP}, \\text{ADJ}, \\text{DKN}, \\text{VND}, \\text{PEPS} \\}\\). On appelle cette matrice, la matrice de transition.\nQuelle est la probabilité qu’un vélo soit à la station PEPS au jour 2 sachant qu’il était à la station ADJ au début ?\nSupposons qu’il y ait \\(20\\) vélos à ABP, \\(35\\) vélos à ADJ, \\(26\\) vélos à DKN, \\(45\\) à VND et \\(10\\) au PEPS. En utilisant une diagonalisation de la matrice \\(T\\), donner la répartition des vélos après \\(10\\) jours."
  },
  {
    "objectID": "td/02-revision-td.html#exercice-2-paradoxe-des-deux-enfants",
    "href": "td/02-revision-td.html#exercice-2-paradoxe-des-deux-enfants",
    "title": "TD: Révision",
    "section": "Exercice 2: Paradoxe des deux enfants",
    "text": "Exercice 2: Paradoxe des deux enfants\nOn cherche à modéliser les probabilités d’avoir des enfants d’un certain sexe. Dans toutes les questions, les enfants sont soit de sexe masculin, soit de sexe féminin, de façon équiprobable.\n\nM. Gagnon a deux enfants. L’enfant aîné est une fille. Quelle est la probabilité que son deuxième enfant soit aussi une fille ?\nMme Tremblay a deux enfants. On lui pose la question suivante : “Avez-vous au moins un garçon ?” et elle répond : “Oui”. Quelle est la probabilité que les deux enfants soient des garçons ?\nEst-ce que la probabilité de Mme Tremblay d’avoir deux garçons change si on lui pose la question suivante : “Indiquez moi le sexe de l’un de vos enfants.” et qu’elle répond : “J’ai (au moins) un garçon.” ?\nOn croise M. Gagnon dans la rue en train de se balader avec sa fille. On lui demande quel jour de la semaine elle est née. Elle nous répond: “Vendredi”. Quelle est la probabilité que son deuxième enfant soit aussi une fille ?"
  },
  {
    "objectID": "td/02-revision-td.html#exercice-3-la-loi-dohm",
    "href": "td/02-revision-td.html#exercice-3-la-loi-dohm",
    "title": "TD: Révision",
    "section": "Exercice 3: La loi d’Ohm",
    "text": "Exercice 3: La loi d’Ohm\nOn cherche à calculer la valeur d’un résistance. Pour cela, on lui envoie un courant électrique (intensité en ampères, A) et on mesure la différence de potentiel entre les bornes de la résistance (tension en volt, V). On trouve les valeurs suivantes :\n\n\n\nIntensité (A)\nVoltage (V)\n\n\n\n\n0.2\n4.0\n\n\n0.5\n10.4\n\n\n0.9\n18.7\n\n\n1.0\n21.1\n\n\n1.2\n25.1\n\n\n1.3\n27.4\n\n\n1.8\n37.8\n\n\n\n\nCalculer l’intensité moyenne et le voltage moyen.\nCalculer les variances de l’intensité et du voltage.\nCalculer la covariance entre l’intensité et le voltage.\nLa loi d’Ohm nous dit que l’intensité et le voltage sont proportionnelle suivant la relation \\(V = R A\\) où \\(R\\) est la valeur de la résistance en Ohm. Cette relation est équivalente à estimer un modèle linéaire entre l’intensité et le voltage. La résistance \\(R\\) est donc donnée par le ratio entre la covariance entre l’intensité et le voltage et la variance de l’intensité (cf. cours de régression pour une preuve). Calculer la valeur de \\(R\\).\nEn reprenant les valeurs du tableau, vérifier la valeur de \\(R\\). Pourquoi est-ce que l’on ne retrouve pas exactement les valeurs données ?"
  }
]